{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:24px; font-family:'Roboto'; font-weight:bold;\">\n",
    "Script to visualize iMOD inputs in QGIS.\n",
    "</span><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\033[1m{'*'*50} Mdl_In_to_mm {'*'*50}\\033[0m\")\n",
    "print('This script converts model inputs (mainly IDF) to TIF files, to be visualized in QGIS. It also calculates some parameters from Mdl Ins (e.g.) Aquifer layer thickness is calculated from TOP-BOT (same as MF does internally).')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.0. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from WS_Mdl import utils as U\n",
    "from WS_Mdl import geo as G\n",
    "from WS_Mdl import utils_imod as UIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(G)\n",
    "importlib.reload(U)\n",
    "importlib.reload(UIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1. Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MdlN = 'NBr13'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Process Regular, Time Independent IDF Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select rows to be converted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.PRJ_to_TIF(MdlN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Time dependent packages\n",
    "Those will have to be processed 1 by 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_paths = U.get_MdlN_paths(MdlN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for Pkg in DF.loc[ (DF[\"time\"].notna()) & (DF['time']!='-'), 'package'].unique():\n",
    "    print(DF.loc[ DF['package']==Pkg, 'path'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_time = DF[ ( DF[\"time\"].notna() ) &\n",
    "              ( DF[\"time\"]!='-'    ) &\n",
    "              ( DF['path'].notna() )] # Non time packages have NaN in 'time' Fld. Failed packages have '-', so they'll also be excluded. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.0. DRN & RIV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import imod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------- Get paths ------------------------------------------------------------------------------------------\n",
    "d_paths = U.get_MdlN_paths(MdlN)\n",
    "Xmin, Ymin, Xmax, Ymax, cellsize, N_R, N_C = U.Mdl_Dmns_from_INI(d_paths['path_INI'])\n",
    "\n",
    "# -------------------- Read PRJ to DF -------------------------------------------------------------------------------------\n",
    "DF = UIM.PRJ_to_DF(MdlN) # Read PRJ file to DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mdl = 'NBr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f' --- Converting time dependant packages ---')\n",
    "for i, R in DF_time[DF_time['package'].isin(('DRN', 'RIV'))].iterrows():\n",
    "    print(f\"\\t{f\"{R['package']}_{R['parameter']}\":<30} ... \", end='')\n",
    "    \n",
    "    try:    \n",
    "        ## Prepare directoreis and filenames\n",
    "        path_TIF = os.path.join(d_paths['path_Mdl'], 'PoP', 'In', R['package'], R['MdlN'], os.path.basename(re.sub(r'\\.idf$', '.tif', R['path'], flags=re.IGNORECASE)))  # Full path to TIF file\n",
    "        os.makedirs(os.path.dirname(path_TIF), exist_ok=True) # Make sure the directory exists\n",
    "\n",
    "        ## Build a dictionary mapping each band’s name to its row’s metadata.\n",
    "        d_MtDt = {f\"{R['parameter']}_L{R['layer']}_{R['MdlN']}\" : {('origin_path' if col == 'path' else col): str(val) for col, val in R.items()}}\n",
    "\n",
    "        DA = imod.formats.idf.open(R['path'], pattern=f'{{name}}_{Mdl}').sel(x=slice(Xmin, Xmax), y=slice(Ymax, Ymin))\n",
    "        # Utl.DA_to_TIF(DA.squeeze(drop=True), path_TIF, d_MtDt) # .squeeze cause 2D arrays have extra dimension with size 1 sometimes.\n",
    "        print(f'\\u2713 - IDF converted to TIF - single-band without L attribute')\n",
    "    except Exception as e:\n",
    "        print(f\"\\u274C - Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R['path']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1. WEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_WEL = DF.loc[DF['package']=='WEL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, R in DF_WEL.iloc[3:6].iterrows():\n",
    "    print(f\"\\t{os.path.basename(R['path']):<30} ... \", end='\\n')\n",
    "\n",
    "    try:\n",
    "        DF_IPF = imod.formats.ipf.read(R['path'])\n",
    "        DF_IPF = DF_IPF.loc[ ( (DF_IPF['x']>Xmin) & (DF_IPF['x']<Xmax ) ) &\n",
    "                            ( (DF_IPF['y']>Ymin) & (DF_IPF['y']<Ymax ) )].copy() # Slice to OBS within the Mdl Aa\n",
    "        \n",
    "        if ('q_m3' in DF_IPF.columns) and ('id' not in DF_IPF.columns):\n",
    "            DF_IPF.rename(columns={'q_m3':'id'}, inplace=True) # One of the IPF files has q_m3 instead of id in it's fields. Don't ask me why, but it has to be dealt with.\n",
    "\n",
    "        #666 I'll only save the average flow now\n",
    "        DF_IPF_AVG = DF_IPF.groupby('id')[DF_IPF.select_dtypes(include=np.number).columns].agg(np.mean)\n",
    "        _GDF_AVG = gpd.GeoDataFrame(DF_IPF_AVG, geometry=gpd.points_from_xy(DF_IPF_AVG['x'], DF_IPF_AVG['y'])).set_crs(crs=Utl.crs)\n",
    "\n",
    "        path_GPKG = os.path.join(d_paths['path_Mdl'], 'PoP', 'In', R['package'], R['MdlN'], os.path.basename(re.sub(r'\\.ipf$', '.gpkg', R['path'], flags=re.IGNORECASE)))  # Full path to TIF file    os.makedirs(os.path.dirname(path_GPKG), exist_ok=True) # Make sure the directory exists\n",
    "        _GDF_AVG.to_file(path_GPKG, driver=\"GPKG\") #, layer=os.path.basename(path_GPKG))\n",
    "        print(f'\\u2713 - IPF average values (per id) converted to GPKG')\n",
    "    except:\n",
    "        print('\\u274C')\n",
    "\n",
    "print(f' --- Success! ---')\n",
    "print(f' {\"-\"*100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2. CHD --- TBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -1 Junkyard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0.1. extra (MetaSWAP files to be copied) Pkg needs to be read separetely cause of its unique format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: # Deactiated for now. Extra files are .inp, which is not a specific format. I'd have to process them individually, so I'm skipping this for now.\n",
    "    DF.drop('EXTRA', inplace=True) # Drop the \"failed to read package\" row, as we're going to read it now.\n",
    "    Pkg_name = 'extra'\n",
    "    Pkg = d_PRJ[Pkg_name]\n",
    "\n",
    "    l_paths = [str(i[0]) for i in Pkg['paths']]\n",
    "    for path in l_paths:\n",
    "        Par = path.split('/')[-3]\n",
    "\n",
    "        Ln_DF_path = {\"package\": Pkg_name, \"parameter\": Par, 'path': path, 'active': True} \n",
    "        DF.loc[f'{Pkg_name.upper()}_{Par}'] = Ln_DF_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
