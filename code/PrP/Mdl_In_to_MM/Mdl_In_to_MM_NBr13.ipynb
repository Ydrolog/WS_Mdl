{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:24px; font-family:'Roboto'; font-weight:bold;\">\n",
    "Script to visualize iMOD inputs in QGIS.\n",
    "</span><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m************************************************** Mdl_In_to_mm **************************************************\u001b[0m\n",
      "This script converts model inputs (mainly IDF) to TIF files, to be visualized in QGIS. It also calculates some parameters from Mdl Ins (e.g.) Aquifer layer thickness is calculated from TOP-BOT (same as MF does internally).\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\033[1m{'*'*50} Mdl_In_to_mm {'*'*50}\\033[0m\")\n",
    "print('This script converts model inputs (mainly IDF) to TIF files, to be visualized in QGIS. It also calculates some parameters from Mdl Ins (e.g.) Aquifer layer thickness is calculated from TOP-BOT (same as MF does internally).')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.0. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from WS_Mdl import utils as U\n",
    "from WS_Mdl import geo as G\n",
    "from WS_Mdl import utils_imod as UIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'WS_Mdl.utils_imod' from 'c:\\\\users\\\\karam014\\\\onedrive - universiteit utrecht\\\\ws_mdl\\\\code\\\\WS_Mdl\\\\utils_imod.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(G)\n",
    "importlib.reload(U)\n",
    "importlib.reload(UIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1. Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MdlN = 'NBr13'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. PoP In\n",
    "Also makes replace.csv for S QGIS project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.PRJ_to_TIF(MdlN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Make new MM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.Up_MM(MdlN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. PoP Out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0. GXG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.0.1. Write TIF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.HD_IDF_GXG_to_MBTIF(MdlN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.HD_IDF_GXG_to_MBTIF('NBr12')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.0.1 Calculate differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rasterio\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_paths = U.get_MdlN_paths(MdlN)\n",
    "MdlN_B, path_PoP, path_MdlN, path_PoP_Out_MdlN, path_PoP_Out_MdlN_B = [ d_paths[v] for v in ['MdlN_B', 'path_PoP', 'path_MdlN', 'path_PoP_Out_MdlN', 'path_PoP_Out_MdlN_B'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_GXG = os.path.join(path_PoP_Out_MdlN, 'GXG')\n",
    "path_GXG_B = path_GXG.replace (MdlN, MdlN_B)\n",
    "path_GXG_SmB = os.path.join(path_PoP_Out_MdlN, 'GXG_SmB')\n",
    "os.makedirs(path_GXG_SmB, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_path_S = [os.path.join(path_GXG, p) for p in sorted(os.listdir(path_GXG), key=lambda f: int(f.split('_')[1][1:]))]\n",
    "l_path_B = [x.replace(MdlN, MdlN_B) for x in l_path_S]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p_S, p_B in zip(l_path_S, l_path_B):\n",
    "    # print(f_S, f_B, '-'*50, sep='\\n')\n",
    "    with rasterio.open(p_S) as f_S, rasterio.open(p_B) as f_B:\n",
    "        assert f_S.count == f_B.count, f\"Different number of bands:\\n{p_S}:\\t{f_S.count}\\n{p_B}:\\t{f_B.count}\"\n",
    "        assert f_S.width == f_B.width and f_S.height == f_B.height, f\"Image dimensions must match:\\n{p_S}:\\t{f_S.width}x{f_S.height}\\n{p_B}:\\t{f_B.width}x{f_B.height}\"\n",
    "\n",
    "        profile = f_S.profile  # Use metadata from the first file\n",
    "        profile.update(dtype=rasterio.float32)  # Ensure output can handle differences (including negatives)\n",
    "\n",
    "        path_Out = os.path.join(path_GXG_SmB, os.path.basename(p_S).replace(MdlN, f\"{MdlN}_m_{MdlN_B}\"))\n",
    "        print(path_Out)\n",
    "\n",
    "        with rasterio.open(path_Out, 'w', **profile) as dst:\n",
    "            for i in range(f_S.count):\n",
    "                d_S = f_S.read(i + 1).astype(np.float32)\n",
    "                d_B = f_B.read(i + 1).astype(np.float32)\n",
    "                dst.write(d_S - d_B, i + 1)\n",
    "\n",
    "            tags_S = f_S.tags()\n",
    "            tags_B = f_B.tags()\n",
    "            combined_tags = {**{f\"S_{k}\": v for k, v in tags_S.items()},\n",
    "                             **{f\"B_{k}\": v for k, v in tags_B.items()}}\n",
    "            dst.update_tags(**combined_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Other PoP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from pathlib import Path\n",
    "import imod\n",
    "N_cores = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_rules = \"(L == 1)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… - NBr13 paths extracted from RunLog and returned as dictionary with keys:\n",
      "Mdl, MdlN_B, path_Mdl, path_INI, path_BAT, path_PRJ, path_Smk, path_MdlN, path_Out_HD, path_PoP, path_PoP_Out_MdlN, path_MM, path_INI_B, path_BAT_B, path_PRJ_B, path_Smk_B, path_MdlN_B, path_Out_HD_B, path_PoP_Out_MdlN_B, path_MM_B\n"
     ]
    }
   ],
   "source": [
    "# Get paths\n",
    "d_paths = U.get_MdlN_paths(MdlN)\n",
    "path_PoP, path_MdlN = [ d_paths[v] for v in ['path_PoP', 'path_MdlN'] ]\n",
    "path_HD = os.path.join(path_MdlN, 'GWF_1/MODELOUTPUT/HEAD/HEAD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = U.HD_Out_IDF_to_DF(path_HD) # Read the IDF files to a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DF_rules is not None:\n",
    "    DF = DF.query(DF_rules)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of layers in the model\n",
    "l_L = sorted({int(match.group(1)) for f in Path(path_HD).glob(\"HEAD_*.IDF\")\n",
    "            if (match := re.compile(r\"_L(\\d+)\\.IDF$\").search(f.name))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dictionary of the IDF files for each layer\n",
    "d_IDF_GXG = {i: sorted(f for f in Path(path_HD).glob(f\"HEAD_*_L{i}.IDF\")\n",
    "                    if re.search(r'HEAD_(\\d{4})(\\d{2})(\\d{2})', f.name)\n",
    "                    and int((m := re.search(r'HEAD_(\\d{4})(\\d{2})(\\d{2})', f.name)).group(3)) in {14, 28})\n",
    "            for i in l_L}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if N_cores is None:\n",
    "    N_cores = max(os.cpu_count() - 2, 1)\n",
    "start = DT.now() # Start time\n",
    "\n",
    "start = DT.now()\n",
    "with PPE(max_workers=N_cores) as E:\n",
    "    futures = [E.submit(_HD_IDF_GXG_to_MBTIF_process_L, L, d_IDF_GXG, MdlN, path_PoP, path_HD, crs)\n",
    "                for L in d_IDF_GXG.keys()]\n",
    "    for f in futures:\n",
    "        print('\\t', f.result(), '- Elapsed time (from start):', DT.now() - start)\n",
    "\n",
    "print('Total elapsed:', DT.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _HD_IDF_GXG_to_MBTIF_process_L(L, d_IDF_GXG, MdlN, path_PoP, path_HD, crs):\n",
    "    \"\"\"Only for use within HD_IDF_GXG_to_MBTIF - to utilize multiprocessing.\"\"\"\n",
    "    XA = imod.idf.open(d_IDF_GXG[L])\n",
    "    GXG = imod.evaluate.calculate_gxg(XA.squeeze())\n",
    "    GXG = GXG.rename_vars({var: var.upper() for var in GXG.data_vars})\n",
    "    GXG = GXG.rename_vars({'N_YEARS_GXG': 'N_years_GXG', 'N_YEARS_GVG': 'N_years_GVG'})\n",
    "    GXG[\"GHG_m_GLG\"] = GXG[\"GHG\"] - GXG[\"GLG\"]\n",
    "    GXG = GXG[[\"GHG\", \"GLG\", \"GHG_m_GLG\", \"GVG\", \"N_years_GXG\", \"N_years_GVG\"]]\n",
    "\n",
    "    path_Out = os.path.join(path_PoP, 'Out', MdlN, 'GXG', f'GXG_L{L}_{MdlN}.tif')\n",
    "    os.makedirs(os.path.dirname(path_Out), exist_ok=True)\n",
    "\n",
    "    d_MtDt = {str(i+1): {f'{var}_AVG': float(GXG[var].mean().values) for var in GXG.data_vars} \n",
    "              for i in range(len(GXG.data_vars))}\n",
    "    \n",
    "    d_MtDt['all'] = {'parameters': XA.coords,\n",
    "                     'Description': f'{MdlN} GXG (path: {path_HD})\\nFor more info see: https://deltares.github.io/imod-python/api/generated/evaluate/imod.evaluate.calculate_gxg.html'}\n",
    "\n",
    "    # Set proper band names and write to MBTIF\n",
    "    band_names = [f\"{var}_{MdlN}\" for var in GXG.data_vars]\n",
    "    DA = GXG.to_array(dim=\"band\").astype(np.float32)\n",
    "    DA[\"band\"] = band_names\n",
    "    DA_to_MBTIF(DA, path_Out, d_MtDt, crs=crs, _print=False)\n",
    "    return f\"GXG_L{L} âœ”\"\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
