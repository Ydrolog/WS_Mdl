{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:24px; font-family:'Roboto'; font-weight:bold;\">\n",
    "Script to visualize iMOD inputs in QGIS.\n",
    "</span><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m************************************************** Mdl_In_to_mm **************************************************\u001b[0m\n",
      "This script converts model inputs (mainly IDF) to TIF files, to be visualized in QGIS. It also calculates some parameters from Mdl Ins (e.g.) Aquifer layer thickness is calculated from TOP-BOT (same as MF does internally).\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\033[1m{'*'*50} Mdl_In_to_mm {'*'*50}\\033[0m\")\n",
    "print('This script converts model inputs (mainly IDF) to TIF files, to be visualized in QGIS. It also calculates some parameters from Mdl Ins (e.g.) Aquifer layer thickness is calculated from TOP-BOT (same as MF does internally).')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.0. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import WS_Mdl as WS # import functions defined for WS_Mdl (by me)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os",
	"from os import listdir as LD, makedirs as MDs",
	"from os.path import join as PJ, basename as PBN, dirname as PDN, exists as PE \n",
    "import imod\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "import numpy as np\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1. Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MdlN = 'NBr5'\n",
    "Mdl = ''.join([c for c in MdlN if not c.isdigit()])\n",
    "t_Pa_replace = ('C:\\\\Users\\\\Karam014\\\\AppData', r'C:\\OD\\WS_Mdl\\models\\NBr') # For some reason imod.idf.read reads the path incorrectly, so I have to replace the incorrect part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_Pa = WS.get_MdlN_paths(MdlN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Read INI file to get model size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xmin, Ymin, Xmax, Ymax, cellsize, N_R, N_C = WS.Mdl_Dmns_from_INI(d_Pa['INI'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Read PRJ to a DF, so that it's easy to review and process each In file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0. Fill DF with Info from d_PRJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_PRJ, OBS = WS.read_PRJ_with_OBS(d_Pa['PRJ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['package', 'parameter','time', 'active', 'is_constant', 'layer', 'factor', 'addition', 'constant', 'path']\n",
    "DF = pd.DataFrame(columns=columns) # Main DF to store all the packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0.0 Process most packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --- Reading PRJ Packages into DF ---\n",
      "\t(cap)  \t...\tâœ“\n",
      "\textra  \t...\tðŸ”´\n",
      "\t(bnd)  \t...\tâœ“\n",
      "\t(top)  \t...\tâœ“\n",
      "\t(bot)  \t...\tâœ“\n",
      "\t(khv)  \t...\tâœ“\n",
      "\t(kva)  \t...\tâœ“\n",
      "\t(shd)  \t...\tâœ“\n",
      "\t(sto)  \t...\tâœ“\n",
      "\t(spy)  \t...\tâœ“\n",
      "\t(hfb)  \t...\tâœ“\n",
      "\t(drn)  \t...\tâœ“\n",
      "\t(riv)  \t...\tâœ“\n",
      "\t(wel)  \t...\tâœ“\n",
      "\t(pcg)  \t...\tðŸ”´\n",
      "\t(chd)  \t...\tâœ“\n",
      "\tperiods\t...\tðŸ”´\n",
      "\tspecies\t...\tðŸ”´\n",
      " --- Success! ---\n",
      " ----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(f' --- Reading PRJ Packages into DF ---')\n",
    "for Pkg_name in list(d_PRJ.keys()): # Iterate over packages\n",
    "    print(f\"\\t{Pkg_name:<7}\\t...\\t\", end='')\n",
    "    try:\n",
    "        Pkg = d_PRJ[Pkg_name]\n",
    "\n",
    "        if int(Pkg['active']): # if the package is active, process it\n",
    "            l_Par = [k for k in Pkg.keys() if k not in {'active', 'n_system', 'time'}] # Make list from package keys/parameters\n",
    "            for Par in l_Par[:]: # Iterate over parameters\n",
    "\n",
    "                for N, L in enumerate(Pkg[Par]): # differentiate between packages (have time) and modules.\n",
    "                    Ln_DF_path = {**L, \"package\": Pkg_name, \"parameter\": Par} #, 'Pa_type':L['path'].suffix.lower()} #, \"metadata\": L}\n",
    "                    \n",
    "                    if ('time' in d_PRJ[Pkg_name].keys()):\n",
    "                        if (Pkg['n_system'] > 1):\n",
    "                            DF.loc[f'{Pkg_name.upper()}_{Par}_Sys{(N)%Pkg['n_system']+1}_{L['time']}'] = Ln_DF_path\n",
    "                        elif (Pkg['n_system']==1):\n",
    "                            DF.loc[f\"{Pkg_name.upper()}_{Par}\"] = Ln_DF_path\n",
    "                    else:\n",
    "                        if (Pkg['n_system'] > 1):\n",
    "                            DF.loc[f'{Pkg_name.upper()}_{Par}_Sys{(N)%Pkg['n_system']+1}'] = Ln_DF_path\n",
    "                        elif (Pkg['n_system']==1):\n",
    "                            DF.loc[f\"{Pkg_name.upper()}_{Par}\"] = Ln_DF_path\n",
    "            print('\ðŸŸ¢')\n",
    "        else:\n",
    "            print(f'\\u2012 the package is innactive.')\n",
    "    except:\n",
    "        DF.loc[f'{Pkg_name.upper()}'] = \"-\"\n",
    "        DF.loc[f'{Pkg_name.upper()}', 'active'] = 'Failed to read package'\n",
    "        print('\\u274C')\n",
    "print(f' --- Success! ---')\n",
    "print(f' {\"-\"*100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0.1. extra (MetaSWAP files to be copied) Pkg needs to be read separetely cause of its unique format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: # Deactiated for now. Extra files are .inp, which is not a specific format. I'd have to process them individually, so I'm skipping this for now.\n",
    "    DF.drop('EXTRA', inplace=True) # Drop the \"failed to read package\" row, as we're going to read it now.\n",
    "    Pkg_name = 'extra'\n",
    "    Pkg = d_PRJ[Pkg_name]\n",
    "\n",
    "    l_paths = [str(i[0]) for i in Pkg['paths']]\n",
    "    for path in l_paths:\n",
    "        Par = path.split('/')[-3]\n",
    "\n",
    "        Ln_DF_path = {\"package\": Pkg_name, \"parameter\": Par, 'path': path, 'active': True} \n",
    "        DF.loc[f'{Pkg_name.upper()}_{Par}'] = Ln_DF_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Edit DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF['package'] = DF['package'].str.replace('(',\"\").str.replace(')','').str.upper()\n",
    "DF['suffix'] = DF['path'].apply(lambda x: x.suffix.lower() if hasattr(x, 'suffix') else \"-\")  # Check if 'suffix' exists # Make suffix column so that paths can be categorized\n",
    "DF['path'] = DF['path'].astype('string') # Convert path to string so that the wrong part of the path can be .replace()ed\n",
    "DF['MdlN'] = DF['path'].str.split(\"_\").str[-1].str.split('.').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: # Deactiated for now. Extra files are .inp, which is not a specific format. I'd have to process them individually, so I'm skipping this for now.\n",
    "    DF.loc[DF['package'] == 'EXTRA', 'path'] = DF.loc[DF['package'] == 'EXTRA', 'path'].apply(lambda x: os.path.abspath(PJ(d_Pa['PRJ'], x)))\n",
    "    DF.loc[ DF['package']=='EXTRA', 'MdlN'] = DF.loc[ DF['package']=='EXTRA', 'path'].apply(lambda x: re.split(r\"[\\\\/]\", str(x))[-2])\n",
    "    DF.loc[ DF['package']=='EXTRA', 'suffix'] = DF.loc[ DF['package']=='EXTRA', 'path'].apply(lambda x: str(x).split(\".\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF['path'] = DF['path'].str.replace(*t_Pa_replace, regex=False) # Replace incorrect part of paths. I'm not sure why iMOD doesn't read them right. Maybe cause they're relative it's assumed they start form a directory which is incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = DF.loc[:, list(DF.columns[:2]) + ['MdlN'] + list(DF.columns[2:-3]) + ['suffix', DF.columns[-3]]] # Rearrange columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF.to_csv('DF.csv') # Enable if you want to review the DF in Excel\n",
    "# DF.to_excel('DF.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Process Regular, Time Independent IDF Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select rows to be converted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_Rgu = DF[ ( DF[\"time\"].isna()   ) &\n",
    "                 ( DF['path'].notna()  ) & # Non time packages have NaN in 'time' Fld. Failed packages have '-', so they'll also be excluded. \n",
    "                 ( DF['suffix']=='.idf')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --- Converting time-independant package IDF files to TIF ---\n",
      "\tboundary                       ... âœ“ - single-band with L attribute\n",
      "\tlanduse                        ... âœ“ - single-band without L attribute\n",
      "\trootzone_thickness             ... âœ“ - single-band without L attribute\n",
      "\tsoil_physical_unit             ... âœ“ - single-band without L attribute\n",
      "\tmeteo_station_number           ... âœ“ - single-band with L attribute\n",
      "\tsurface_elevation              ... âœ“ - single-band without L attribute\n",
      "\tartificial_recharge            ... âœ“ - single-band without L attribute\n",
      "\tartificial_recharge_layer      ... âœ“ - single-band without L attribute\n",
      "\twetted_area                    ... âœ“ - single-band without L attribute\n",
      "\turban_area                     ... âœ“ - single-band without L attribute\n",
      "\tibound                         ... âœ“ - single-band with L attribute\n",
      "\ttop                            ... âœ“ - multi-band\n",
      "\tbottom                         ... âœ“ - multi-band\n",
      "\tkh                             ... âœ“ - multi-band\n",
      "\thead                           ... âœ“ - multi-band\n",
      " --- Success! ---\n",
      " ----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(f' --- Converting time-independant package IDF files to TIF ---')\n",
    "for Par in DF_Rgu['parameter'].unique()[:]:\n",
    "    print(f\"\\t{Par:<30} ... \", end='')\n",
    "\n",
    "    try:\n",
    "        DF_Par = DF_Rgu[DF_Rgu['parameter']==Par] # Slice DF_Rgu for current parameter.\n",
    "        DF_Par = DF_Par.drop_duplicates(subset='path', keep='first') # Drop duplicates, keep the first one. imod.formats.idf.open will do that with the list of paths anyway, so the only way to match the paths to the correct metadata is to have only one path per metadata.\n",
    "        if DF_Par['package'].nunique() > 1:\n",
    "            print(\"There are multiple packages for the same parameter. Check DF_Rgu.\")\n",
    "            break\n",
    "        else:\n",
    "            Pkg = DF_Par['package'].iloc[0] # Get the package name\n",
    "\n",
    "        ## Prepare directoreis and filenames\n",
    "        Pkg_MdlN = Mdl + str(DF_Par['MdlN'].str.extract(r'(\\d+)').astype(int).max().values[0])\n",
    "        Pa_TIF = PJ(d_Pa['Pa_Mdl'], 'PoP', 'In', Pkg, Pkg_MdlN, f\"{Pkg}_{Par}_{Pkg_MdlN}.tif\")  # Full path to TIF file\n",
    "        MDs(PDN(Pa_TIF), exist_ok=True) # Make sure the directory exists\n",
    "\n",
    "        ## Build a dictionary mapping each bandâ€™s name to its rowâ€™s metadata. We're assuming that the order the paths are read into DA is the same as the order in DF_Par.\n",
    "        d_MtDt = {}\n",
    "        for i, R in DF_Par.iterrows():\n",
    "            d_MtDt[f\"{R['parameter']}_L{R['layer']}_{R['MdlN']}\"] = {('origin_path' if col == 'path' else col): str(val) for col, val in R.items()}\n",
    "\n",
    "        ## Read files-paths to xarray Data Array (DA), then write them to TIF file(s).\n",
    "        if DF_Par.shape[0] > 1: # If there are multiple paths for the same parameter\n",
    "            DA = imod.formats.idf.open(list(DF_Par['path']), pattern=\"{name}_L{layer}_\").sel(x=slice(Xmin, Xmax), y=slice(Ymax, Ymin))\n",
    "            WS.DA_to_MBTIF(DA, Pa_TIF, d_MtDt)\n",
    "            print(f'\ðŸŸ¢ - multi-band')\n",
    "        else:\n",
    "            try:\n",
    "                DA = imod.formats.idf.open(list(DF_Par['path']), pattern=\"{name}_L{layer}_\").sel(x=slice(Xmin, Xmax), y=slice(Ymax, Ymin))\n",
    "                WS.DA_to_TIF(DA.squeeze(drop=True), Pa_TIF, d_MtDt) # .squeeze cause 2D arrays have extra dimension with size 1 sometimes.\n",
    "                print(f'\ðŸŸ¢ - single-band with L attribute')\n",
    "            except:\n",
    "                DA = imod.formats.idf.open(list(DF_Par['path']), pattern=\"{name}_\").sel(x=slice(Xmin, Xmax), y=slice(Ymax, Ymin))\n",
    "                WS.DA_to_TIF(DA.squeeze(drop=True), Pa_TIF, d_MtDt) # .squeeze cause 2D arrays have extra dimension with size 1 sometimes.\n",
    "                print(f'\ðŸŸ¢ - single-band without L attribute')\n",
    "    except:\n",
    "        print('\\u274C')\n",
    "print(f' --- Success! ---')\n",
    "print(f' {\"-\"*100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Calculated Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_Clc_In = {} # Dictionary to store calculated inputs. We'll make use of that "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0. Layer Thickness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "DA_TOP = imod.formats.idf.open(list(DF_Rgu[DF_Rgu['parameter']=='top']['path']), pattern=\"{name}_L{layer}_\").sel(x=slice(Xmin, Xmax), y=slice(Ymax, Ymin))\n",
    "DA_BOT = imod.formats.idf.open(list(DF_Rgu[DF_Rgu['parameter']=='bottom']['path']), pattern=\"{name}_L{layer}_\").sel(x=slice(Xmin, Xmax), y=slice(Ymax, Ymin))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0.0 TOP-BOT QA\n",
    "Check if the bot of each layer is the same as the top of the layer below, to QA the Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "DA_TOP_below = DA_TOP.sel(layer=slice(2, None)).assign_coords(layer=DA_TOP.layer.sel(layer=slice(2, None)) - 1)\n",
    "DA_BOT_1to36 = DA_BOT.sel(layer=slice(1, 36))\n",
    "DA_TOP_BOT_Cmp = DA_BOT_1to36 - DA_TOP_below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_BOT_Cmp_Min = DA_TOP_BOT_Cmp.min(dim=[\"x\", \"y\"])  # Replace with your spatial dims\n",
    "TOP_BOT_Cmp_Max = DA_TOP_BOT_Cmp.max(dim=[\"x\", \"y\"])\n",
    "TOP_BOT_Cmp_Abs = DA_TOP_BOT_Cmp.reduce(np.abs).max(dim=[\"x\", \"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.True_"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_TOP_BOT_Cmp = pd.DataFrame({\"Layer\": TOP_BOT_Cmp_Min.layer.values,  # Extract layer values\n",
    "                               \"Min Difference\": TOP_BOT_Cmp_Min.values,\n",
    "                               \"Max Difference\": TOP_BOT_Cmp_Max.values,\n",
    "                               \"Abs Difference\": TOP_BOT_Cmp_Abs.values})\n",
    "DF_TOP_BOT_Cmp.values.all()==0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bingo! Let's continue with the calcs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0.1. Calculate Thk and fill dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "DA_Thk = (DA_TOP - DA_BOT).squeeze(drop=True) # Let's make a dictionary to store Info about each parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>package</th>\n",
       "      <th>parameter</th>\n",
       "      <th>MdlN</th>\n",
       "      <th>time</th>\n",
       "      <th>active</th>\n",
       "      <th>is_constant</th>\n",
       "      <th>layer</th>\n",
       "      <th>factor</th>\n",
       "      <th>addition</th>\n",
       "      <th>constant</th>\n",
       "      <th>suffix</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(CAP)_boundary</th>\n",
       "      <td>CAP</td>\n",
       "      <td>boundary</td>\n",
       "      <td>NBr1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>.idf</td>\n",
       "      <td>C:\\OD\\WS_Mdl\\models\\NBr\\In\\BND\\BND_L1_NBr1.IDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(CAP)_landuse</th>\n",
       "      <td>CAP</td>\n",
       "      <td>landuse</td>\n",
       "      <td>NBr1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000000000000000000.0</td>\n",
       "      <td>.idf</td>\n",
       "      <td>C:\\OD\\WS_Mdl\\models\\NBr\\In\\CAP\\LGN\\LGN_NBr1.idf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(CAP)_rootzone_thickness</th>\n",
       "      <td>CAP</td>\n",
       "      <td>rootzone_thickness</td>\n",
       "      <td>NBr1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000000000000000000.0</td>\n",
       "      <td>.idf</td>\n",
       "      <td>C:\\OD\\WS_Mdl\\models\\NBr\\In\\CAP\\RZN\\RZN_NBr1.idf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(CAP)_soil_physical_unit</th>\n",
       "      <td>CAP</td>\n",
       "      <td>soil_physical_unit</td>\n",
       "      <td>NBr1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000000000000000000.0</td>\n",
       "      <td>.idf</td>\n",
       "      <td>C:\\OD\\WS_Mdl\\models\\NBr\\In\\CAP\\SFU\\SFU_NBr1.idf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(CAP)_meteo_station_number</th>\n",
       "      <td>CAP</td>\n",
       "      <td>meteo_station_number</td>\n",
       "      <td>NBr1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>.idf</td>\n",
       "      <td>C:\\OD\\WS_Mdl\\models\\NBr\\In\\BND\\BND_L1_NBr1.IDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(SHD)_head_Sys33</th>\n",
       "      <td>SHD</td>\n",
       "      <td>head</td>\n",
       "      <td>NBr1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.99</td>\n",
       "      <td>.idf</td>\n",
       "      <td>C:\\OD\\WS_Mdl\\models\\NBr\\In\\SHD\\SHD_L17_NBr1.idf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(SHD)_head_Sys34</th>\n",
       "      <td>SHD</td>\n",
       "      <td>head</td>\n",
       "      <td>NBr1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.99</td>\n",
       "      <td>.idf</td>\n",
       "      <td>C:\\OD\\WS_Mdl\\models\\NBr\\In\\SHD\\SHD_L17_NBr1.idf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(SHD)_head_Sys35</th>\n",
       "      <td>SHD</td>\n",
       "      <td>head</td>\n",
       "      <td>NBr1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.99</td>\n",
       "      <td>.idf</td>\n",
       "      <td>C:\\OD\\WS_Mdl\\models\\NBr\\In\\SHD\\SHD_L18_NBr1.idf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(SHD)_head_Sys36</th>\n",
       "      <td>SHD</td>\n",
       "      <td>head</td>\n",
       "      <td>NBr1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.99</td>\n",
       "      <td>.idf</td>\n",
       "      <td>C:\\OD\\WS_Mdl\\models\\NBr\\In\\SHD\\SHD_L18_NBr1.idf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(SHD)_head_Sys37</th>\n",
       "      <td>SHD</td>\n",
       "      <td>head</td>\n",
       "      <td>NBr1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.99</td>\n",
       "      <td>.idf</td>\n",
       "      <td>C:\\OD\\WS_Mdl\\models\\NBr\\In\\SHD\\SHD_L19_NBr1.idf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           package             parameter  MdlN time active  \\\n",
       "(CAP)_boundary                 CAP              boundary  NBr1  NaN   True   \n",
       "(CAP)_landuse                  CAP               landuse  NBr1  NaN   True   \n",
       "(CAP)_rootzone_thickness       CAP    rootzone_thickness  NBr1  NaN   True   \n",
       "(CAP)_soil_physical_unit       CAP    soil_physical_unit  NBr1  NaN   True   \n",
       "(CAP)_meteo_station_number     CAP  meteo_station_number  NBr1  NaN   True   \n",
       "...                            ...                   ...   ...  ...    ...   \n",
       "(SHD)_head_Sys33               SHD                  head  NBr1  NaN   True   \n",
       "(SHD)_head_Sys34               SHD                  head  NBr1  NaN   True   \n",
       "(SHD)_head_Sys35               SHD                  head  NBr1  NaN   True   \n",
       "(SHD)_head_Sys36               SHD                  head  NBr1  NaN   True   \n",
       "(SHD)_head_Sys37               SHD                  head  NBr1  NaN   True   \n",
       "\n",
       "                           is_constant layer factor addition  \\\n",
       "(CAP)_boundary                       2     1    1.0      0.0   \n",
       "(CAP)_landuse                        2     1    1.0      0.0   \n",
       "(CAP)_rootzone_thickness             2     1    1.0      0.0   \n",
       "(CAP)_soil_physical_unit             2     1    1.0      0.0   \n",
       "(CAP)_meteo_station_number           2     1    1.0      0.0   \n",
       "...                                ...   ...    ...      ...   \n",
       "(SHD)_head_Sys33                     2    33    1.0      0.0   \n",
       "(SHD)_head_Sys34                     2    34    1.0      0.0   \n",
       "(SHD)_head_Sys35                     2    35    1.0      0.0   \n",
       "(SHD)_head_Sys36                     2    36    1.0      0.0   \n",
       "(SHD)_head_Sys37                     2    37    1.0      0.0   \n",
       "\n",
       "                                           constant suffix  \\\n",
       "(CAP)_boundary                              -9999.0   .idf   \n",
       "(CAP)_landuse               100000000000000000000.0   .idf   \n",
       "(CAP)_rootzone_thickness    100000000000000000000.0   .idf   \n",
       "(CAP)_soil_physical_unit    100000000000000000000.0   .idf   \n",
       "(CAP)_meteo_station_number                  -9999.0   .idf   \n",
       "...                                             ...    ...   \n",
       "(SHD)_head_Sys33                            -999.99   .idf   \n",
       "(SHD)_head_Sys34                            -999.99   .idf   \n",
       "(SHD)_head_Sys35                            -999.99   .idf   \n",
       "(SHD)_head_Sys36                            -999.99   .idf   \n",
       "(SHD)_head_Sys37                            -999.99   .idf   \n",
       "\n",
       "                                                                       path  \n",
       "(CAP)_boundary               C:\\OD\\WS_Mdl\\models\\NBr\\In\\BND\\BND_L1_NBr1.IDF  \n",
       "(CAP)_landuse               C:\\OD\\WS_Mdl\\models\\NBr\\In\\CAP\\LGN\\LGN_NBr1.idf  \n",
       "(CAP)_rootzone_thickness    C:\\OD\\WS_Mdl\\models\\NBr\\In\\CAP\\RZN\\RZN_NBr1.idf  \n",
       "(CAP)_soil_physical_unit    C:\\OD\\WS_Mdl\\models\\NBr\\In\\CAP\\SFU\\SFU_NBr1.idf  \n",
       "(CAP)_meteo_station_number   C:\\OD\\WS_Mdl\\models\\NBr\\In\\BND\\BND_L1_NBr1.IDF  \n",
       "...                                                                     ...  \n",
       "(SHD)_head_Sys33            C:\\OD\\WS_Mdl\\models\\NBr\\In\\SHD\\SHD_L17_NBr1.idf  \n",
       "(SHD)_head_Sys34            C:\\OD\\WS_Mdl\\models\\NBr\\In\\SHD\\SHD_L17_NBr1.idf  \n",
       "(SHD)_head_Sys35            C:\\OD\\WS_Mdl\\models\\NBr\\In\\SHD\\SHD_L18_NBr1.idf  \n",
       "(SHD)_head_Sys36            C:\\OD\\WS_Mdl\\models\\NBr\\In\\SHD\\SHD_L18_NBr1.idf  \n",
       "(SHD)_head_Sys37            C:\\OD\\WS_Mdl\\models\\NBr\\In\\SHD\\SHD_L19_NBr1.idf  \n",
       "\n",
       "[195 rows x 12 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_Rgu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_Clc_In['Thk'] = {'Par': 'thickness',\n",
    "                   'DA': DA_Thk,\n",
    "                   'MdlN': Mdl + str(max(DF_Rgu.loc[DF_Rgu['package'].isin(['TOP', 'BOT']), 'MdlN'].str.extract(r'(\\d+)')[0])), #666 the largest number from the TOP and BOT MdlNs \n",
    "                   'MtDt': {**{f\"thickness_L{i+1}\": {\"layer\": f\"L{i+1}\"} for i in range(DA_Thk.shape[0])},  # Per-layer metadata\n",
    "                            \"all\": {\"description\": \"Layer thickness calculated as 'top - bottom' per layer.\",\n",
    "                                    \"source_files\": f\"\"\"{'-'*200}TOP: {' '*30} {\" | | \".join(DF_Rgu.loc[DF_Rgu['package'] == 'TOP', 'path'])} {'-'*200}\n",
    "                                                        BOT: {' '*30} {\" | | \".join(DF_Rgu.loc[DF_Rgu['package'] == 'BOT', 'path'])} \"\"\"}}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Transmissivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "DA_Kh = imod.formats.idf.open(list(DF_Rgu[DF_Rgu['parameter']=='kh']['path']), pattern=\"{name}_L{layer}_\").sel(x=slice(Xmin, Xmax), y=slice(Ymax, Ymin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "DA_T = DA_Thk * DA_Kh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_Clc_In['T'] = {'Par': 'transmissivity',\n",
    "                  'DA': DA_T,\n",
    "                  'MdlN': Mdl + (max(DF_Rgu.loc[DF_Rgu['package'].isin(['TOP', 'BOT', 'NPF']), 'MdlN'].str.extract(r'(\\d+)')[0])), #666 the largest number from the TOP and BOT MdlNs                   \n",
    "                  'MtDt': {**{f\"transmissivity_L{i+1}\": {\"layer\": f\"L{i+1}\"} for i in range(DA_Thk.shape[0])},  # Per-layer metadata\n",
    "                           \"all\": {\"description\": \"Layer transmissivity (horizontal) calculated as '(top - bottom)*Kh' per layer.\",\n",
    "                                   \"source_files\": f\"\"\"{'-'*200}TOP: {' '*30} {\" | | \".join(DF_Rgu.loc[DF_Rgu['package'] == 'TOP', 'path'])} \n",
    "                                                       {'-'*200}BOT: {' '*30} {\" | | \".join(DF_Rgu.loc[DF_Rgu['package'] == 'BOT', 'path'])}\n",
    "                                                       {'-'*200}NPF: {' '*30} {\" | | \".join(DF_Rgu.loc[DF_Rgu['package'] == 'NPF', 'path'])}\"\"\"}}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Save calculated inputs to TIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --- Converting calculated inputs to TIF ---\n",
      "\tthickness                      ... âœ“ - multi-band\n",
      "\ttransmissivity                 ... âœ“ - multi-band\n",
      " --- Success! ---\n",
      " ----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(f' --- Converting calculated inputs to TIF ---')\n",
    "for Par in d_Clc_In.keys():\n",
    "    print(f\"\\t{d_Clc_In[Par]['Par']:<30} ... \", end='')\n",
    "\n",
    "    try:\n",
    "        # Prepare directoreis and filenames\n",
    "        Pa_TIF = PJ(d_Pa['Pa_Mdl'], 'PoP', 'Clc_In', Par, d_Clc_In[Par]['MdlN'], f\"{Par}_{d_Clc_In[Par]['MdlN']}.tif\")  # Full path to TIF file #666 need to think which MdlN to use. It's hard to do the same as with the other packages.\n",
    "        MDs(PDN(Pa_TIF), exist_ok=True) # Make sure the directory exists\n",
    "\n",
    "        ## Write DAs to TIF files.\n",
    "        DA = d_Clc_In[Par]['DA'].squeeze(drop=True)\n",
    "        d_MtDt = d_Clc_In[Par]['MtDt']\n",
    "\n",
    "        if not DA.rio.crs: # Ensure DA_Thk has a CRS (if missing, set it)\n",
    "            DA.rio.write_crs(WS.crs, inplace=True)  # Replace with correct CRS\n",
    "\n",
    "        if len(DA.shape) == 3: # If there are multiple paths for the same parameter\n",
    "            WS.DA_to_MBTIF(DA, Pa_TIF, d_MtDt)\n",
    "            print(f'\ðŸŸ¢ - multi-band')\n",
    "        elif len(DA.shape) == 2:\n",
    "            WS.DA_to_TIF(DA.squeeze(drop=True), Pa_TIF, d_MtDt) # .squeeze cause 2D arrays have extra dimension with size 1 sometimes.\n",
    "            print(f'\ðŸŸ¢ - single-band')\n",
    "    except:\n",
    "        print('\\u274C')\n",
    "print(f' --- Success! ---')\n",
    "print(f' {\"-\"*100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Time dependent packages\n",
    "Those will have to be processed 1 by 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\OD\\WS_Mdl\\models\\NBr\\In\\DRN\\DRN_Cond_buis_NBr1.IDF\n",
      "C:\\OD\\WS_Mdl\\models\\NBr\\In\\RIV\\RIV_Cond_DETAILWATERGANGEN_NBr1.IDF\n",
      "C:\\OD\\WS_Mdl\\models\\NBr\\In\\WEL\\WEL_Ind_Aa_and_Maas_SS_NBr1.ipf\n",
      "C:\\OD\\WS_Mdl\\models\\NBr\\In\\CHD\\NBr5\\head_20100114_L1_NBr5.idf\n"
     ]
    }
   ],
   "source": [
    "for Pkg in DF.loc[ (DF[\"time\"].notna()) & (DF['time']!='-'), 'package'].unique():\n",
    "    print(DF.loc[ DF['package']==Pkg, 'path'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_time = DF[ ( DF[\"time\"].notna() ) &\n",
    "              ( DF[\"time\"]!='-'    ) &\n",
    "              ( DF['path'].notna() )] # Non time packages have NaN in 'time' Fld. Failed packages have '-', so they'll also be excluded. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.0. DRN & RIV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --- Converting time dependant packages ---\n",
      "\tDRN_conductance                ... âœ“ - IDF converted to TIF - single-band without L attribute\n",
      "\tDRN_conductance                ... âœ“ - IDF converted to TIF - single-band without L attribute\n",
      "\tDRN_conductance                ... âœ“ - IDF converted to TIF - single-band without L attribute\n",
      "\tDRN_conductance                ... âœ“ - IDF converted to TIF - single-band without L attribute\n",
      "\tDRN_conductance                ... âœ“ - IDF converted to TIF - single-band without L attribute\n",
      "\tDRN_conductance                ... âœ“ - IDF converted to TIF - single-band without L attribute\n",
      "\tDRN_elevation                  ... âœ“ - IDF converted to TIF - single-band without L attribute\n",
      "\tDRN_elevation                  ... âœ“ - IDF converted to TIF - single-band without L attribute\n",
      "\tDRN_elevation                  ... âœ“ - IDF converted to TIF - single-band without L attribute\n",
      "\tDRN_elevation                  ... âœ“ - IDF converted to TIF - single-band without L attribute\n",
      "\tDRN_elevation                  ... âœ“ - IDF converted to TIF - single-band without L attribute\n",
      "\tDRN_elevation                  ... âœ“ - IDF converted to TIF - single-band without L attribute\n",
      "\tRIV_conductance                ... âœ“ - IDF converted to TIF - single-band without L attribute\n",
      "\tRIV_conductance                ... âœ“ - IDF converted to TIF - single-band without L attribute\n",
      "\tRIV_conductance                ... âœ“ - IDF converted to TIF - single-band without L attribute\n",
      "\tRIV_conductance                ... âœ“ - IDF converted to TIF - single-band without L attribute\n",
      "\tRIV_conductance                ... âœ“ - IDF converted to TIF - single-band without L attribute\n",
      "\tRIV_conductance                ... âœ“ - IDF converted to TIF - single-band without L attribute\n",
      "\tRIV_conductance                ... âœ“ - IDF converted to TIF - single-band without L attribute\n",
      "\tRIV_conductance                ... âœ“ - IDF converted to TIF - single-band without L attribute\n",
      "\tRIV_conductance                ... âœ“ - IDF converted to TIF - single-band without L attribute\n",
      "\tRIV_conductance                ... âœ“ - IDF converted to TIF - single-band without L attribute\n",
      "\tRIV_conductance                ... âœ“ - IDF converted to TIF - single-band without L attribute\n",
      "\tRIV_conductance                ... âœ“ - IDF converted to TIF - single-band without L attribute\n",
      "\tRIV_conductance                ... âœ“ - IDF converted to TIF - single-band without L attribute\n",
      "\tRIV_conductance                ... âœ“ - IDF converted to TIF - single-band without L attribute\n",
      "\tRIV_conductance                ... âœ“ - IDF converted to TIF - single-band without L attribute\n",
      "\tRIV_stage                      ... âœ“ - IDF converted to TIF - single-band without L attribute\n",
      "\tRIV_stage                      ... âœ“ - IDF converted to TIF - single-band without L attribute\n",
      "\tRIV_stage                      ... âœ“ - IDF converted to TIF - single-band without L attribute\n",
      "\tRIV_stage                      ... âœ“ - IDF converted to TIF - single-band without L attribute\n",
      "\tRIV_stage                      ... âœ“ - IDF converted to TIF - single-band without L attribute\n",
      "\tRIV_stage                      ... âœ“ - IDF converted to TIF - single-band without L attribute\n",
      "\tRIV_stage                      ... âœ“ - IDF converted to TIF - single-band without L attribute\n",
      "\tRIV_stage                      ... âœ“ - IDF converted to TIF - single-band without L attribute\n",
      "\tRIV_stage                      ... âœ“ - IDF converted to TIF - single-band without L attribute\n",
      "\tRIV_stage                      ... âœ“ - IDF converted to TIF - single-band without L attribute\n",
      "\tRIV_stage                      ... âœ“ - IDF converted to TIF - single-band without L attribute\n",
      "\tRIV_stage                      ... âœ“ - IDF converted to TIF - single-band without L attribute\n",
      "\tRIV_stage                      ... âœ“ - IDF converted to TIF - single-band without L attribute\n",
      "\tRIV_stage                      ... âœ“ - IDF converted to TIF - single-band without L attribute\n",
      "\tRIV_stage                      ... âœ“ - IDF converted to TIF - single-band without L attribute\n",
      "\tRIV_bottom_elevation           ... âœ“ - IDF converted to TIF - single-band without L attribute\n",
      "\tRIV_bottom_elevation           ... âœ“ - IDF converted to TIF - single-band without L attribute\n",
      "\tRIV_bottom_elevation           ... âœ“ - IDF converted to TIF - single-band without L attribute\n",
      "\tRIV_bottom_elevation           ... âœ“ - IDF converted to TIF - single-band without L attribute\n",
      "\tRIV_bottom_elevation           ... âœ“ - IDF converted to TIF - single-band without L attribute\n",
      "\tRIV_bottom_elevation           ... âœ“ - IDF converted to TIF - single-band without L attribute\n",
      "\tRIV_bottom_elevation           ... âœ“ - IDF converted to TIF - single-band without L attribute\n",
      "\tRIV_bottom_elevation           ... âœ“ - IDF converted to TIF - single-band without L attribute\n",
      "\tRIV_bottom_elevation           ... âœ“ - IDF converted to TIF - single-band without L attribute\n",
      "\tRIV_bottom_elevation           ... âœ“ - IDF converted to TIF - single-band without L attribute\n",
      "\tRIV_bottom_elevation           ... âœ“ - IDF converted to TIF - single-band without L attribute\n",
      "\tRIV_bottom_elevation           ... âœ“ - IDF converted to TIF - single-band without L attribute\n",
      "\tRIV_bottom_elevation           ... âœ“ - IDF converted to TIF - single-band without L attribute\n",
      "\tRIV_bottom_elevation           ... âœ“ - IDF converted to TIF - single-band without L attribute\n",
      "\tRIV_bottom_elevation           ... âœ“ - IDF converted to TIF - single-band without L attribute\n"
     ]
    }
   ],
   "source": [
    "print(f' --- Converting time dependant packages ---')\n",
    "for i, R in DF_time[DF_time['package'].isin(('DRN', 'RIV'))].iterrows():\n",
    "    print(f\"\\t{f\"{R['package']}_{R['parameter']}\":<30} ... \", end='')\n",
    "    \n",
    "    try:    \n",
    "        ## Prepare directoreis and filenames\n",
    "        Pa_TIF = PJ(d_Pa['Pa_Mdl'], 'PoP', 'In', R['package'], R['MdlN'], PBN(re.sub(r'\\.idf$', '.tif', R['path'], flags=re.IGNORECASE)))  # Full path to TIF file\n",
    "        MDs(PDN(Pa_TIF), exist_ok=True) # Make sure the directory exists\n",
    "\n",
    "        ## Build a dictionary mapping each bandâ€™s name to its rowâ€™s metadata.\n",
    "        d_MtDt = {f\"{R['parameter']}_L{R['layer']}_{R['MdlN']}\" : {('origin_path' if col == 'path' else col): str(val) for col, val in R.items()}}\n",
    "\n",
    "        DA = imod.formats.idf.open(R['path'], pattern=f'{{name}}_{Mdl}').sel(x=slice(Xmin, Xmax), y=slice(Ymax, Ymin))\n",
    "        WS.DA_to_TIF(DA.squeeze(drop=True), Pa_TIF, d_MtDt) # .squeeze cause 2D arrays have extra dimension with size 1 sometimes.\n",
    "        print(f'\ðŸŸ¢ - IDF converted to TIF - single-band without L attribute')\n",
    "    except:\n",
    "        print('\\u274C')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1. WEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_WEL = DF.loc[DF['package']=='WEL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tWEL_Ind_Aa_and_Maas_T_NBr1.ipf ... \n",
      "âœ“ - IPF average values (per id) converted to GPKG\n",
      "\tWEL_Ind_Br_T_NBr1.ipf          ... \n",
      "âœ“ - IPF average values (per id) converted to GPKG\n",
      "\tWEL_Br_Wa_T_NBr1.ipf           ... \n",
      "âœ“ - IPF average values (per id) converted to GPKG\n",
      " --- Success! ---\n",
      " ----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i, R in DF_WEL.iloc[3:6].iterrows():\n",
    "    print(f\"\\t{PBN(R['path']):<30} ... \", end='\\n')\n",
    "\n",
    "    try:\n",
    "        DF_IPF = imod.formats.ipf.read(R['path'])\n",
    "        DF_IPF = DF_IPF.loc[ ( (DF_IPF['x']>Xmin) & (DF_IPF['x']<Xmax ) ) &\n",
    "                            ( (DF_IPF['y']>Ymin) & (DF_IPF['y']<Ymax ) )].copy() # Slice to OBS within the Mdl Aa\n",
    "        \n",
    "        if ('q_m3' in DF_IPF.columns) and ('id' not in DF_IPF.columns):\n",
    "            DF_IPF.rename(columns={'q_m3':'id'}, inplace=True) # One of the IPF files has q_m3 instead of id in it's fields. Don't ask me why, but it has to be dealt with.\n",
    "\n",
    "        #666 I'll only save the average flow now\n",
    "        DF_IPF_AVG = DF_IPF.groupby('id')[DF_IPF.select_dtypes(include=np.number).columns].agg(np.mean)\n",
    "        _GDF_AVG = gpd.GeoDataFrame(DF_IPF_AVG, geometry=gpd.points_from_xy(DF_IPF_AVG['x'], DF_IPF_AVG['y'])).set_crs(crs=WS.crs)\n",
    "\n",
    "        Pa_GPKG = PJ(d_Pa['Pa_Mdl'], 'PoP', 'In', R['package'], R['MdlN'], PBN(re.sub(r'\\.ipf$', '.gpkg', R['path'], flags=re.IGNORECASE)))  # Full path to TIF file    MDs(PDN(Pa_GPKG), exist_ok=True) # Make sure the directory exists\n",
    "        _GDF_AVG.to_file(Pa_GPKG, driver=\"GPKG\") #, layer=PBN(Pa_GPKG))\n",
    "        print(f'\ðŸŸ¢ - IPF average values (per id) converted to GPKG')\n",
    "    except:\n",
    "        print('\\u274C')\n",
    "\n",
    "print(f' --- Success! ---')\n",
    "print(f' {\"-\"*100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2. CHD --- TBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -2. Constant parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -1. Junkyard\n",
    "Collection of code that may potentially be useful in the future. Converted to Markdown, so that it doesn't get executed by accident."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with open('explore_d_PRJ.txt', 'w') as f:\n",
    "    for Pkg in list(d_PRJ.keys()): # Iterate through packages\n",
    "        f.write(f\"{Pkg} --- {type(d_PRJ[Pkg])}\\n\")\n",
    "\n",
    "        if 'active' in d_PRJ[Pkg].keys(): # If the key active doesn't exist in the d (like in time and species Pkgs)\n",
    "            if d_PRJ[Pkg]['active'] and d_Pkg_Instr[Pkg]: # If the package is active and the instruction is True in the instruction dictionary\n",
    "                f.write(f\"\\t{d_PRJ[Pkg].keys()} -- {type(d_PRJ[Pkg])}\\n\")\n",
    "\n",
    "                if 'time' in d_PRJ[Pkg].keys(): # 666 Time packages are a bit more complex. Let me do the others first.\n",
    "                    True\n",
    "                else: # If there is no time component\n",
    "                    True\n",
    "                    # for Par in [i for i in d_PRJ[Pkg].keys() if i not in ['n_system', 'active']]: # n_system and active don't need to be printed\n",
    "                    #     print(f'  - {d_PRJ[Pkg][Par]['path']}')     \n",
    "        else:\n",
    "            f.write(\"\\t\\u274C 'active' not in Pkg parameters\\n\")\n",
    "        f.write(f'{\"-\"*150}')\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. CAP\n",
    "Pkg_name = '(cap)'\n",
    "Pkg = d_PRJ[Pkg_name]\n",
    "l_Par = [i for i in Pkg.keys()]\n",
    "active, n_system = Pkg['active'], Pkg['n_system']\n",
    "l_Par.remove('active'), l_Par.remove('n_system')\n",
    "for Par in l_Par:\n",
    "    print(Par, type(Pkg[Par]))\n",
    "    # print(Pkg[Par])\n",
    "\n",
    "    d_Pa = {} # I'm only making 1 d for all the files as I'm assuming they'll all be the same file-type for a Parameter. The key: value == L: parameter value.\n",
    "    for N, L in enumerate(Pkg[Par]):\n",
    "        print(L)\n",
    "        if ('path' in L):\n",
    "            path = Path(str(L['path']).replace(*t_Pa_replace))\n",
    "            print(f\"\\t{path}\")\n",
    "            print(f\"\\t{PBN(L['path'])}\")\n",
    "            # d_Pa[f'L{N}'] = \n",
    "\n",
    "            if Pkg['n_system'] > 1:\n",
    "                DF_paths.loc[f'{Pkg_name.upper()}_{Par}_L{Pkg['n_system']}'] = L\n",
    "            elif Pkg['n_system']==1:\n",
    "                DF_paths.loc[f'{Pkg_name.upper()}_{Par}'] = L\n",
    "\n",
    "    \n",
    "    print('------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with open('explore_d_PRJ.txt', 'w') as f:\n",
    "    for Pkg_name in list(d_PRJ.keys())[:]: # Iterate over packages\n",
    "        try:\n",
    "            f.write(f'{Pkg_name}\\n')\n",
    "            Pkg = d_PRJ[Pkg_name]\n",
    "\n",
    "            l_Par = list(set(Pkg.keys()) - {'active', 'n_system'}) # Make list from package keys/parameters\n",
    "            # active, n_system = Pkg['active'], Pkg['n_system']\n",
    "            for Par in l_Par[:]: # Iterate over packages\n",
    "                f.write(f\"\\t{Par}, {type(Pkg[Par])}\\n\")\n",
    "                # f.write(Pkg[Par])\n",
    "\n",
    "                d_Pa = {} # I'm only making 1 d for all the files as I'm assuming they'll all be the same file-type for a Parameter. The key: value == L: parameter value.\n",
    "                for N, L in enumerate(Pkg[Par]):\n",
    "                    f.write(f'\\t\\t{L}\\n')\n",
    "                    if ('path' in L) and Pkg['active']:\n",
    "                        path = Path(str(L['path']).replace(*t_Pa_replace))\n",
    "                        f.write(f\"\\t\\t{path}\\n\")\n",
    "                        f.write(f\"\\t\\t{PBN(L['path'])}\\n\")\n",
    "                        # d_Pa[f'L{N}'] = \n",
    "\n",
    "                        Ln_DF_path = {**L, \"package\": Pkg_name, \"parameter\": Par, 'Pa_type':L['path'].suffix.lower()} #, \"metadata\": L}\n",
    "                        if ('time' in d_PRJ[Pkg_name].keys()):\n",
    "                            N_times = len(d_PRJ[Pkg_name]['time'])\n",
    "\n",
    "                            if (Pkg['n_system'] > 1):\n",
    "                                DF.loc[f'{Pkg_name.upper()}_{Par}_L{(N)%N_times+1}_{L['time']}'] = Ln_DF_path\n",
    "                            elif (Pkg['n_system']==1):\n",
    "                                DF.loc[f\"{Pkg_name.upper()}_{Par}_L{(N)%N_times+1}\"] = Ln_DF_path\n",
    "                        else:\n",
    "                            if (Pkg['n_system'] > 1):\n",
    "                                DF.loc[f'{Pkg_name.upper()}_{Par}_L{N+1}'] = Ln_DF_path\n",
    "\n",
    "                            elif (Pkg['n_system']==1):\n",
    "                                DF.loc[f\"{Pkg_name.upper()}_{Par}\"] = Ln_DF_path\n",
    "                    else:\n",
    "                        print(f'\\t{Pkg}_{Par} failed. Either path not in L or Pkg not active.')\n",
    "\n",
    "            print(Pkg_name)\n",
    "        except:\n",
    "            DF_failed.loc[f'{Pkg_name.upper()}'] = \"-\"    \n",
    "            print('Exception', Pkg_name)\n",
    "                \n",
    "        f.write(f'{\"-\"*100}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d_Pkg_Instr = {\"(cap)\": True, \n",
    "               \"extra\": True,\n",
    "               \"(bnd)\": True,\n",
    "               \"(top)\": True,\n",
    "               \"(bot)\": True,\n",
    "               \"(khv)\": True,\n",
    "               \"(kva)\": True,\n",
    "               \"(shd)\": True,\n",
    "               \"(sto)\": True,\n",
    "               \"(spy)\": True,\n",
    "               \"(hfb)\": True,\n",
    "               \"(drn)\": True,\n",
    "               \"(riv)\": True,\n",
    "               \"(wel)\": True,\n",
    "               \"(pcg)\": True,\n",
    "               \"(chd)\": True,\n",
    "               \"periods\": True,\n",
    "               \"species\": True} # Defines the way the packages will be processed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
