{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:24px; font-family:'Roboto'; font-weight:bold;\">\n",
    "Script to PoP iMOD Sim HD outputs\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're advised to run the notebook cells one by one to understand what they're doing and avoid any problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os
from os import listdir as LD, makedirs as MDs
from os.path import join as PJ, basename as PBN, dirname as PDN, exists as PE\n",
    "import shutil\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 200)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import openpyxl as xl\n",
    "import imod\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.transform import from_bounds\n",
    "from shapely.geometry import shape\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_DF_IDF(path_Fo, S_Fi_IDF):\n",
    "    \"\"\" Reads all .IDF Fis listed in a S_Fi_IDF into DF['IDF']. Returns the DF containing Fi_names and the IDF contents.\n",
    "        path_Fo is the path of the Fo where th files are stored in.\"\"\"\n",
    "\n",
    "    DF = pd.DataFrame({'Fi_name': S_Fi_IDF, 'IDF': None})\n",
    "\n",
    "    for i, Fi in tqdm(DF['Fi_name'].items(), desc=\"Processing .IDF files\", total=len(DF['Fi_name'])):\n",
    "        if Fi.endswith('.IDF'):  # Ensure only .IDF files are processed\n",
    "            try:    # Read the .IDF file into an xA DataA\n",
    "                DF.at[i, 'IDF'] = imod.idf.read( PJ(path_Fo, Fi) )\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {Fi}: {e}\")\n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def A_to_Raster_n_IDF(A, IDF_MtDt, path_Out, field='HD_L1', crs=\"EPSG:4326\"):\n",
    "    # 1. Write a GeoTIFF raster with rasterio\n",
    "    nrows, ncols = A.shape\n",
    "\n",
    "    transform = from_bounds(\n",
    "        west=IDF_MtDt['xmin'],\n",
    "        south=IDF_MtDt['ymin'],\n",
    "        east=IDF_MtDt['xmax'],\n",
    "        north=IDF_MtDt['ymax'],\n",
    "        width=ncols,\n",
    "        height=nrows)\n",
    "\n",
    "    meta = {\n",
    "        \"driver\": \"GTiff\",\n",
    "        \"height\": nrows,\n",
    "        \"width\": ncols,\n",
    "        \"count\": 1,\n",
    "        \"dtype\": str(A.dtype),\n",
    "        \"crs\": crs,        # use your known CRS here\n",
    "        \"transform\": transform,\n",
    "    }\n",
    "\n",
    "    tif_path = path_Out + \".tif\"\n",
    "    with rasterio.open(tif_path, \"w\", **meta) as dst:\n",
    "        dst.write(A, 1)  # Write band 1\n",
    "    print(f\"{tif_path} has been saved (GeoTIFF).\")\n",
    "\n",
    "    # 2. Write the same data as an iMOD IDF\n",
    "    #    Create xarray DataArray with spatial coords\n",
    "    x = IDF_MtDt['xmin'] + IDF_MtDt['dx'] * (0.5 + np.arange(ncols))\n",
    "    # Common convention is top-to-bottom descending:\n",
    "    # but if your 'ymax' < 'ymin', you'll invert accordingly.\n",
    "    y = IDF_MtDt['ymax'] - IDF_MtDt['dy'] * (0.5 + np.arange(nrows))\n",
    "\n",
    "    DA = xr.DataArray(A, coords={\"y\": y, \"x\": x}, dims=[\"y\", \"x\"], name=field)\n",
    "\n",
    "    # Write the IDF\n",
    "    idf_path = path_Out + \".idf\"\n",
    "    imod.idf.write(idf_path, DA)\n",
    "    print(f\"{idf_path} has been saved (iMOD IDF).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block can be replaced with a configuration excel spreadsheet that will be read as a DF.\n",
    "I think it's preferable to have a working script first, then convert it to functions and a shorter main script, that's why I'm not using the Cfg s/s o the get go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mdl = 'NBr'\n",
    "SimN_B = 2\n",
    "SimN_S = 3\n",
    "SmB = True\n",
    "day_start = 20180101\n",
    "day_end = 20181231"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_Mo_winter = [10, 11, 12, 1, 2, 3]\n",
    "l_Mo_summer = [i for i in range(1,13) if i not in l_Mo_winter]\n",
    "l_layers = ['L1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_base = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_Sim = rf'../../../models/{Mdl}/Sim'\n",
    "path_PoP = rf'../../../models/{Mdl}/PoP'\n",
    "path_B = PJ(path_Sim, f'{Mdl}{SimN_B}/GWF_1/MODELOUTPUT/HEAD/HEAD')\n",
    "path_S = PJ(path_Sim, f'{Mdl}{SimN_S}/GWF_1/MODELOUTPUT/HEAD/HEAD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_Fi_B = pd.Series([i for i in LD(path_B) if i.split('.')[0].split('_')[-1] in l_layers])\n",
    "S_Fi_S = pd.Series([i for i in LD(path_S) if i.split('.')[0].split('_')[-1] in l_layers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_Fi_B_Mo = S_Fi_B.str.split(\"_\").str[1].str[4:6].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load IDF's and calculate AVGs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing .IDF files: 100%|██████████| 365/365 [00:09<00:00, 39.60it/s]\n"
     ]
    }
   ],
   "source": [
    "DF_IDF_B = make_DF_IDF(path_B, S_Fi_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_B_AVG = np.mean(np.stack(DF_IDF_B['IDF'].apply(lambda x: x[0])), axis=0)\n",
    "A_B_AVG_summer = np.mean(np.stack(DF_IDF_B.loc[ S_Fi_B_Mo.isin(l_Mo_summer), 'IDF'].apply(lambda x: x[0])), axis=0)\n",
    "A_B_AVG_winter = np.mean(np.stack(DF_IDF_B.loc[ S_Fi_B_Mo.isin(l_Mo_winter), 'IDF'].apply(lambda x: x[0])), axis=0)\n",
    "d_A_B_AVG = {'full_year': A_B_AVG,\n",
    "             'summer': A_B_AVG_summer,\n",
    "             'winter': A_B_AVG_winter}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDF_MtDt = DF_IDF_B.at[0, 'IDF'][1] # The metadata for all IDF's is the same, except for time. But time doesn't matter for what we'll do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../models/NBr/PoP\\HD_map\\NBr2\\HD_NBr2..tif has been saved (GeoTIFF).\n",
      "../../../models/NBr/PoP\\HD_map\\NBr2\\HD_NBr2..idf has been saved (iMOD IDF).\n",
      "../../../models/NBr/PoP\\HD_map\\NBr2\\HD_summer_NBr2..tif has been saved (GeoTIFF).\n",
      "../../../models/NBr/PoP\\HD_map\\NBr2\\HD_summer_NBr2..idf has been saved (iMOD IDF).\n",
      "../../../models/NBr/PoP\\HD_map\\NBr2\\HD_winter_NBr2..tif has been saved (GeoTIFF).\n",
      "../../../models/NBr/PoP\\HD_map\\NBr2\\HD_winter_NBr2..idf has been saved (iMOD IDF).\n"
     ]
    }
   ],
   "source": [
    "for k in d_A_B_AVG:\n",
    "    group = '' if k=='full_year' else (k+'_')\n",
    "    path_Out = PJ(path_PoP, 'HD_map', f'{Mdl}{SimN_B}', f'HD_{group}{Mdl}{SimN_B}.')\n",
    "    MDs(PDN(path_Out), exist_ok=True)\n",
    "    A_to_Raster_n_IDF(d_A_B_AVG[k], IDF_MtDt, path_Out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'path_S' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m DF_IDF_S \u001b[38;5;241m=\u001b[39m make_DF_IDF(\u001b[43mpath_S\u001b[49m, S_Fi_S)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'path_S' is not defined"
     ]
    }
   ],
   "source": [
    "DF_IDF_S = make_DF_IDF(path_S, S_Fi_S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_S_AVG = np.mean(np.stack(DF_IDF_S['IDF'].apply(lambda x: x[0])), axis=0)\n",
    "A_S_AVG_summer = np.mean(np.stack(DF_IDF_S.loc[ S_Fi_S_Mo.isin(l_Mo_summer), 'IDF'].apply(lambda x: x[0])), axis=0)\n",
    "A_S_AVG_winter = np.mean(np.stack(DF_IDF_S.loc[ S_Fi_S_Mo.isin(l_Mo_winter), 'IDF'].apply(lambda x: x[0])), axis=0)\n",
    "d_A_S_AVG = {'full_year': A_S_AVG,\n",
    "             'summer': A_S_AVG_summer,\n",
    "             'winter': A_S_AVG_winter}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDF_MtDt = DF_IDF_S.at[0, 'IDF'][1] # The metadata for all IDF's is the same, except for time. But time doesn't matter for what we'll do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../models/NBr/PoP\\HD_map\\NBr2\\HD_NBr2..tif has been saved (GeoTIFF).\n",
      "../../../models/NBr/PoP\\HD_map\\NBr2\\HD_NBr2..idf has been saved (iMOD IDF).\n",
      "../../../models/NBr/PoP\\HD_map\\NBr2\\HD_summer_NBr2..tif has been saved (GeoTIFF).\n",
      "../../../models/NBr/PoP\\HD_map\\NBr2\\HD_summer_NBr2..idf has been saved (iMOD IDF).\n",
      "../../../models/NBr/PoP\\HD_map\\NBr2\\HD_winter_NBr2..tif has been saved (GeoTIFF).\n",
      "../../../models/NBr/PoP\\HD_map\\NBr2\\HD_winter_NBr2..idf has been saved (iMOD IDF).\n"
     ]
    }
   ],
   "source": [
    "for k in d_A_S_AVG:\n",
    "    group = '' if k=='full_year' else (k+'_')\n",
    "    path_Out = PJ(path_PoP, 'HD_map', f'{Mdl}{SimN_S}', f'HD_{group}{Mdl}{SimN_S}.')\n",
    "    MDs(PDN(path_Out), exist_ok=True)\n",
    "    A_to_Raster_n_IDF(d_A_S_AVG[k], IDF_MtDt, path_Out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
