{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5088444",
   "metadata": {},
   "source": [
    "# *** Compare SFR stages Vs RIV stages ***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995c4916",
   "metadata": {},
   "source": [
    "## 0.0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cdbd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import WS_Mdl.utils as U\n",
    "import WS_Mdl.utils_imod as UIM\n",
    "import WS_Mdl.calcs as C\n",
    "import WS_Mdl.geo as G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe104c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import importlib as IL\n",
    "# IL.reload(U)\n",
    "# IL.reload(UIM)\n",
    "# IL.reload(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81b0924",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir as LD, makedirs as MDs\n",
    "from os.path import join as PJ, basename as PBN, dirname as PDN, exists as PE\n",
    "import shutil as sh\n",
    "import pandas as pd\n",
    "from datetime import datetime as DT\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca6e21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from itables import init_notebook_mode\n",
    "# init_notebook_mode(all_interactive=True)\n",
    "# import contextlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b789b34",
   "metadata": {},
   "source": [
    "## 0.1. Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2201f84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MdlN = 'NBr40'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da68110",
   "metadata": {},
   "outputs": [],
   "source": [
    "U.set_verbose(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8464b2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load paths and variables from PRJ & INI\n",
    "d_Pa = U.get_MdlN_Pa(MdlN)\n",
    "Pa_PRJ = d_Pa['PRJ']\n",
    "Dir_PRJ = PDN(Pa_PRJ)\n",
    "d_INI = U.INI_to_d(d_Pa['INI'])\n",
    "Xmin, Ymin, Xmax, Ymax, cellsize, N_R, N_C = U.Mdl_Dmns_from_INI(d_Pa['INI'])\n",
    "SP_date_1st, SP_date_last = [DT.strftime(DT.strptime(d_INI[f'{i}'], '%Y%m%d'), '%Y-%m-%d') for i in ['SDATE', 'EDATE']]\n",
    "dx = dy = float(d_INI['CELLSIZE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314b442a",
   "metadata": {},
   "outputs": [],
   "source": [
    "U.Mdl_Dmns_from_INI(d_Pa['INI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e3095d",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_X_Y_Cols = ['Xstart', 'Ystart', 'Xend', 'Yend']\n",
    "l_Circ_IDs = [6561, 8788, 18348]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b4a7f7",
   "metadata": {},
   "source": [
    "# 1. Load Model Ins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b323952",
   "metadata": {},
   "source": [
    "## 1.0. Load PRJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2fc3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRJ_, PRJ_OBS = UIM.o_PRJ_with_OBS(Pa_PRJ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0960a113",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRJ, period_data = PRJ_[0], PRJ_[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cfe111",
   "metadata": {},
   "source": [
    "## 1.1. Load DIS and limit to Mdl Aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347d651b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRJ_regrid = UIM.regrid_PRJ(PRJ, MdlN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02039dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "BND = PRJ_regrid['bnd']['ibound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068608ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set outer boundaries to -1 (for CHD)\n",
    "\n",
    "# Get the coordinate indices for boundaries\n",
    "y_coords = BND.y\n",
    "x_coords = BND.x\n",
    "first_y = y_coords.isel(y=0)  # First y coordinate\n",
    "last_y = y_coords.isel(y=-1)  # Last y coordinate  \n",
    "first_x = x_coords.isel(x=0)  # First x coordinate\n",
    "last_x = x_coords.isel(x=-1)  # Last x coordinate\n",
    "\n",
    "# Set boundary values using .loc indexing\n",
    "BND.loc[:, first_y, :] = -1  # Top row (all layers, first y, all x)\n",
    "BND.loc[:, last_y, :] = -1   # Bottom row (all layers, last y, all x)\n",
    "BND.loc[:, :, first_x] = -1  # Left column (all layers, all y, first x)  \n",
    "BND.loc[:, :, last_x] = -1   # Right column (all layers, all y, last x)\n",
    "\n",
    "print(\"âœ… Boundary conditions set successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31569d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "BND.isel(layer=0, x=range(0,10), y=range(0,10)).plot.imshow(cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deed1ee2",
   "metadata": {},
   "source": [
    "## 1.2. Load MF6 Mdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51582fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = pd.date_range(SP_date_1st, SP_date_last, freq='D')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48aef4a2",
   "metadata": {},
   "source": [
    "Using original PRJ to load MF6 Mdl gives warnings (and it's very slow). Thus, well use the regridded PRJ, which is much faster. It can be further sped up by multi-processing, but this is not implemented yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5357ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sim_MF6 = mf6.Modflow6Simulation.from_imod5_data(PRJ_regrid, period_data, times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744a96ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "MF6_Mdl = Sim_MF6['imported_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875d5c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "MF6_Mdl[\"oc\"] = mf6.OutputControl(save_head=\"last\", save_budget=\"last\")\n",
    "Sim_MF6[\"ims\"] = UIM.mf6_solution_moderate_settings() # Mimic iMOD5's \"Moderate\" settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7b7fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "MF6_DIS = MF6_Mdl[\"dis\"]  # This gets the OLD 100m grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402356eb",
   "metadata": {},
   "source": [
    "## 1.3. Load MSW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696a3097",
   "metadata": {},
   "source": [
    "### 1.3.0. Fix mete_grid.inp relative paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05c28be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the mete_grid.inp path in the PRJ_MSW_for_MSW dictionary\n",
    "PRJ['extra']['paths'][2][0] = UIM.mete_grid_Cvt_to_AbsPa(Pa_PRJ, PRJ_regrid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808649bd",
   "metadata": {},
   "source": [
    "### 1.3.2. Finally load MSW Sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9cc8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the MetaSwap model\n",
    "PRJ_MSW = {'cap': PRJ_regrid.copy()['cap'], 'extra': PRJ_regrid.copy()['extra']}\n",
    "MSW_Mdl = msw.MetaSwapModel.from_imod5_data(PRJ_MSW, MF6_DIS, times)\n",
    "print(\"ðŸŸ¢ - MetaSwap model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0555966b",
   "metadata": {},
   "source": [
    "## 1.4. Connect MF6 to MetaSWAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a467f1",
   "metadata": {},
   "source": [
    "### 1.4.1. Clip models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd64d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sim_MF6_AoI = Sim_MF6.clip_box(x_min=Xmin, x_max=Xmax, y_min=Ymin, y_max=Ymax)\n",
    "MF6_Mdl_AoI = Sim_MF6_AoI['imported_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d176a143",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSW_Mdl_AoI = MSW_Mdl.clip_box(x_min=Xmin, x_max=Xmax, y_min=Ymin, y_max=Ymax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d4565c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MF6 Model AoI DIS shape: {MF6_Mdl_AoI['dis'].dataset.sizes}\")\n",
    "print(f\"MSW Model AoI grid shape: {MSW_Mdl_AoI['grid'].dataset.sizes}\")\n",
    "print(\"âœ… Both models successfully clipped to Area of Interest with compatible discretization!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176414e0",
   "metadata": {},
   "source": [
    "## 1.5. Load & Cleanup models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ada8c7",
   "metadata": {},
   "source": [
    "### 1.5.0. Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c914df",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pkg in MF6_Mdl_AoI.values():\n",
    "    pkg.dataset.load()\n",
    "\n",
    "for pkg in MSW_Mdl_AoI.values():\n",
    "    pkg.dataset.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2cb255",
   "metadata": {},
   "source": [
    "### 1.5.1. MF6 mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5d3b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mask from current regridded model (not the old one)\n",
    "mask = MF6_Mdl_AoI.domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71be718e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix CHD package layer ordering issue (layers must be monotonically increasing)\n",
    "from imod.mf6 import ConstantHead\n",
    "chd_pkg = Sim_MF6_AoI['imported_model']['chd_merged']\n",
    "head_data_sorted = chd_pkg.dataset['head'].load().sortby('layer')\n",
    "Sim_MF6_AoI['imported_model']['chd_merged'] = ConstantHead(head=head_data_sorted, validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38983eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sim_MF6_AoI.mask_all_models(mask)\n",
    "DIS_AoI = MF6_Mdl_AoI[\"dis\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcc5538",
   "metadata": {},
   "source": [
    "### 1.5.2. Cleanup MF6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf51b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for Pkg in [i for i in MF6_Mdl_AoI.keys() if ('riv' in i.lower()) or ('drn' in i.lower())]:\n",
    "        MF6_Mdl_AoI[Pkg].cleanup(DIS_AoI)\n",
    "except:\n",
    "    print('Failed to cleanup packages. Proceeding without cleanup. Fingers crossed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c98f3a",
   "metadata": {},
   "source": [
    "### 1.5.3 Cleanup MetaSWAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cca65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSW_Mdl_AoI[\"grid\"].dataset[\"rootzone_depth\"] = MSW_Mdl_AoI[\"grid\"].dataset[\"rootzone_depth\"].fillna(1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39003970",
   "metadata": {},
   "source": [
    "## 1.6. Couple & Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef22db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metamod_coupling = primod.MetaModDriverCoupling(mf6_model=\"imported_model\", mf6_recharge_package=\"msw-rch\", mf6_wel_package=\"msw-sprinkling\")\n",
    "metamod = primod.MetaMod(MSW_Mdl_AoI, Sim_MF6_AoI, coupling_list=[metamod_coupling])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72642cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(d_Pa['Pa_MdlN'], exist_ok=True) # Create simulation directory if it doesn't exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d16ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use correct paths from d_Pa instead of hardcoded paths\n",
    "Pa_MF6_DLL = d_Pa['MF6_DLL']\n",
    "Pa_MSW_DLL = d_Pa['MSW_DLL']\n",
    "Pa_IMC = d_Pa['coupler_Exe']\n",
    "\n",
    "print(f\"âœ… MF6 DLL path: {Pa_MF6_DLL}\")\n",
    "print(f\"âœ… MSW DLL path: {Pa_MSW_DLL}\")\n",
    "print(f\"âœ… Coupler exe path: {d_Pa['coupler_Exe']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112896a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metamod.write(directory=d_Pa['Pa_MdlN'], modflow6_dll=Pa_MF6_DLL, metaswap_dll=Pa_MSW_DLL, metaswap_dll_dependency=PDN(Pa_MF6_DLL))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ccba65",
   "metadata": {},
   "source": [
    "# 2. Create SFR lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbfb348",
   "metadata": {},
   "source": [
    "## 2.1.Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b859ed2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pa_Gpkg = PJ(U.Pa_WS, rf\"g:\\models\\NBr\\PrP\\SFR\\BrabantseDelta\\Gpkg\\WBD_detail_SW_NW_cleaned.gpkg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0339fd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "GDF = gpd.read_file(Pa_Gpkg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82334799",
   "metadata": {},
   "outputs": [],
   "source": [
    "GDF0 = GDF.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca82906",
   "metadata": {},
   "outputs": [],
   "source": [
    "GDF = U.GDF_clip_Mdl_Aa(GDF, d_Pa['INI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affac981",
   "metadata": {},
   "outputs": [],
   "source": [
    "GDF1 = GDF.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0436a4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "GDF1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065f78b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "GDF1.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32182c0",
   "metadata": {},
   "source": [
    "## 2.2 Ensure slope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640fd121",
   "metadata": {},
   "source": [
    "#### Upstream and downstream elevations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685e4e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "GDF[[ 'ID', 'Elv_UStr', 'Elv_DStr']].describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c519cf4",
   "metadata": {},
   "source": [
    "No nulls + the percentiles make sense.ðŸŸ¢<br>\n",
    "Let's make sure the UStr is always higher than the DnStr.<br>\n",
    "Then let's print out some values to check in QGIS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3e1704",
   "metadata": {},
   "outputs": [],
   "source": [
    "(GDF['Elv_UStr'] <= GDF['Elv_DStr']).sum(), (GDF['Elv_UStr'] < GDF['Elv_DStr']).sum(), (GDF['Elv_UStr'] > GDF['Elv_DStr']).sum(), GDF.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfa3bfe",
   "metadata": {},
   "source": [
    "We will assume SFRmaker will work where Elv_UStr >= Elv_DStr, so we'll only adjust those where Elv_UStr < Elv_DStr."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd64cfe",
   "metadata": {},
   "source": [
    "#### Let's print out some CODEs where =, to check in QGIS. *(We don't really need to, I'm just curious)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4caa4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "GDF_Elv = GDF[['ID', 'Elv_UStr', 'Elv_DStr', 'DStr_code', 'DStr_ID']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f340a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "GDF_Elv['Diff'] = GDF_Elv['Elv_UStr'] - GDF_Elv['Elv_DStr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219082c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "GDF_Elv.loc[GDF_Elv['Diff'] == 0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45eb41db",
   "metadata": {},
   "outputs": [],
   "source": [
    "GDF_Elv.loc[ GDF_Elv['Diff'] < 0 ].sort_values(by='Diff', ascending=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a69c8c0",
   "metadata": {},
   "source": [
    "##### Let's see if any of the problematic segments have multiple UStr segments. That would make a solution harder to implement.<br>\n",
    "*(if there is only 1 UStr segment, the DStr Elv of the UStr segment can be modified to allow the UStr Elv of the current segmet to be increased as well, but if there are multiple, this becomes more complicated)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8b3751",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_problematic = GDF_Elv.loc[ GDF_Elv['Diff'] < 0, 'ID'].tolist()\n",
    "for S in l_problematic:\n",
    "    sum = (GDF['DStr_ID']==S).sum()\n",
    "    if sum > 1:\n",
    "        print(S, sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bac756a",
   "metadata": {},
   "source": [
    "##### Elv correction algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b0ba86",
   "metadata": {},
   "source": [
    "We'll design an algorithm to fix those with <. Those with = will be fixed by SFR itself (hopefully). The following abbreviations are useful for explaining the concept:\n",
    "- A: DStr Elv of DStr segment\n",
    "- B: UStr Elv of DStr segment\n",
    "- C: DStr Elv of current segment\n",
    "- D: UStr Elv of current segment\n",
    "- F: DStr Elv of UStr segment(s)\n",
    "\n",
    "Here is the idea behind the algorithm:\n",
    "1. If **C > D & B <= D** :<br>\n",
    "-> Set **C = D**\n",
    "2. If **C > D & B > D** :<br>\n",
    "-> Set **C = D**. Set **B = D**\n",
    "3. If **C <= D** :<br>\n",
    "-> **No action**.\n",
    "\n",
    "Repeat till there are no segments with C < D.\n",
    "\n",
    "When there is no downstream segment, we apply the logic used in case 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69992922",
   "metadata": {},
   "outputs": [],
   "source": [
    "GDF_Elv = GDF_Elv.merge(GDF[['ID', 'Elv_UStr', 'Elv_DStr']], left_on='DStr_ID', right_on='ID', suffixes=('', '_DStr'), how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3643f24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "GDF_Elv[['A', 'B']] = GDF_Elv[['Elv_UStr_DStr', 'Elv_DStr_DStr']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56b0249",
   "metadata": {},
   "outputs": [],
   "source": [
    "GDF_Elv[['C', 'D']] = GDF_Elv[['Elv_UStr', 'Elv_DStr']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905669c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "GDF_Elv[GDF_Elv['B'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f80b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_elevations(row):\n",
    "    if row['C'] <= row['D']: # If UStr Elv <= DStr Elv, no adjustment needed\n",
    "        return row['B'], row['C']\n",
    "    elif (row['C'] > row['D']) and (pd.isna(row['B'])): # If UStr Elv <= DStr Elv but DStr Elv is missing (OuFl segment)\n",
    "        return pd.NA, row['D']\n",
    "    elif (row['C'] > row['D']) and (row['B'] <= row['D']):\n",
    "        return row['B'], row['D']\n",
    "    elif (row['C'] > row['D']) and (row['B'] > row['D']):\n",
    "        return row['D'], row['D']\n",
    "    else:\n",
    "        # Default case - should not happen, but ensures function always returns a tuple\n",
    "        return row['B'], row['C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbbeda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "GDF_Elv[['B_', 'C_']] = GDF_Elv.apply(adjust_elevations, axis=1, result_type='expand')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bc75cc",
   "metadata": {},
   "source": [
    "I'm worried consequtive segments might be problematic. Let's check if there are any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd1fcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "GDF_Elv_unfixed = GDF_Elv[ (GDF_Elv['Diff']<0)]\n",
    "consequtive = GDF_Elv_unfixed.loc[GDF_Elv_unfixed['DStr_ID'].isin(GDF_Elv_unfixed['ID']), 'DStr_ID']\n",
    "GDF_Elv_unfixed.loc[ (GDF_Elv_unfixed['ID'].isin(consequtive)) | (GDF_Elv_unfixed['DStr_ID'].isin(consequtive)), ['ID', 'DStr_ID', 'A', 'B', 'B_', 'C', 'C_', 'D']].sort_values(by='D').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bade28",
   "metadata": {},
   "source": [
    "Consequtive not ok. Let's hope that SFRmaker can handle this. Otherwise we'll have to come back later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1969e788",
   "metadata": {},
   "outputs": [],
   "source": [
    "GDF_Elv.loc[ GDF_Elv['D'] - GDF_Elv['C_'] < 0 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e642418",
   "metadata": {},
   "source": [
    "Cool, no segments without any drop in Elv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe76969a",
   "metadata": {},
   "outputs": [],
   "source": [
    "GDF_Elv['segment_drop'] = GDF_Elv['D'] - GDF_Elv['C_']\n",
    "GDF_Elv['DStr_drop'] = GDF_Elv['C_'] - GDF_Elv['B']\n",
    "GDF_Elv.loc[ GDF_Elv['C_'] - GDF_Elv['B_'] < 0 , ['ID', 'DStr_ID', 'A', 'B', 'B_', 'C', 'C_', 'D', 'segment_drop', 'DStr_drop'] ].sort_values(by='DStr_drop').reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b431e305",
   "metadata": {},
   "source": [
    "There are **quite a few** segments where C_ > B!!! SFRmaker might fix this. If not, I'll come back and fix it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e213c5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "GDF2 = GDF.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4e1cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "GDF = GDF.merge( GDF_Elv[['ID', 'C_', 'D']], on='ID', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c854f6c5",
   "metadata": {},
   "source": [
    "## 2.3 Remove DStr_IDs that are outside the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a886cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "GDF3 = GDF.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b07011",
   "metadata": {},
   "outputs": [],
   "source": [
    "GDF_DStr_Out_Mdl_Aa = GDF.loc[~GDF['DStr_ID'].isin(GDF['ID']) & GDF['DStr_ID']!=0]\n",
    "GDF_DStr_Out_Mdl_Aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c615023",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(GDF_DStr_Out_Mdl_Aa), GDF_DStr_Out_Mdl_Aa['DStr_ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4073a556",
   "metadata": {},
   "outputs": [],
   "source": [
    "GDF.loc[~GDF['DStr_ID'].isin(GDF['ID']) & GDF['DStr_ID']!=0, 'DStr_ID'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b548d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(GDF.loc[~GDF['DStr_ID'].isin(GDF['ID']) & GDF['DStr_ID']!=0, 'DStr_ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9422d97d",
   "metadata": {},
   "source": [
    "## 2.4 Remove circular IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5168c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_Circ_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eabd40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "GDF = GDF.loc[ ~GDF['DStr_ID'].isin(l_Circ_IDs) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53020b74",
   "metadata": {},
   "source": [
    "## 2.5 Generate SFRmaker lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14920b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "GDF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a8c867",
   "metadata": {},
   "outputs": [],
   "source": [
    "GDF['width2'] = GDF['width'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ea3ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = sfr.Lines.from_dataframe(df=GDF.copy(), # .copy() to avoid GDF columns being renamed by function (this feels like a bug to me)\n",
    "    id_column='ID',\n",
    "    routing_column='DStr_ID',\n",
    "    width1_column='width', width2_column='width2',\n",
    "    dn_elevation_column='C_',\n",
    "    up_elevation_column='D',\n",
    "    name_column='CODE',\n",
    "    width_units='m',\n",
    "    height_units='m',\n",
    "    crs=GDF.crs\n",
    "    #    shapefile=Pa_GPkg_1ry_SHP_SFR,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093af5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_lines = lines.df\n",
    "U.DF_info(lines.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85647fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_lines.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bf09c2",
   "metadata": {},
   "source": [
    "# 3. Connect SFR to MF6 model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1ea38c",
   "metadata": {},
   "source": [
    "## 3.0. Create SFR_grid item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae1c448",
   "metadata": {},
   "source": [
    "### 3.0.0 Initiate parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cfab97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sfr.StructuredGrid directly from MF6_DIS (DataFrame approach) #666 This cell and the cells below it can be combined into a function to read in a MF6_DIS (imod) object, and return a DF (GDF_grid) with the grid and geometry. \n",
    "DS = MF6_DIS.dataset\n",
    "N_L, N_R, N_C = DS.dims['layer'], DS.dims['y'], DS.dims['x']\n",
    "dx, dy = abs(float(DS.coords['dx'].values)), abs(float(DS.coords['dy'].values))\n",
    "Ls, Xs, Ys = DS.coords['layer'].values, DS.coords['x'].values, DS.coords['y'].values\n",
    "X_Ogn, Y_Ogn = Xs[0] - dx/2, Ys[0] + dy/2  # Upper-left corner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fb910e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct TOP, BOT. TOP array: 1st layer from DS['top'], rest from DS['bottom'][::-1] with layer+1\n",
    "TOPs = np.zeros((N_L, N_R, N_C))\n",
    "TOPs[0] = DS['top'].values\n",
    "TOPs[1:] = DS['bottom'].sel(layer=range(1, N_L))\n",
    "BOTs = DS['bottom'].values  # Shape: (N_L, N_R, N_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a81f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create full 3D grid indices\n",
    "k, i, j = np.meshgrid(range(N_L), range(N_R), range(N_C), indexing='ij')\n",
    "k, i, j = k.ravel(), i.ravel(), j.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30f30c0",
   "metadata": {},
   "source": [
    "### 3.0.1 Prepare GDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5534d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "GDF_grid = gpd.GeoDataFrame({\n",
    "    'k': k,\n",
    "    'i': i,\n",
    "    'j': j, \n",
    "    'node': range(N_L * N_R * N_C),\n",
    "    'isfr': 1,  # All cells can potentially have SFR # if function is made out of this, this needs to be removed and added to the DF after the function has run.\n",
    "    'top': TOPs.ravel(),\n",
    "    'bottom': BOTs.ravel(),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7273f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = GDF_grid['k'].eq(0)\n",
    "i_L0 = GDF_grid.loc[mask, 'i'].to_numpy()\n",
    "j_L0 = GDF_grid.loc[mask, 'j'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc02f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin = X_Ogn + j_L0*dx\n",
    "xmax = X_Ogn + (j_L0+1)*dx\n",
    "ymin = Y_Ogn - (i_L0+1)*dy\n",
    "ymax = Y_Ogn - i_L0*dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c04b0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "L0_geom = [box(x0, y0, x1, y1) for x0, y0, x1, y1 in zip(xmin, ymin, xmax, ymax)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f707b763",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in GDF_grid['k'].unique():\n",
    "    GDF_grid.loc[GDF_grid['k'] == k, 'geometry'] = L0_geom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92691bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "GDF_grid = GDF_grid.set_geometry('geometry', crs=DS.rio.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43d84b1",
   "metadata": {},
   "source": [
    "### 3.0.2 Identify deepest SFR layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75ef3d1",
   "metadata": {},
   "source": [
    "The reason we're doing this is that the model has too many Ls and it takes a very long time to run the SFR functions with all of them. So we'll find the deepest L that has any part of the stream network in it, and **we'll only use up to that layer for the SFR grid.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ed7853",
   "metadata": {},
   "outputs": [],
   "source": [
    "for L in range(BOTs.shape[0]):\n",
    "    L_BOT_min = BOTs[L].min()\n",
    "    L_BOT_max = BOTs[L].max()\n",
    "    print(L+1, f\"|{L_BOT_min:8.2f} |\", f\"{L_BOT_max:8.2f} |\")\n",
    "    if L_BOT_min > DF_lines['elevdn'].min():\n",
    "        SFR_deepest_L = L+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aee6560",
   "metadata": {},
   "outputs": [],
   "source": [
    "SFR_deepest_L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438b8fa1",
   "metadata": {},
   "source": [
    "### 3.0.3 Create SFR grid(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbdf43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SFR_grid = sfr.StructuredGrid(GDF_grid.loc[GDF_grid['k'] <= SFR_deepest_L-1], crs=G.crs) # -1 cause grid k starts at 0, L at 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f544790a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SFR_grid_L1 = sfr.StructuredGrid(GDF_grid.loc[GDF_grid['k'] == 0], crs=G.crs) # Extract layer 1 (k=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874b2665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what type of object and its basic info without triggering full repr\n",
    "print(f\"Type: {type(SFR_grid)}\")\n",
    "print(f\"SFR_grid object created: {SFR_grid is not None}\")\n",
    "\n",
    "# Check if it has expensive methods for representation\n",
    "print(f\"Available methods: {[method for method in dir(SFR_grid) if not method.startswith('_')][:10]}\")\n",
    "\n",
    "# Try to get basic info without full representation\n",
    "try:\n",
    "    print(f\"Grid shape info: {hasattr(SFR_grid, 'shape')}\")\n",
    "    if hasattr(SFR_grid, 'nlay'):\n",
    "        print(f\"Number of layers: {SFR_grid.nlay}\")\n",
    "    if hasattr(SFR_grid, 'nrow'):\n",
    "        print(f\"Number of rows: {SFR_grid.nrow}\")\n",
    "    if hasattr(SFR_grid, 'ncol'):\n",
    "        print(f\"Number of cols: {SFR_grid.ncol}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error getting basic info: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490b38bc",
   "metadata": {},
   "source": [
    "## 3.2. SFRdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a2ccde",
   "metadata": {},
   "outputs": [],
   "source": [
    "GDF4 = GDF.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5104626",
   "metadata": {},
   "outputs": [],
   "source": [
    "GDF = GDF4.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ef8172",
   "metadata": {},
   "outputs": [],
   "source": [
    "GDF.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18208c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = lines.paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41d55ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(paths.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bda520",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = sfr.Lines.from_dataframe(df=GDF.copy(), # .copy() to avoid GDF columns being renamed by function (this feels like a bug to me)\n",
    "    id_column='ID',\n",
    "    routing_column='DStr_ID',\n",
    "    width1_column='width', width2_column='width2',\n",
    "    dn_elevation_column='C_',\n",
    "    up_elevation_column='D',\n",
    "    name_column='CODE',\n",
    "    width_units='m',\n",
    "    height_units='m',\n",
    "    crs=GDF.crs\n",
    "    #    shapefile=Pa_GPkg_1ry_SHP_SFR,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c14af85",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_ids = [i for i,p in lines.paths.items() if p[-1] != 0]\n",
    "lines.df = lines.df[~lines.df['id'].isin(bad_ids)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f704db",
   "metadata": {},
   "outputs": [],
   "source": [
    "SFR_data = lines.to_sfr(grid=SFR_grid_L1, one_reach_per_cell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55633e76",
   "metadata": {},
   "source": [
    "### 3.2.1 Explore DF_reach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9f57e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_reach = SFR_data.reach_data.copy()\n",
    "DF_reach[['k', 'i', 'j']] = DF_reach[['k', 'i', 'j']] + 1 # convert to 1-based indexing for reviewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2a50a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_reach.describe() #include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59200f38",
   "metadata": {},
   "source": [
    "Some comments regarding DF_reaches: #666 Needs to be re-done\n",
    "- We have a large **number of reaches** (rno.max()=7819), and all columns have the same number of valid values, which is good.\n",
    "- **k** wasn't filled properly. We need to use the assign_layer function to fix this. **Surprise...<br>There are 2...<br>\n",
    "<t> sfrmaker.sfrdata.assign_layers <br>\n",
    "<t> sfrmaker.utils.assign_layers <br>\n",
    "We'll use the latter, where we can use BOTs. The other one requires a full loaded flopy model. <t>**\n",
    "- **j** is within range, so it was probably calculated correctly.\n",
    "- **iseg** makes sense. **ireach** is the reach number within the segment (according to copilot), seems feasible.\n",
    "- **width** has a few values that are too big. Let's print them out to check in QGIS.\n",
    "- **rchlen, slope, strtop** all make sense.\n",
    "- **strthick** is 1 everywhere. We need to edit this, based on some sort of assumption and the conductance value of the equivalent RIV item. Let's start with strthick=0.1 (cause 1m is too much).\n",
    "- **strhc1**, **thts**, **thti**, **eps** & **uhc** are not used as far as I know.\n",
    "- **outreach** seems iffy, as it's float, while I was expecting an int.\n",
    "- how can **asum** be negative?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34535a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_reach['strthick'] = 0.1  # Set a default streambed thickness of 0.1 m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65941b7",
   "metadata": {},
   "source": [
    "#### Explore width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0f702f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_reach.loc[:, ['rno', 'outreach', 'iseg', 'outseg', 'node', 'k', 'i', 'j', 'name', 'rchlen', 'width', 'strtop', 'strthick', 'asum']].sort_values(by=['width', 'i', 'j'], ascending=[False, True, True])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909d0649",
   "metadata": {},
   "source": [
    "I'll set all widths > 100 m to 1 m for now. #666"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734407bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_reach.loc[ DF_reach['width']>100, 'width'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c64e80",
   "metadata": {},
   "source": [
    "### 3.2.2 Assign the correct layers - k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56bc87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_reach[['k', 'i', 'j']] = DF_reach[['k', 'i', 'j']] - 1 # convert to 0-based indexing for utils_assign_layers function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c41ea0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reach_Ls, strtps = sfr.utils.assign_layers(reach_data=DF_reach, botm_array=BOTs, pad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2274bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_reach['k'] = reach_Ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5192d91f",
   "metadata": {},
   "source": [
    "### 3.2.3 Check \n",
    "Examples to check if segments were connected to the right cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2321af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, seg in enumerate(DF_reach['name'].unique()[:10]):\n",
    "    print(i+1, seg, DF_reach.loc[DF_reach['name']==seg, 'name'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4906e616",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_reach[['k', 'i', 'j']] = DF_reach[['k', 'i', 'j']] + 1 # convert to 1-based indexing for reviewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef23b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_reach.loc[DF_reach['name'] == 'OVK01451', ['rno', 'outreach', 'iseg', 'outseg', 'node', 'k', 'i', 'j', 'name', 'rchlen', 'width', 'strtop', \n",
    "                                              'strthick', 'asum']].sort_values(by=['i', 'j'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc9aa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_reach.loc[DF_reach['name'] == 'OVK02048', ['rno', 'outreach', 'iseg', 'outseg', 'node', 'k', 'i', 'j', 'name', 'rchlen', 'width', 'strtop', \n",
    "                                              'strthick', 'asum']].sort_values(by=['name', 'j', 'i'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc36d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_reach.loc[DF_reach['name'] == 'OVK20466', ['rno', 'outreach', 'iseg', 'outseg', 'node', 'k', 'i', 'j', 'name', 'rchlen', 'width', 'strtop', \n",
    "                                              'strthick', 'asum']].sort_values(by=['name', 'j', 'i'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e754ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_reach[['k', 'i', 'j']] = DF_reach[['k', 'i', 'j']] - 1 # convert to 0-based indexing for SFRmaker operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99082b4",
   "metadata": {},
   "source": [
    "### 3.2.4 Apply RIV conductance to DF_reach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9449c15b",
   "metadata": {},
   "source": [
    "##### Calculate Default Conductance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fddbeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_RC = DF_reach.copy()[['rno', 'name', 'k', 'i', 'j', 'iseg', 'outseg', 'rchlen', 'width', 'strtop', 'strthick', 'strhc1', 'asum']]\n",
    "DF_RC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25b0253",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_RC['Cond'] = DF_RC['width'] * DF_RC['rchlen'] * DF_RC['strhc1'] / DF_RC['strthick']\n",
    "DF_RC.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f05cc1",
   "metadata": {},
   "source": [
    "##### Import RIV Cond shapefiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d0bbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pa_Cond = PJ(U.Pa_WS, r\"models\\NBr\\In\\RIV\")\n",
    "l_Pa_Cond = [i for i in U.LD(Pa_Cond) if ('Cond' in i) and i.lower().endswith('.idf')]\n",
    "l_Pa_Cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28756438",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_Pa_Cond = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d8169d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for Pa in l_Pa_Cond:\n",
    "    d_Pa_Cond[Pa] = imod.idf.open(PJ(Pa_Cond, Pa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d98c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_key = list(d_Pa_Cond.keys())[1]\n",
    "A_whole = d_Pa_Cond[A_key]\n",
    "A = A_whole.sel(x=slice(Xmin, Xmax), y=slice(Ymax, Ymin))\n",
    "print(A_key)\n",
    "A.plot.imshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a3f712",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_key = list(d_Pa_Cond.keys())[0]\n",
    "B_whole = d_Pa_Cond[B_key]\n",
    "B = B_whole.sel(x=slice(Xmin, Xmax), y=slice(Ymax, Ymin))\n",
    "print(B_key)\n",
    "B.plot.imshow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9283fa98",
   "metadata": {},
   "source": [
    "We've loaded the main RIV cond as A, and the detailed as B. We'll use the average for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f98a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create union array C: average where both valid, single value where only one valid\n",
    "## 0.5* for NBr42\n",
    "C =  0.5 * xr.where(~np.isnan(A) & ~np.isnan(B), (A + B) / 2,  # Both valid: average\n",
    "             xr.where(~np.isnan(A), A, B))                # Only one valid: use that one\n",
    "\n",
    "print(f\"Union array C: {(~np.isnan(C)).sum().values} valid values, sum = {C.sum(skipna=True).values}\")\n",
    "C.plot.imshow()\n",
    "plt.title('Array C: Union of A and B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1cc778",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_RC['RIV_Cond'] = DF_RC['Cond'].copy() # Apply conductance matching to DF_RC using array C. Start with copy of existing Cond values as fallback\n",
    "\n",
    "C_DF_RC = C.values[DF_RC['i'].values, DF_RC['j'].values] # Get array values for all i,j coordinates at once (vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feebe6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace only where array has valid (non-NaN) values\n",
    "valid_mask_RC = ~np.isnan(C_DF_RC)\n",
    "DF_RC.loc[valid_mask_RC, 'RIV_Cond'] = C_DF_RC[valid_mask_RC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9fdd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"DF_RC conductance matching results:\")\n",
    "print(f\"Replaced {valid_mask_RC.sum()} values out of {len(DF_RC)} total rows ({valid_mask_RC.sum()/len(DF_RC)*100:.1f}%)\")\n",
    "print(f\"Original Cond: min={DF_RC['Cond'].min():.3f}, max={DF_RC['Cond'].max():.3f}\")\n",
    "print(f\"New RIV_Cond: min={DF_RC['RIV_Cond'].min():.3f}, max={DF_RC['RIV_Cond'].max():.3f}\")\n",
    "\n",
    "# Check how many values actually changed\n",
    "changed_values_RC = (DF_RC['Cond'] != DF_RC['RIV_Cond'])\n",
    "print(f\"Values that changed: {changed_values_RC.sum()} out of {len(DF_RC)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f265b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_RC['K_RIV'] = DF_RC['RIV_Cond'] * DF_RC['strthick'] / (DF_RC['width'] * DF_RC['rchlen'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafecc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_RC['Cond_Diff'] = DF_RC['RIV_Cond'] - DF_RC['Cond']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ab456f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_RC.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c618f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_reach['strhc1'] = DF_RC['K_RIV'] # Set it back to DF_reach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9faa5f4b",
   "metadata": {},
   "source": [
    "### 3.2.5 Explore segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e903c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_Sgm = SFR_data.segment_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcef1abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_Sgm.iloc[:].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d83bb2",
   "metadata": {},
   "source": [
    "Most columns aren't interesting. Let's plot the interesting ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d603ed7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_Sgm[[\"nseg\", \"outseg\", \"roughch\", \"elevup\", \"elevdn\", \"width1\", \"width2\", ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adebbc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(DF_Sgm['width1'] == DF_Sgm['width1']).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e6c30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(DF_Sgm['elevup'] >= DF_Sgm['elevdn']).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af18ca9a",
   "metadata": {},
   "source": [
    "We can see:\n",
    "- the roughness values are all the same (default) - **OK**\n",
    "- downstream elevation is always lower than (or equal to) upstream - **OK**\n",
    "- the widths seem to be the ones read from the shapefile - **OK**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdd3d0c",
   "metadata": {},
   "source": [
    "### 3.2.6 Add OBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a482922",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(SFR_data.add_observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea06e904",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pa_SFR_OBS_In = PJ(d_Pa['In'], f'OBS/SFR/NBr40/NBr40_SFR_OBS_Pnt.csv') #666 Should be PJ(d_Pa['In'], f'OBS/SFR/{MdlN}/{MdlN}_SFR_OBS_Pnt.csv')\n",
    "DF_SFR_OBS = pd.read_csv(Pa_SFR_OBS_In)\n",
    "DF_SFR_OBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394c3936",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in DF_SFR_OBS.iterrows(): # Have to add them one by one, otherwise it groups them by reach and only keeps the 1st one. This is an SFRmaker bug, I can fix that later and make a pull request.\n",
    "    SFR_data.add_observations(\n",
    "        pd.DataFrame(row).T,\n",
    "        x_location_column='x',  \n",
    "        y_location_column='y',\n",
    "        obstype_column='obstype',\n",
    "        obsname_column='site_no'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8ffb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "SFR_data.observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d47b08",
   "metadata": {},
   "source": [
    "### 3.2.7 Run diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe18b763",
   "metadata": {},
   "outputs": [],
   "source": [
    "SFR_data.run_diagnostics(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43b71e4",
   "metadata": {},
   "source": [
    "Most checks passed, except for: #666 need to re-check\n",
    "1. Checking reach_data for downstream rises in streambed elevation...<br>68 reaches encountered with strtop < strtop of downstream reach. Let's see if this causes a problem.\n",
    "2. Checking for model cells with multiple non-zero SFR conductances...\n",
    "565 model cells with multiple non-zero SFR conductances found.\n",
    "This can be fixed easily with one of the SFRdata options. We'll come here if it causes an error in the Sim.\n",
    "3. floppy Mdl not connected to SFRdata means:<br>\n",
    "    3.1 Cannot check reach proximities\n",
    "    3.2 Cannot check streambed elevations against cell bottom elevations. This shouldn't be a problem as the assign_layers function uses strbedthck (to assign k).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f187064f",
   "metadata": {},
   "outputs": [],
   "source": [
    "GDF_Elv.loc[ GDF_Elv['D'] - GDF_Elv['B_'] < 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec1e762",
   "metadata": {},
   "source": [
    "There are fewer entries in the GDF_Elv where the DStr Elv > UStr Elv, but this DF contains segments, not reaches. So this is expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea9457d",
   "metadata": {},
   "source": [
    "## 3.3 Write file and add to NAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60a3049",
   "metadata": {},
   "outputs": [],
   "source": [
    "SFR_data.reach_data = DF_reach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e92b865",
   "metadata": {},
   "outputs": [],
   "source": [
    "SFR_data.write_package(d_Pa['SFR'], version='mf6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb181299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to find an inteernal SFRmaker way to fix this later. This is just a temporary patch.\n",
    "with open(d_Pa['SFR'], 'r+', encoding='cp1252') as f:\n",
    "    content = f.read()\n",
    "    content = content.replace(f\"FILEIN {MdlN}.SFR6.obs\", f\"FILEIN imported_model/{MdlN}.SFR6.obs\")\n",
    "    content = content.replace('BUDGET FILEOUT', '#BUDGET FILEOUT')\n",
    "    f.seek(0)\n",
    "    f.truncate()\n",
    "    f.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853562fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.rename('model_SFR.chk', PJ(d_Pa['MF6'], 'imported_model/model_SFR.chk'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9334cfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(d_Pa['NAM_Mdl'], 'r') as f1:\n",
    "    l_Lns_NAM = f1.readlines()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff4484b",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_Lns_NAM.insert(-1, f\"  sfr6 imported_model/{PBN(d_Pa['SFR'])} sfr\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfb9b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(d_Pa['NAM_Mdl'], 'w') as f2:\n",
    "    f2.writelines(l_Lns_NAM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc0a4b8",
   "metadata": {},
   "source": [
    "# 4. Connect DRN to SFR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5424b18e",
   "metadata": {},
   "source": [
    "### 4.3.1 Prepare DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315b707b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = PJ(d_Pa['Pa_MdlN'], 'modflow6/imported_model')\n",
    "folders = [f for f in os.listdir(base) if ('drn' in f.lower()) and not ('.' in f) and os.path.isdir(PJ(base, f))]\n",
    "l_DRN_Pa = [PJ(base, folder, fname)\n",
    "             for folder in folders\n",
    "             for fname in os.listdir(PJ(base, folder))\n",
    "             if os.path.isfile(PJ(base, folder, fname))]\n",
    "# l_DRN_Pa  # list of full paths to files inside the matched \"drn\" folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9f872e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mf6_drn_bin(filepath: str | Path) -> pd.DataFrame:\n",
    "    \"\"\"Read MODFLOW 6 DRN binary input (imod format) into a DataFrame.\"\"\"\n",
    "    dtype = np.dtype([\n",
    "        (\"k\",    \"<i4\"),   # layer\n",
    "        (\"i\",    \"<i4\"),   # row\n",
    "        (\"j\",    \"<i4\"),   # column\n",
    "        (\"elev\", \"<f8\"),   # elevation\n",
    "        (\"cond\", \"<f8\"),   # conductance\n",
    "    ])\n",
    "    path = Path(filepath)\n",
    "    nrec = path.stat().st_size // dtype.itemsize\n",
    "    arr = np.fromfile(path, dtype=dtype, count=nrec)\n",
    "    return pd.DataFrame(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541ec348",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_DRN_DF = {}\n",
    "\n",
    "for i in range(len(l_DRN_Pa)):\n",
    "    DF_DRN = read_mf6_drn_bin(l_DRN_Pa[i])\n",
    "    d_DRN_DF[int(re.search(r'(?i)drn[-_]?(\\d+)', PDN(l_DRN_Pa[i])).group(1))] = DF_DRN.loc[ ~DF_DRN['i'].isin([1, N_R]) & ~DF_DRN['j'].isin([1, N_C]) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341a39da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in d_DRN_DF.keys():\n",
    "    # print(f\"DRN-{k} DataFrame shape: {d_DRN_DF[k].shape}\")\n",
    "    d_DRN_DF[k] = U.Calc_DF_XY(d_DRN_DF[k], X_Ogn, Y_Ogn, cellsize)\n",
    "    d_DRN_DF[k].drop(columns=['cond', 'elev'], inplace=True)\n",
    "    d_DRN_DF[k]['Pkg1'] = f'drn-{k}'\n",
    "    d_DRN_DF[k]['Pvd_ID'] = d_DRN_DF[k].index + 1  # 1-based index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d5a5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_reach_for_DRN = U.Calc_DF_XY(DF_reach[['rno', 'i', 'j']], X_Ogn, Y_Ogn, cellsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0645356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all DRN DataFrames and match with reach points by minimum distance\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Combine all d_DRN_DF items into a single DataFrame  \n",
    "DF_DRN_all = pd.concat(d_DRN_DF.values(), ignore_index=True)\n",
    "\n",
    "# Calculate distances and find closest reach for each DRN point\n",
    "drn_coords = DF_DRN_all[['X', 'Y']].values\n",
    "reach_coords = DF_reach_for_DRN[['X', 'Y']].values\n",
    "distances = cdist(drn_coords, reach_coords, metric='euclidean')\n",
    "min_indices = np.argmin(distances, axis=1)\n",
    "\n",
    "# Add matched reach data to DRN DataFrame\n",
    "matched_reach_data = DF_reach_for_DRN.iloc[min_indices].reset_index(drop=True)\n",
    "DF_DRN_all_matched = DF_DRN_all.copy()\n",
    "DF_DRN_all_matched['Rcv_ID'] = matched_reach_data['rno'].values\n",
    "DF_DRN_all_matched['distance_to_match'] = distances[np.arange(len(drn_coords)), min_indices]\n",
    "\n",
    "print(f\"Combined {len(DF_DRN_all):,} DRN points from {len(d_DRN_DF)} DataFrames\")\n",
    "print(f\"Matched to {DF_DRN_all_matched['Rcv_ID'].nunique()} unique reaches\")\n",
    "print(f\"Mean distance: {DF_DRN_all_matched['distance_to_match'].mean():.0f}m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641fb094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Quick summary of matching results\n",
    "# print(f\"Results: {len(DF_DRN_all_matched):,} DRN points matched\")\n",
    "# print(f\"Distance stats: mean={DF_DRN_all_matched['distance_to_match'].mean():.0f}m, \"\n",
    "#       f\"perfect_matches={(DF_DRN_all_matched['distance_to_match'] == 0).sum():,}\")\n",
    "# print(DF_DRN_all_matched[['k', 'i', 'j', 'X', 'Y', 'Pkg1', 'Rcv_ID', 'distance_to_match']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59eeb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_DRN_all_matched['Pkd2'] = 'sfr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d072b388",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_DRN_write = DF_DRN_all_matched[['Pkg1', 'Pvd_ID', 'Pkd2', 'Rcv_ID']]\n",
    "DF_DRN_write['MVR_TYPE'] = 'FACTOR'\n",
    "DF_DRN_write['value'] = 1\n",
    "DF_DRN_write"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379c06fc",
   "metadata": {},
   "source": [
    "### 4.3.2 Write MVR file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81bc74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pa_MVR = PJ(d_Pa['Sim_In'], f'{MdlN}.MVR6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab378f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Pa_MVR, 'w') as f:\n",
    "    f.write(f\"\"\"BEGIN OPTIONS\n",
    "END OPTIONS\n",
    "\n",
    "BEGIN DIMENSIONS\n",
    "    MAXMVR {DF_DRN_write.shape[0]}\n",
    "    MAXPACKAGES {len(d_DRN_DF.keys())+1}\n",
    "END DIMENSIONS\n",
    "\n",
    "BEGIN PACKAGES\n",
    "    {'\\n    '.join([f\"drn-{k}\" for  k in d_DRN_DF.keys()])}\n",
    "    sfr\n",
    "END PACKAGES\n",
    "\n",
    "BEGIN PERIOD 1\n",
    "\"\"\")\n",
    "    f.write(U.DF_to_MF_block(DF_DRN_write))\n",
    "    f.write('END PERIOD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36bdd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert MVR line to NAM\n",
    "with open(d_Pa['NAM_Mdl'], 'r') as f1:\n",
    "    l_Lns_NAM = f1.readlines()  \n",
    "\n",
    "l_Lns_NAM.insert(-1, f\"  MVR6 imported_model/{PBN(Pa_MVR)} MVR\\n\")\n",
    "\n",
    "with open(d_Pa['NAM_Mdl'], 'w') as f2:\n",
    "    f2.writelines(l_Lns_NAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76efa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add MOVER option to SFR\n",
    "with open(d_Pa['SFR'], 'r') as f1:\n",
    "    l_Lns_SFR = f1.readlines()  \n",
    "\n",
    "l_Lns_SFR.insert(3, f\"  MOVER\\n\")\n",
    "\n",
    "with open(d_Pa['SFR'], 'w') as f2:\n",
    "    f2.writelines(l_Lns_SFR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945e06ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add MOVER option to DRN files\n",
    "for i in d_DRN_DF.keys():\n",
    "    with open(PJ(d_Pa['Sim_In'], f'drn-{i}.drn'), 'r') as f1:\n",
    "        l_Lns_DRN = f1.readlines()  \n",
    "\n",
    "    l_Lns_DRN.insert(3, f\"  MOVER\\n\")\n",
    "\n",
    "    with open(PJ(d_Pa['Sim_In'], f'drn-{i}.drn'), 'w') as f2:\n",
    "        f2.writelines(l_Lns_DRN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00359cd",
   "metadata": {},
   "source": [
    "# 5. Execute model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872869d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "U.mete_grid_add_missing_Cols(PJ(d_Pa['Pa_MdlN'], 'metaswap/mete_grid.inp'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ee8110",
   "metadata": {},
   "source": [
    "# -1. Junkyard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d578ba8",
   "metadata": {},
   "source": [
    "## -1.1 Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539bae68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create flopy MF6 model with DIS package from existing MF6_DIS\n",
    "# def create_flopy_model_from_imod_dis(mf6_dis, model_name=\"gwf_model\"):\n",
    "#     \"\"\"\n",
    "#     Convert imod MF6_DIS to flopy MF6 model with DIS package\n",
    "#     \"\"\"\n",
    "#     # Extract data from imod DIS\n",
    "#     dataset = mf6_dis.dataset\n",
    "#     nlay, nrow, ncol = dataset.dims['layer'], dataset.dims['y'], dataset.dims['x']\n",
    "#     dx = abs(float(dataset.coords['dx'].values))\n",
    "#     dy = abs(float(dataset.coords['dy'].values))\n",
    "    \n",
    "#     # Get elevation arrays\n",
    "#     top_array = dataset['top'].values\n",
    "#     bottom_array = dataset['bottom'].values\n",
    "#     idomain_array = dataset['idomain'].values\n",
    "    \n",
    "#     # Calculate grid origin \n",
    "#     x_coords = dataset.coords['x'].values\n",
    "#     y_coords = dataset.coords['y'].values\n",
    "#     xorigin = x_coords[0] - dx/2\n",
    "#     yorigin = y_coords[-1] - dy/2\n",
    "    \n",
    "#     # Create flopy simulation\n",
    "#     model_ws = \"flopy_model\"\n",
    "#     os.makedirs(model_ws, exist_ok=True)\n",
    "    \n",
    "#     sim = mf6.MFSimulation(sim_name=\"mf6_sim\", sim_ws=model_ws, exe_name='mf6')\n",
    "#     tdis = mf6.ModflowTdis(sim, nper=1, perioddata=[(1.0, 1, 1.0)])\n",
    "#     ims = mf6.ModflowIms(sim, print_option='ALL')\n",
    "    \n",
    "#     # Create groundwater flow model\n",
    "#     gwf = mf6.MFModel(simulation=sim, model_type='gwf6', modelname=model_name)\n",
    "    \n",
    "#     # Create DIS package\n",
    "#     dis = mf6.ModflowGwfdis(\n",
    "#         gwf,\n",
    "#         nlay=nlay, nrow=nrow, ncol=ncol,\n",
    "#         delr=dx, delc=dy,\n",
    "#         top=top_array,\n",
    "#         botm=bottom_array,\n",
    "#         idomain=idomain_array,\n",
    "#         xorigin=xorigin,\n",
    "#         yorigin=yorigin\n",
    "#     )\n",
    "    \n",
    "#     print(f\"âœ“ Created flopy MF6 model with DIS:\")\n",
    "#     print(f\"  - Grid: {nlay} layers, {nrow} rows, {ncol} cols\")\n",
    "#     print(f\"  - Cell size: {dx} x {dy} m\")\n",
    "#     print(f\"  - Origin: ({xorigin:.0f}, {yorigin:.0f})\")\n",
    "#     print(f\"  - Workspace: {model_ws}\")\n",
    "    \n",
    "#     return sim, gwf, dis\n",
    "\n",
    "# # Create flopy model\n",
    "# sim, gwf, dis = create_flopy_model_from_imod_dis(MF6_DIS)\n",
    "\n",
    "# # Access the flopy grid object\n",
    "# flopy_grid = gwf.modelgrid\n",
    "# print(f\"\\\\nâœ“ Flopy StructuredGrid created:\")\n",
    "# print(f\"  - Shape: {flopy_grid.shape}\")\n",
    "# print(f\"  - Extent: {flopy_grid.extent}\")\n",
    "# print(f\"  - Grid ready for use with flopy tools!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947aff9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create proper metadata dictionary for all 37 layers\n",
    "# n_layers = DS.bottom.shape[0]  # Should be 37\n",
    "# d_MtDt_bottom = {}\n",
    "\n",
    "# # Add metadata for each layer\n",
    "# for i in range(n_layers):\n",
    "#     layer_num = i + 1  # 1-based layer numbering\n",
    "#     d_MtDt_bottom[f'layer_{layer_num:02d}'] = {\n",
    "#         'layer': f'L{layer_num}',\n",
    "#         'description': f'Bottom elevation for layer {layer_num}',\n",
    "#         'units': 'm'\n",
    "#     }\n",
    "\n",
    "# # Add global metadata\n",
    "# d_MtDt_bottom['all'] = {\n",
    "#     'metadata': f\"Created on {DT.today().strftime('%Y-%m-%d %H:%M:%S')}, to sense check SFRmaker's calculated Ls against the real grid. 100x100 gets interpolated.\",\n",
    "#     'source': 'DS.bottom',\n",
    "#     'total_layers': n_layers\n",
    "# }\n",
    "\n",
    "# print(f\"Creating TIF with {n_layers} bands...\")\n",
    "# print(f\"Metadata keys: {len([k for k in d_MtDt_bottom.keys() if k != 'all'])} bands\")\n",
    "\n",
    "# # Now call the function with proper metadata\n",
    "# G.DA_to_MBTIF(\n",
    "#     DS.bottom, \n",
    "#     r\"C:\\OD\\WS_Mdl\\models\\NBr\\PoP\\In\\BOT\\NBr1\\BOT_NBr1_25x25.tif\", \n",
    "#     d_MtDt_bottom, \n",
    "#     crs=G.crs, \n",
    "#     _print=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3548f3",
   "metadata": {},
   "source": [
    "##### k=0 investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e615850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"SFR Grid dimensions: {SFR_grid.nrow} rows Ã— {SFR_grid.ncol} cols\")\n",
    "# print(f\"Max node in reach data: {DF_reach['node'].max()}\")\n",
    "# print(f\"Expected max node for 2D grid: {SFR_grid.nrow * SFR_grid.ncol - 1}\")\n",
    "# print(f\"Max i in reach data: {DF_reach['i'].max()}\")\n",
    "# print(f\"Max j in reach data: {DF_reach['j'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0e032f",
   "metadata": {},
   "source": [
    "**Why is SFRmaker doing this incorrect conversion?**\n",
    "\n",
    "The issue is in SFRmaker's source code (`sfrmaker/lines.py` around lines 356-372). \n",
    "\n",
    "**The Problem:**\n",
    "- SFRmaker hardcodes `k = 0` for all reaches \n",
    "- It assumes all node numbers are **2D nodes** (layer 0 only)\n",
    "- It uses 2D conversion formulas: `i = node Ã· ncol` and `j = node % ncol`\n",
    "\n",
    "**What's happening in your case:**\n",
    "- Your model has **3D nodes** that include layer information\n",
    "- SFRmaker receives 3D node numbers (like 1,155,680) \n",
    "- It incorrectly applies 2D conversion to these 3D nodes\n",
    "- This gives wrong `i` values (like 2,407 instead of proper row indices 0-343)\n",
    "\n",
    "**The correct 3D conversion should be:**\n",
    "- `k = node Ã· (nrow Ã— ncol)`\n",
    "- `i = (node % (nrow Ã— ncol)) Ã· ncol` \n",
    "- `j = node % ncol`\n",
    "\n",
    "This is a bug in SFRmaker - it doesn't handle 3D structured grids properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d615b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's demonstrate the problem with a few example nodes from your data\n",
    "# import numpy as np\n",
    "\n",
    "# # Get some example 3D nodes from your reach data\n",
    "# example_nodes = DF_reach['node'].iloc[::10000].tolist()[:5]  # Every 10000th node, first 5\n",
    "# print(\"Example 3D nodes from your data:\", example_nodes)\n",
    "# print()\n",
    "\n",
    "# # Grid dimensions\n",
    "# nrow, ncol = SFR_grid.nrow, SFR_grid.ncol  # 344, 480\n",
    "# print(f\"Grid: {nrow} rows Ã— {ncol} cols\")\n",
    "# print()\n",
    "\n",
    "# # Show what SFRmaker is doing (INCORRECT for 3D nodes)\n",
    "# print(\"âŒ SFRmaker's INCORRECT 2D conversion:\")\n",
    "# for node in example_nodes:\n",
    "#     i_wrong = node // ncol  # SFRmaker's approach\n",
    "#     j = node % ncol\n",
    "#     k = 0  # SFRmaker hardcodes this\n",
    "#     print(f\"  Node {node:>7} â†’ k={k}, i={i_wrong:>4}, j={j:>3}\")\n",
    "# print()\n",
    "\n",
    "# # Show what the CORRECT 3D conversion should be\n",
    "# print(\"âœ… CORRECT 3D conversion:\")\n",
    "# for node in example_nodes:\n",
    "#     k_correct = node // (nrow * ncol)\n",
    "#     i_correct = (node % (nrow * ncol)) // ncol\n",
    "#     j_correct = node % ncol\n",
    "#     print(f\"  Node {node:>7} â†’ k={k_correct}, i={i_correct:>3}, j={j_correct:>3}\")\n",
    "    \n",
    "# print(f\"\\nðŸ“Š Your data statistics:\")\n",
    "# print(f\"   Max i in data: {DF_reach['i'].max()} (should be â‰¤ {nrow-1})\")\n",
    "# print(f\"   Max j in data: {DF_reach['j'].max()} (should be â‰¤ {ncol-1}) âœ“\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b10196",
   "metadata": {},
   "source": [
    "##### testing relics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d811c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#N_L, N_R, N_C, f\"{N_L * N_R * N_C:,}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91589fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DF_reach['node'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12491933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF_reach['i_copy'] = DF_reach['i'].copy()\n",
    "# DF_reach['k_copy'] = DF_reach['k'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8918b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF_reach['test'] = (DF_reach['i_copy'] % (DF_reach['k'] * DF_reach['j']))\n",
    "# DF_reach[['node', 'k', 'i', 'j', 'test']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd31d2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF_test = DF_reach[['node', 'k', 'i_copy', 'j']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02613226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF_test['k_a'] = DF_reach['node'] // (N_R * N_C)\n",
    "# DF_test['k_b'] = DF_reach['i_copy'] % (N_R *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edfbfef",
   "metadata": {},
   "source": [
    "#### Co-pilot assign layer error investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bed559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's look for the exact case from the previous output\n",
    "# # From cell 173 output, we saw k=6, i=281, j=392 with strtop=19.759\n",
    "# test_case = DF_reach[(DF_reach['strtop'] > 19.75) & (DF_reach['strtop'] < 19.77)]\n",
    "# print(\"Found test cases with strtop around 19.76:\")\n",
    "# print(test_case[['k', 'i', 'j', 'strtop', 'strthick', 'rno']].head())\n",
    "\n",
    "# if len(test_case) > 0:\n",
    "#     # Take the first match\n",
    "#     k, i, j, strtop, strthick = test_case.iloc[0][['k', 'i', 'j', 'strtop', 'strthick']]\n",
    "#     strbot_calculated = strtop - strthick\n",
    "#     print(f\"\\nAnalyzing case: k={k}, i={i}, j={j}\")\n",
    "#     print(f\"strtop: {strtop}\")\n",
    "#     print(f\"strthick: {strthick}\")\n",
    "#     print(f\"strbot (strtop - strthick): {strbot_calculated}\")\n",
    "    \n",
    "#     # Get the BOTs at this location (using 0-based indexing)\n",
    "#     print(f\"\\nLayer bottoms at i={i}, j={j}:\")\n",
    "#     for L in range(min(10, BOTs.shape[0])):  # Show first 10 layers\n",
    "#         bot = BOTs[L, i, j]\n",
    "#         print(f\"L{L+1} bottom: {bot:.6f}\")\n",
    "        \n",
    "#     # Let's check what layer the reach was actually assigned to\n",
    "#     assigned_k = reach_Ls[test_case.index[0]]\n",
    "#     print(f\"\\nReach was assigned to layer k={assigned_k+1} (1-based) = k={assigned_k} (0-based)\")\n",
    "    \n",
    "#     # Check where strbot should be assigned\n",
    "#     print(f\"\\nAnalyzing where strbot ({strbot_calculated:.6f}) should be assigned:\")\n",
    "#     for L in range(min(8, BOTs.shape[0]-1)):  # Check first 8 layers\n",
    "#         if L == 0:\n",
    "#             top = TOPs[0, i, j]  # First layer top - TOPs is 3D like BOTs\n",
    "#         else:\n",
    "#             top = BOTs[L-1, i, j]  # Previous layer bottom = current layer top\n",
    "#         bot = BOTs[L, i, j]\n",
    "#         fits = bot <= strbot_calculated <= top\n",
    "#         print(f\"L{L+1}: top={top:.6f}, bot={bot:.6f} - strbot fits? {fits}\")\n",
    "#         if fits:\n",
    "#             print(f\"  --> Stream bottom SHOULD be in Layer {L+1} (0-based: {L})\")\n",
    "#             if L != assigned_k:\n",
    "#                 print(f\"  *** PROBLEM: But it was assigned to Layer {assigned_k+1} (0-based: {assigned_k}) ***\")\n",
    "#             break\n",
    "    \n",
    "#     # Let's also test what happens if we use strthick=1.0 instead of 0.1\n",
    "#     strbot_with_thick_1 = strtop - 1.0\n",
    "#     print(f\"\\nIf strthick was 1.0 instead of 0.1:\")\n",
    "#     print(f\"strbot would be: {strbot_with_thick_1:.6f}\")\n",
    "#     for L in range(min(8, BOTs.shape[0]-1)):\n",
    "#         if L == 0:\n",
    "#             top = TOPs[0, i, j]\n",
    "#         else:\n",
    "#             top = BOTs[L-1, i, j]\n",
    "#         bot = BOTs[L, i, j]\n",
    "#         fits = bot <= strbot_with_thick_1 <= top\n",
    "#         if fits:\n",
    "#             print(f\"  --> With strthick=1.0, would be assigned to Layer {L+1} (0-based: {L})\")\n",
    "#             if L == assigned_k:\n",
    "#                 print(f\"  *** This matches the actual assignment! The function may be ignoring strthick=0.1 ***\")\n",
    "#             break\n",
    "# else:\n",
    "#     print(\"No test case found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bd0106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's test the assign_layers function more systematically\n",
    "# # Create a small test case to verify if it's using strthick properly\n",
    "\n",
    "# print(\"=== TESTING sfr.utils.assign_layers BEHAVIOR ===\")\n",
    "# print()\n",
    "\n",
    "# # Create a minimal test dataframe with known values\n",
    "# test_df = DF_reach.iloc[3910:3912].copy()  # Take the problematic cases\n",
    "# print(\"Test data:\")\n",
    "# print(test_df[['k', 'i', 'j', 'strtop', 'strthick']])\n",
    "# print()\n",
    "\n",
    "# # Test 1: Call with strthick = 0.1 (current values)\n",
    "# print(\"Test 1: Using strthick = 0.1 (current values)\")\n",
    "# test_layers_01, _ = sfr.utils.assign_layers(reach_data=test_df, botm_array=BOTs)\n",
    "# print(\"Assigned layers:\", test_layers_01)\n",
    "# print()\n",
    "\n",
    "# # Test 2: Temporarily change strthick to 1.0 and see what happens\n",
    "# test_df_thick1 = test_df.copy()\n",
    "# test_df_thick1['strthick'] = 1.0\n",
    "# print(\"Test 2: Changing strthick to 1.0\")\n",
    "# print(test_df_thick1[['k', 'i', 'j', 'strtop', 'strthick']])\n",
    "# test_layers_10, _ = sfr.utils.assign_layers(reach_data=test_df_thick1, botm_array=BOTs)\n",
    "# print(\"Assigned layers:\", test_layers_10)\n",
    "# print()\n",
    "\n",
    "# # Test 3: What if we use a different column name?\n",
    "# test_df_custom = test_df.copy()\n",
    "# test_df_custom['custom_thick'] = 0.1\n",
    "# print(\"Test 3: Using custom column name 'custom_thick'\")\n",
    "# test_layers_custom, _ = sfr.utils.assign_layers(reach_data=test_df_custom, botm_array=BOTs, strthick_col='custom_thick')\n",
    "# print(\"Assigned layers:\", test_layers_custom)\n",
    "# print()\n",
    "\n",
    "# print(\"=== ANALYSIS ===\")\n",
    "# print(f\"With strthick=0.1: {test_layers_01}\")\n",
    "# print(f\"With strthick=1.0: {test_layers_10}\")\n",
    "# print(f\"With custom column: {test_layers_custom}\")\n",
    "\n",
    "# if np.array_equal(test_layers_01, test_layers_10):\n",
    "#     print(\"âŒ PROBLEM: strthick=0.1 and strthick=1.0 give SAME results!\")\n",
    "#     print(\"   This suggests the function is NOT using the strthick column.\")\n",
    "# elif np.array_equal(test_layers_01, test_layers_custom):\n",
    "#     print(\"âœ… The function DOES use the strthick column correctly.\")\n",
    "# else:\n",
    "#     print(\"ðŸ¤” Mixed results - need further investigation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6a66b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's test specifically with the problematic case we found earlier\n",
    "# print(\"=== TESTING THE SPECIFIC PROBLEMATIC CASE ===\")\n",
    "\n",
    "# # Get the exact case that was wrong\n",
    "# problematic_case = DF_reach[(DF_reach['strtop'] > 19.75) & (DF_reach['strtop'] < 19.77)].iloc[[0]]\n",
    "# print(\"Problematic case:\")\n",
    "# print(problematic_case[['k', 'i', 'j', 'strtop', 'strthick']])\n",
    "\n",
    "# # Test it individually\n",
    "# test_layer, _ = sfr.utils.assign_layers(reach_data=problematic_case, botm_array=BOTs)\n",
    "# print(f\"Function assigned layer: {test_layer} (0-based)\")\n",
    "# print(f\"As scalar: {test_layer if np.isscalar(test_layer) else test_layer[0]} (0-based)\")\n",
    "\n",
    "# # Let's manually calculate what it should be\n",
    "# k, i, j, strtop, strthick = problematic_case.iloc[0][['k', 'i', 'j', 'strtop', 'strthick']]\n",
    "# strbot = strtop - strthick\n",
    "\n",
    "# print(f\"\\nManual calculation:\")\n",
    "# print(f\"strtop: {strtop}\")\n",
    "# print(f\"strthick: {strthick}\")  \n",
    "# print(f\"strbot: {strbot}\")\n",
    "\n",
    "# # Find the correct layer manually\n",
    "# for L in range(BOTs.shape[0]-1):\n",
    "#     if L == 0:\n",
    "#         top = TOPs[0, i, j]\n",
    "#     else:\n",
    "#         top = BOTs[L-1, i, j]\n",
    "#     bot = BOTs[L, i, j]\n",
    "    \n",
    "#     if bot <= strbot <= top:\n",
    "#         print(f\"Manual calculation says layer should be: {L} (0-based)\")\n",
    "#         if L != (test_layer if np.isscalar(test_layer) else test_layer[0]):\n",
    "#             print(f\"âŒ MISMATCH: Function returned {test_layer}, should be {L}\")\n",
    "#         else:\n",
    "#             print(f\"âœ… MATCH: Function correctly returned {L}\")\n",
    "#         break\n",
    "\n",
    "# # Let's also check if there might be a pad parameter affecting this\n",
    "# print(f\"\\nLet's check what happens with different pad values:\")\n",
    "# for pad in [0.0, 1.0, 2.0]:\n",
    "#     test_layer_pad, _ = sfr.utils.assign_layers(reach_data=problematic_case, botm_array=BOTs, pad=pad)\n",
    "#     layer_val = test_layer_pad if np.isscalar(test_layer_pad) else test_layer_pad[0] \n",
    "#     print(f\"With pad={pad}: layer = {layer_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7671cde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's explore the logic behind the 'pad' parameter\n",
    "# print(\"=== UNDERSTANDING THE 'pad' PARAMETER LOGIC ===\")\n",
    "\n",
    "# # From the documentation:\n",
    "# # \"Minimum distance that streambed bottom must be above layer bottom.\n",
    "# #  When determining the layer or whether the streambed bottom is below\n",
    "# #  the model bottom, streambed bottom - pad is used.\"\n",
    "\n",
    "# k, i, j, strtop, strthick = problematic_case.iloc[0][['k', 'i', 'j', 'strtop', 'strthick']]\n",
    "# strbot = strtop - strthick\n",
    "\n",
    "# print(f\"Example case: strtop={strtop:.3f}, strthick={strthick}, strbot={strbot:.3f}\")\n",
    "# print(f\"\\nLayer boundaries at this location:\")\n",
    "\n",
    "# for L in range(7):  # Show first 7 layers\n",
    "#     if L == 0:\n",
    "#         top = TOPs[0, i, j]\n",
    "#     else:\n",
    "#         top = BOTs[L-1, i, j]\n",
    "#     bot = BOTs[L, i, j]\n",
    "    \n",
    "#     print(f\"L{L+1}: top={top:.3f}, bot={bot:.3f}, thickness={top-bot:.3f}\")\n",
    "    \n",
    "#     # Show what happens with different pad values\n",
    "#     for pad in [0.0, 0.5, 1.0]:\n",
    "#         effective_strbot = strbot - pad\n",
    "#         fits = bot <= effective_strbot <= top\n",
    "#         if fits:\n",
    "#             print(f\"  â†’ With pad={pad}: effective_strbot={effective_strbot:.3f} fits in L{L+1}\")\n",
    "\n",
    "# print(f\"\\n=== WHY USE PAD? ===\")\n",
    "# print(f\"1. NUMERICAL STABILITY: Prevents streams from being placed exactly on layer boundaries\")\n",
    "# print(f\"2. HYDROGEOLOGICAL REALISM: Ensures minimum thickness between stream and impermeable layer\")\n",
    "# print(f\"3. MODEL CONVERGENCE: Avoids numerical issues when stream and layer bottom are too close\")\n",
    "# print(f\"4. SAFETY MARGIN: Accounts for elevation uncertainties in DEM/bathymetry data\")\n",
    "\n",
    "# print(f\"\\n=== PRACTICAL IMPLICATIONS ===\")\n",
    "# print(f\"â€¢ pad=0.0: Stream can be right at layer bottom (risky for convergence)\")\n",
    "# print(f\"â€¢ pad=1.0: Stream must be at least 1m above layer bottom (default, conservative)\")\n",
    "# print(f\"â€¢ pad=0.1-0.5: Reasonable compromise for most applications\")\n",
    "\n",
    "# print(f\"\\n=== WHEN MIGHT YOU WANT DIFFERENT pad VALUES? ===\")\n",
    "# print(f\"â€¢ High-resolution models (small cells): Use smaller pad (0.1-0.5m)\")\n",
    "# print(f\"â€¢ Regional models (large cells): Default pad=1.0 is usually fine\")\n",
    "# print(f\"â€¢ Very thin aquifers: May need smaller pad to allow streams in shallow layers\")\n",
    "# print(f\"â€¢ Uncertain elevations: Larger pad for safety margin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b514d312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's show a concrete example of why pad matters for model stability\n",
    "# print(\"=== CONCRETE EXAMPLE: WHY pad PREVENTS PROBLEMS ===\")\n",
    "\n",
    "# print(\"Scenario: Stream bottom at 19.659m, Layer 5 bottom at 18.913m\")\n",
    "# print(\"Distance between stream bottom and layer bottom: {:.3f}m\".format(19.659 - 18.913))\n",
    "\n",
    "# print(f\"\\nWithout pad (pad=0.0):\")\n",
    "# print(f\"â€¢ Stream bottom = 19.659m\")\n",
    "# print(f\"â€¢ Layer bottom = 18.913m\") \n",
    "# print(f\"â€¢ Available thickness for groundwater flow = 0.746m\")\n",
    "# print(f\"â€¢ âœ… Seems OK, but what if there are small elevation errors?\")\n",
    "\n",
    "# print(f\"\\nWith default pad=1.0:\")\n",
    "# print(f\"â€¢ Effective stream bottom = 19.659 - 1.0 = 18.659m\")\n",
    "# print(f\"â€¢ Gets assigned to Layer 7 (bottom = 18.319m)\")\n",
    "# print(f\"â€¢ Distance from stream to layer bottom = 18.659 - 18.319 = 0.340m\")\n",
    "# print(f\"â€¢ âœ… Much safer margin\")\n",
    "\n",
    "# print(f\"\\n=== REAL-WORLD ISSUES pad HELPS AVOID ===\")\n",
    "# print(f\"â€¢ DEM elevation errors (Â±0.1-1.0m typical)\")\n",
    "# print(f\"â€¢ Stream bathymetry uncertainties\")\n",
    "# print(f\"â€¢ Model discretization effects\")\n",
    "# print(f\"â€¢ Numerical precision in MODFLOW calculations\")\n",
    "# print(f\"â€¢ Convergence problems when hydraulic gradients become extreme\")\n",
    "\n",
    "# print(f\"\\n=== RECOMMENDATION FOR YOUR CASE ===\")\n",
    "# print(f\"Since you're working with strthick=0.1 (very thin), consider:\")\n",
    "# print(f\"â€¢ pad=0.1 to 0.5: Respects your thin streams while maintaining stability\")\n",
    "# print(f\"â€¢ pad=0.0: Only if you're confident in elevation accuracy\")\n",
    "# print(f\"â€¢ pad=1.0: Conservative default, but may push streams too deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f284dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's check the dimensions and understand the coordinate system\n",
    "# print(\"BOTs shape:\", BOTs.shape)\n",
    "# print(\"TOPs shape:\", TOPs.shape)\n",
    "# print(\"DF_reach k,i,j ranges:\")\n",
    "# print(\"k range:\", DF_reach['k'].min(), \"to\", DF_reach['k'].max())  \n",
    "# print(\"i range:\", DF_reach['i'].min(), \"to\", DF_reach['i'].max())\n",
    "# print(\"j range:\", DF_reach['j'].min(), \"to\", DF_reach['j'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e028684",
   "metadata": {},
   "source": [
    "## Investigating SFRmaker Source Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b08f2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's examine the SFRmaker source code to understand the add_observations method\n",
    "# import inspect\n",
    "\n",
    "# # Get the source code of the add_observations method\n",
    "# try:\n",
    "#     source_code = inspect.getsource(SFR_data.add_observations)\n",
    "#     print(\"SFRmaker add_observations method source code:\")\n",
    "#     print(\"=\" * 60)\n",
    "#     print(source_code)\n",
    "# except Exception as e:\n",
    "#     print(f\"Could not get source code: {e}\")\n",
    "    \n",
    "#     # Try to get the method signature at least\n",
    "#     try:\n",
    "#         sig = inspect.signature(SFR_data.add_observations)\n",
    "#         print(f\"\\nMethod signature: add_observations{sig}\")\n",
    "        \n",
    "#         # Get docstring\n",
    "#         doc = SFR_data.add_observations.__doc__\n",
    "#         if doc:\n",
    "#             print(f\"\\nDocstring:\\n{doc}\")\n",
    "#     except Exception as e2:\n",
    "#         print(f\"Could not get signature: {e2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f224cdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's find the add_observations function that gets called\n",
    "# import sfrmaker\n",
    "# from sfrmaker import sfrdata\n",
    "\n",
    "# # Let's look for the standalone add_observations function\n",
    "# try:\n",
    "#     # Try to import the function directly\n",
    "#     from sfrmaker.sfrdata import add_observations as standalone_add_obs\n",
    "    \n",
    "#     source_code = inspect.getsource(standalone_add_obs)\n",
    "#     print(\"Standalone add_observations function source code:\")\n",
    "#     print(\"=\" * 70)\n",
    "#     print(source_code[:2000])  # Print first 2000 characters to see the logic\n",
    "#     print(\"...\" if len(source_code) > 2000 else \"\")\n",
    "    \n",
    "# except Exception as e:\n",
    "#     print(f\"Could not get standalone function: {e}\")\n",
    "    \n",
    "#     # Let's check the sfrmaker module structure\n",
    "#     print(\"\\nSFRmaker module contents:\")\n",
    "#     for attr in dir(sfrmaker):\n",
    "#         if 'obs' in attr.lower():\n",
    "#             print(f\"  {attr}\")\n",
    "            \n",
    "#     print(\"\\nSFRdata module contents:\")\n",
    "#     for attr in dir(sfrdata):\n",
    "#         if 'obs' in attr.lower():\n",
    "#             print(f\"  {attr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9560d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's get more of the source code, particularly the main logic\n",
    "# from sfrmaker.sfrdata import add_observations as standalone_add_obs\n",
    "\n",
    "# source_code = inspect.getsource(standalone_add_obs)\n",
    "# print(\"Full add_observations function source code (key parts):\")\n",
    "# print(\"=\" * 70)\n",
    "\n",
    "# # Find the main logic section\n",
    "# lines = source_code.split('\\n')\n",
    "# start_printing = False\n",
    "# for i, line in enumerate(lines):\n",
    "#     # Look for where the main processing starts\n",
    "#     if 'if data is None' in line or 'data = data.copy()' in line or 'for i, df in enumerate(data_list)' in line:\n",
    "#         start_printing = True\n",
    "        \n",
    "#     if start_printing:\n",
    "#         print(line)\n",
    "        \n",
    "#     # Stop if we get too long\n",
    "#     if start_printing and i > len(lines) - 20:  # Print most of the function\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6d3457",
   "metadata": {},
   "source": [
    "## 2.4. Explore GDF to fill SFRmaker input requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d27b8a",
   "metadata": {},
   "source": [
    "<!-- ### 2.4.0 Custom Hydrography Required Fields -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152307ba",
   "metadata": {},
   "source": [
    "<!-- Below, we'll match the shapefile attributes to the SFRmaker requirements as per SFRmaker manual ( https://doi-usgs.github.io/sfrmaker/latest/inputs.html):\n",
    "\n",
    "**Custom hydrography** <br>\n",
    "Any Polyline shapefile can be supplied in lieu of NHDPlus, but it must have the following columns, as shown in the second example:\n",
    "1. **flowlines_file**: path to shapefile\n",
    "2. **id_column**: unique identifier for each polyline\n",
    "3. **routing_column**: downstream connection (ID), 0 if none\n",
    "4. **width1_column**: channel width at start of line, in attr\\_length\\_units (optional)\n",
    "5. **width2_column**: channel width at end of line, in attr_length_units (optional)\n",
    "6. **up_elevation_column**: streambed elevation at start of line, in attr_height_units\n",
    "7. **dn_elevation_column**: streambed elevation at end of line, in attr_height_units\n",
    "8. **name_column**: stream name (optional)\n",
    "9. **attr_length_units**: channel width units\n",
    "10. **attr_height_units**: streambed elevation units -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7b534b",
   "metadata": {},
   "source": [
    "<!-- Here are the columns of the GDF, so we can match them to the SFRmaker requirements: -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca069ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, col in enumerate(GDF.columns):\n",
    "#     print(f\"{i}: {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eda76d0",
   "metadata": {},
   "source": [
    "<!-- ### 2.4.2 Explore GDF fields -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fc970c",
   "metadata": {},
   "source": [
    "<!-- #### 2. & 3. will most likely be 'OBJECTID' & 'DStr_ID'. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5774eec0",
   "metadata": {},
   "source": [
    "<!-- But let's ensure there are no nulls and use the .describe() method to check more details -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c260130f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GDF[['OBJECTID', 'DStr_ID']].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14c50e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GDF[['CODE', 'OBJECTID', 'DStr_code', 'DStr_ID']].describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ef44c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GDF.loc[GDF['DStr_ID']==0, 'DStr_ID'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298fe146",
   "metadata": {},
   "source": [
    "<!-- Great. No nuls and 13 DStr_codes with no downstream connection ('DStr'==0) (9 with min_Dist between 100 and 1000, + 5 with min_Dist betwen 10 and 100, -1, that we connected to the meandering long segment). -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c49df0",
   "metadata": {},
   "source": [
    "<!-- #### 4. & 5. Widths (at start and end) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a484d5",
   "metadata": {},
   "source": [
    "<!-- There are 4 candidates for those fields:\n",
    "- 'WS_BODEMBREEDTE_L' (channel bed width)\n",
    "- 'WS_BODBREE_ACCPROF_LI_L' (Accepted profile bottom width (left) (m))\n",
    "- 'WS_BODBREE_ACCPROF_RE_L' (Accepted profile bottom width (right) (m))\n",
    "- 'WS_VW_BODEMBREEDTE_L' (Prescribed bottom width (voorwaarde) (m))\n",
    "\n",
    "Let's compare the values. We can probably just use WS_BODEMBREEDTE. I think it has no/fewer nuls and the values are similar to the other 3 fields. Then we can upgrade. But let's have a look. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3076e339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GDF[['CODE', 'OBJECTID', 'WS_BODEMBREEDTE_L', 'WS_BODBREE_ACCPROF_LI_L', 'WS_BODBREE_ACCPROF_RE_L', 'WS_VW_BODEMBREEDTE_L']].describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3b342a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GDF.loc[ GDF['WS_BODBREE_ACCPROF_LI_L'].notna() | GDF['WS_BODBREE_ACCPROF_RE_L'].notna() | GDF['WS_VW_BODEMBREEDTE_L'].notna(),\n",
    "#          ['CODE', 'WS_BODEMBREEDTE_L', 'WS_BODBREE_ACCPROF_LI_L', 'WS_BODBREE_ACCPROF_RE_L', 'WS_VW_BODEMBREEDTE_L']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6272511b",
   "metadata": {},
   "source": [
    "<!-- 'WS_BODBREE_ACCPROF_LI_L' & 'WS_BODBREE_ACCPROF_RE_L' are not the bottom of the channel. This is clear if we masure the channel width in QGIS. So we won't use those.<br>\n",
    "'WS_VW_BODEMBREEDTE_L' only has nulls, so we won't use that either.<br>\n",
    "**So we'll just use 'WS_BODEMBREEDTE_L'.** -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f2a810",
   "metadata": {},
   "source": [
    "<!-- #### 6. & 7. Upstream and downstream elevations -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589cce6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GDF[[ 'CODE', 'WS_BH_BOVENSTROOMS_L', 'WS_BH_BENEDENSTROOMS_L']].describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c72c09",
   "metadata": {},
   "source": [
    "<!-- No nulls + the percentiles make sense.ðŸŸ¢<br>\n",
    "Let's make sure the UStr is always higher than the DnStr.<br>\n",
    "Then let's print out some values to check in QGIS. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd834f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (GDF['WS_BH_BOVENSTROOMS_L'] <= GDF['WS_BH_BENEDENSTROOMS_L']).sum(), (GDF['WS_BH_BOVENSTROOMS_L'] < GDF['WS_BH_BENEDENSTROOMS_L']).sum(), (GDF['WS_BH_BOVENSTROOMS_L'] > GDF['WS_BH_BENEDENSTROOMS_L']).sum(), GDF.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebd1880",
   "metadata": {},
   "source": [
    "<!-- For 98 segments (out of 591), the UStr Elv is <= the DStr Elv. This is not good. We'll have to fix this. ðŸ”´<br>\n",
    "Only 24/99 have DStr < UStr , the rest are equal. = will be corrected by SFR itself (as far as I know), so no action is required for those. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512916c1",
   "metadata": {},
   "source": [
    "<!-- ##### Let's print out some CODEs where =, to check in QGIS. *(We don't really need to, I'm just curious)* -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f899bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GDF_Elv = GDF[['CODE', 'WS_BH_BOVENSTROOMS_L', 'WS_BH_BENEDENSTROOMS_L', 'DStr_code', 'DStr_ID']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94c1396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GDF_Elv['Diff'] = GDF_Elv['WS_BH_BOVENSTROOMS_L'] - GDF_Elv['WS_BH_BENEDENSTROOMS_L']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d77390a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GDF_Elv.loc[GDF_Elv['Diff'] == 0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b909abd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GDF_Elv.loc[ GDF_Elv['Diff'] < 0 ].sort_values(by='Diff', ascending=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7d2b21",
   "metadata": {},
   "source": [
    "<!-- ##### Let's see if any of the problematic segments have multiple UStr segments. That would make a solution harder to implement.<br>\n",
    "*(if there is only 1 UStr segment, the DStr Elv of the UStr segment can be modified to allow the UStr Elv of the current segmet to be increased as well, but if there are multiple, this becomes more complicated)* -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5012c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# l_problematic = GDF_Elv.loc[ GDF_Elv['Diff'] < 0, 'CODE'].tolist()\n",
    "# for S in l_problematic:\n",
    "#     sum = (GDF['DStr_code']==S).sum()\n",
    "#     if sum > 1:\n",
    "#         print(S, sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d17e70f",
   "metadata": {},
   "source": [
    "<!-- There are multiple segments with more than 1 UStr segment. We'll have to consider this when designing the elevation correction logic.  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71825474",
   "metadata": {},
   "source": [
    "<!-- ##### Elv correction algorithm -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdae325",
   "metadata": {},
   "source": [
    "<!-- We'll design an algorithm to fix those with <. Those with = will be fixed by SFR itself (hopefully). The following abbreviations are useful for explaining the concept:\n",
    "- A: DStr Elv of DStr segment\n",
    "- B: UStr Elv of DStr segment\n",
    "- C: DStr Elv of current segment\n",
    "- D: UStr Elv of current segment\n",
    "- F: DStr Elv of UStr segment(s)\n",
    "\n",
    "Here is the idea behind the algorithm:\n",
    "1. If **C > D & B <= D** :<br>\n",
    "-> Set **C = D**\n",
    "2. If **C > D & B > D** :<br>\n",
    "-> Set **C = D**. Set **B = D**\n",
    "3. If **C <= D** :<br>\n",
    "-> **No action**.\n",
    "\n",
    "Repeat till there are no segments with C < D.\n",
    "\n",
    "When there is no downstream segment, we apply the logic used in case 1. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550445c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GDF_Elv = GDF_Elv.merge(GDF[['CODE', 'WS_BH_BOVENSTROOMS_L', 'WS_BH_BENEDENSTROOMS_L']], left_on='DStr_code', right_on='CODE', suffixes=('', '_DStr'), how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ad0246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GDF_Elv[['A', 'B']] = GDF_Elv[['WS_BH_BENEDENSTROOMS_L_DStr', 'WS_BH_BOVENSTROOMS_L_DStr']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbafec33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GDF_Elv[['C', 'D']] = GDF_Elv[['WS_BH_BENEDENSTROOMS_L', 'WS_BH_BOVENSTROOMS_L']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28277e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GDF_Elv[GDF_Elv['B'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051bc5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init = GDF_Elv.loc[ GDF_Elv['CODE']=='OVK02121', 'B' ].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3a6794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def adjust_elevations(row):\n",
    "#     if row['C'] <= row['D']: # If UStr Elv <= DStr Elv, no adjustment needed\n",
    "#         return row['B'], row['C']\n",
    "#     elif (row['C'] > row['D']) and (pd.isna(row['B'])): # If UStr Elv <= DStr Elv but DStr Elv is missing (OuFl segment), set both to DStr Elv\n",
    "#         return pd.NA, row['D']\n",
    "#     elif (row['C'] > row['D']) and (row['B'] <= row['D']):\n",
    "#         return row['B'], row['D']\n",
    "#     elif (row['C'] > row['D']) and (row['B'] > row['D']):\n",
    "#         return row['D'], row['D']\n",
    "#     else:\n",
    "#         # Default case - should not happen, but ensures function always returns a tuple\n",
    "#         return row['B'], row['C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5fa328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GDF_Elv[['B_', 'C_']] = GDF_Elv.apply(adjust_elevations, axis=1, result_type='expand')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35536e68",
   "metadata": {},
   "source": [
    "<!-- I'm worried consequtive segments might be problematic. Let's check if there are any. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b790c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GDF_Elv_unfixed = GDF_Elv[ (GDF_Elv['Diff']<0)]\n",
    "# consequtive = GDF_Elv_unfixed.loc[GDF_Elv_unfixed['DStr_code'].isin(GDF_Elv_unfixed['CODE']), 'DStr_code']\n",
    "# GDF_Elv_unfixed.loc[ (GDF_Elv_unfixed['CODE'].isin(consequtive)) | (GDF_Elv_unfixed['DStr_code'].isin(consequtive)), ['CODE', 'DStr_code', 'A', 'B', 'B_', 'C', 'C_', 'D']].sort_values(by='D').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc8c772",
   "metadata": {},
   "source": [
    "<!-- Consequtive ok. Let's check if there is a drop in Elv (positive slope) for each segment. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84928f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GDF_Elv.loc[ GDF_Elv['D'] - GDF_Elv['C_'] < 0 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a17fcd0",
   "metadata": {},
   "source": [
    "<!-- Cool, no segments without any drop in Elv. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dac82de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GDF_Elv['segment_drop'] = GDF_Elv['D'] - GDF_Elv['C_']\n",
    "# GDF_Elv['DStr_drop'] = GDF_Elv['C_'] - GDF_Elv['B']\n",
    "# GDF_Elv.loc[ GDF_Elv['C_'] - GDF_Elv['B_'] < 0 , ['CODE', 'DStr_code', 'A', 'B', 'B_', 'C', 'C_', 'D', 'segment_drop', 'DStr_drop'] ].sort_values(by='DStr_drop').reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69f5ed3",
   "metadata": {},
   "source": [
    "<!-- There are **quite a few** segments where C_ > B!!! SFRmaker might fix this. If not, I'll come back and fix it. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ecf0a5",
   "metadata": {},
   "source": [
    "<!-- #### Conclusion -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0c6d50",
   "metadata": {},
   "source": [
    "<!-- **Custom hydrography** <br>\n",
    "Any Polyline shapefile can be supplied in lieu of NHDPlus, but it must have the following columns, as shown in the second example:\n",
    "1. flowlines_file: path to shapefile <br>\n",
    "    -> **Pa_GPkg_1ry** <br>\n",
    "2. id_column: unique identifier for each polyline <br>\n",
    "    -> **OBJECTID** <br>\n",
    "3. routing_column: downstream connection (ID), 0 if none <br>\n",
    "    -> **DStr_ID** <br>\n",
    "4. width1_column: channel width at start of line, in attr\\_length\\_units (optional) <br>\n",
    "    -> **WS_BODEMBREEDTE_L** <br>\n",
    "5. width2_column: channel width at end of line, in attr_length_units (optional) <br>\n",
    "    -> **WS_BODEMBREEDTE_L** <br>\n",
    "6. up_elevation_column: streambed elevation at start of line, in attr_height_units <br>\n",
    "    -> **WS_BH_BOVENSTROOMS_L** <br>\n",
    "7. dn_elevation_column: streambed elevation at end of line, in attr_height_units <br>\n",
    "    -> **WS_BH_BENEDENSTROOMS_L** <br>\n",
    "8. name_column: stream name (optional) <br>\n",
    "    -> **CODE** <br>\n",
    "9. attr_length_units: channel width units <br>\n",
    "    -> **'m'** <br>\n",
    "10. attr_height_units: streambed elevation units <br>\n",
    "    -> **'m'** <br> -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081692cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GDF_Elv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c310fe76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GDF_copy = GDF.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ca3d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GDF = GDF_copy.copy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
