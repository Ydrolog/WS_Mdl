{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45323fb4",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bde7958",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from os import listdir as LD, makedirs as MDs\n",
    "from os.path import join as PJ, basename as PBN, dirname as PDN, exists as PE\n",
    "import pandas as pd\n",
    "from datetime import datetime as DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d4f76d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imod import msw\n",
    "from imod import mf6\n",
    "import primod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae3f08e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import WS_Mdl.utils as U\n",
    "import WS_Mdl.utils_imod as UIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baa0e0c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'WS_Mdl.utils_imod' from 'C:\\\\Users\\\\Karam014\\\\OneDrive - Universiteit Utrecht\\\\WS_Mdl\\\\code\\\\WS_Mdl\\\\utils_imod.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib as IL\n",
    "IL.reload(U)\n",
    "IL.reload(UIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2125c45b",
   "metadata": {},
   "source": [
    "# Options + Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7302b9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "MdlN = 'NBr32'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce246892",
   "metadata": {},
   "outputs": [],
   "source": [
    "U.set_verbose(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a543c73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load paths and variables from PRJ & INI\n",
    "d_Pa = U.get_MdlN_Pa(MdlN)\n",
    "Pa_PRJ = d_Pa['PRJ']\n",
    "Dir_PRJ = PDN(Pa_PRJ)\n",
    "d_INI = U.INI_to_d(d_Pa['INI'])\n",
    "Xmin, Ymin, Xmax, Ymax = [float(i) for i in d_INI['WINDOW'].split(',')]\n",
    "SP_date_1st, SP_date_last = [DT.strftime(DT.strptime(d_INI[f'{i}'], '%Y%m%d'), '%Y-%m-%d') for i in ['SDATE', 'EDATE']]\n",
    "dx = dy = float(d_INI['CELLSIZE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1479689a",
   "metadata": {},
   "source": [
    "# Load PRJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2db71674",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRJ_, PRJ_OBS = UIM.open_PRJ_with_OBS(Pa_PRJ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f43af1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRJ, period_data = PRJ_[0], PRJ_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f95b2563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRJ['msw'] = PRJ.pop('cap') # Rename 'cap' to 'msw' for consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2f13d7",
   "metadata": {},
   "source": [
    "# Load DIS and limit to Mdl Aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cc7e265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🟢 - INI file C:/OD/WS_Mdl\\models/NBr\\code/Mdl_Prep/Mdl_Prep_NBr32.ini read successfully. Dictionary created with 21 keys.\n",
      "🟢 - model dimensions extracted from C:/OD/WS_Mdl\\models/NBr\\code/Mdl_Prep/Mdl_Prep_NBr32.ini.\n",
      "\n",
      "Target grid: 480x344 cells at 25.0x-25.0 m resolution\n",
      "\n",
      "Target extents: X=[113112.5, 125087.5], Y=[387612.5, 396187.5]\n",
      "Processing cap...\n",
      "  cap.urban_infiltration_capacity: ⚪️ - No spatial dims - keeping original\n",
      "  cap.soil_physical_unit: 🟢 - Frozen({'layer': 1, 'y': 344, 'x': 480}) -> Frozen({'layer': 1, 'y': 344, 'x': 480})\n",
      "  cap.rootzone_thickness: ⚪️ - Using nearest neighbor for categorical data\n",
      "  cap.rootzone_thickness: 🟢 - Frozen({'layer': 1, 'y': 344, 'x': 480}) -> Frozen({'layer': 1, 'y': 344, 'x': 480})\n",
      "  cap.rural_runoff_resistance: ⚪️ - No spatial dims - keeping original\n",
      "  cap.rural_runon_resistance: ⚪️ - No spatial dims - keeping original\n",
      "  cap.urban_runoff_resistance: ⚪️ - No spatial dims - keeping original\n",
      "  cap.urban_ponding_depth: ⚪️ - No spatial dims - keeping original\n",
      "  cap.artificial_recharge_capacity: ⚪️ - No spatial dims - keeping original\n",
      "  cap.landuse: ⚪️ - Using nearest neighbor for categorical data\n",
      "  cap.landuse: 🟢 - Frozen({'layer': 1, 'y': 344, 'x': 480}) -> Frozen({'layer': 1, 'y': 344, 'x': 480})\n",
      "  cap.perched_water_table_level: ⚪️ - No spatial dims - keeping original\n",
      "  cap.artificial_recharge_layer: 🟢 - Frozen({'layer': 1, 'y': 344, 'x': 480}) -> Frozen({'layer': 1, 'y': 344, 'x': 480})\n",
      "  cap.soil_moisture_fraction: ⚪️ - No spatial dims - keeping original\n",
      "  cap.conductivitiy_factor: ⚪️ - No spatial dims - keeping original\n",
      "  cap.rural_infiltration_capacity: ⚪️ - No spatial dims - keeping original\n",
      "  cap.surface_elevation: 🟢 - Frozen({'layer': 1, 'y': 344, 'x': 480}) -> Frozen({'layer': 1, 'y': 344, 'x': 480})\n",
      "  cap.urban_area: 🟢 - Area field regridded with grid ratio scaling\n",
      "  cap.artificial_recharge: 🟢 - Frozen({'layer': 1, 'y': 344, 'x': 480}) -> Frozen({'layer': 1, 'y': 344, 'x': 480})\n",
      "  cap.rural_ponding_depth: ⚪️ - No spatial dims - keeping original\n",
      "  cap.urban_runon_resistance: ⚪️ - No spatial dims - keeping original\n",
      "  cap.boundary: 🟢 - Frozen({'layer': 1, 'y': 86, 'x': 120}) -> Frozen({'layer': 1, 'y': 344, 'x': 480})\n",
      "  cap.meteo_station_number: 🟢 - Frozen({'layer': 1, 'y': 86, 'x': 120}) -> Frozen({'layer': 1, 'y': 344, 'x': 480})\n",
      "  cap.wetted_area: 🟢 - Area field regridded with grid ratio scaling\n",
      "Processing extra...\n",
      "  extra.paths: ⚪️ - No spatial dims - keeping original\n",
      "  extra.active: ⚪️ - No spatial dims - keeping original\n",
      "Processing bnd...\n",
      "  bnd.ibound: ⚪️ - Using nearest neighbor for boundary conditions\n",
      "  bnd.ibound: 🟢 - Frozen({'layer': 37, 'y': 86, 'x': 120}) -> Frozen({'layer': 37, 'y': 344, 'x': 480})\n",
      "Processing top...\n",
      "  top.top: 🟢 - Frozen({'layer': 37, 'y': 86, 'x': 120}) -> Frozen({'layer': 37, 'y': 344, 'x': 480})\n",
      "Processing bot...\n",
      "  bot.bottom: 🟢 - Frozen({'layer': 37, 'y': 86, 'x': 120}) -> Frozen({'layer': 37, 'y': 344, 'x': 480})\n",
      "Processing khv...\n",
      "  khv.kh: 🟢 - Frozen({'layer': 37, 'y': 86, 'x': 120}) -> Frozen({'layer': 37, 'y': 344, 'x': 480})\n",
      "Processing kva...\n",
      "  kva.vertical_anisotropy: ⚪️ - No spatial dims - keeping original\n",
      "Processing shd...\n",
      "  shd.head: 🟢 - Frozen({'layer': 37, 'y': 86, 'x': 120}) -> Frozen({'layer': 37, 'y': 344, 'x': 480})\n",
      "Processing sto...\n",
      "  sto.storage_coefficient: ⚪️ - No spatial dims - keeping original\n",
      "Processing spy...\n",
      "  spy.specific_yield: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-1...\n",
      "  hfb-1.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-1.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-2...\n",
      "  hfb-2.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-2.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-3...\n",
      "  hfb-3.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-3.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-4...\n",
      "  hfb-4.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-4.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-5...\n",
      "  hfb-5.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-5.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-6...\n",
      "  hfb-6.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-6.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-7...\n",
      "  hfb-7.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-7.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-8...\n",
      "  hfb-8.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-8.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-9...\n",
      "  hfb-9.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-9.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-10...\n",
      "  hfb-10.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-10.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-11...\n",
      "  hfb-11.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-11.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-12...\n",
      "  hfb-12.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-12.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-13...\n",
      "  hfb-13.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-13.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-14...\n",
      "  hfb-14.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-14.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-15...\n",
      "  hfb-15.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-15.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-16...\n",
      "  hfb-16.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-16.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-17...\n",
      "  hfb-17.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-17.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-18...\n",
      "  hfb-18.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-18.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-19...\n",
      "  hfb-19.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-19.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-20...\n",
      "  hfb-20.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-20.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-21...\n",
      "  hfb-21.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-21.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-22...\n",
      "  hfb-22.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-22.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-23...\n",
      "  hfb-23.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-23.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-24...\n",
      "  hfb-24.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-24.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-25...\n",
      "  hfb-25.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-25.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-26...\n",
      "  hfb-26.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-26.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-27...\n",
      "  hfb-27.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-27.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-28...\n",
      "  hfb-28.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-28.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-29...\n",
      "  hfb-29.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-29.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-30...\n",
      "  hfb-30.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-30.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-31...\n",
      "  hfb-31.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-31.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-32...\n",
      "  hfb-32.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-32.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-33...\n",
      "  hfb-33.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-33.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-34...\n",
      "  hfb-34.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-34.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-35...\n",
      "  hfb-35.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-35.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-36...\n",
      "  hfb-36.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-36.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-37...\n",
      "  hfb-37.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-37.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-38...\n",
      "  hfb-38.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-38.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-39...\n",
      "  hfb-39.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-39.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-40...\n",
      "  hfb-40.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-40.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-41...\n",
      "  hfb-41.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-41.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-42...\n",
      "  hfb-42.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-42.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-43...\n",
      "  hfb-43.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-43.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-44...\n",
      "  hfb-44.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-44.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-45...\n",
      "  hfb-45.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-45.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-46...\n",
      "  hfb-46.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-46.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-47...\n",
      "  hfb-47.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-47.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-48...\n",
      "  hfb-48.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-48.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-49...\n",
      "  hfb-49.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-49.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-50...\n",
      "  hfb-50.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-50.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-51...\n",
      "  hfb-51.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-51.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-52...\n",
      "  hfb-52.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-52.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-53...\n",
      "  hfb-53.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-53.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-54...\n",
      "  hfb-54.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-54.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-55...\n",
      "  hfb-55.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-55.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-56...\n",
      "  hfb-56.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-56.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-57...\n",
      "  hfb-57.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-57.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-58...\n",
      "  hfb-58.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-58.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-59...\n",
      "  hfb-59.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-59.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-60...\n",
      "  hfb-60.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-60.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-61...\n",
      "  hfb-61.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-61.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-62...\n",
      "  hfb-62.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-62.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-63...\n",
      "  hfb-63.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-63.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-64...\n",
      "  hfb-64.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-64.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-65...\n",
      "  hfb-65.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-65.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-66...\n",
      "  hfb-66.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-66.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-67...\n",
      "  hfb-67.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-67.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-68...\n",
      "  hfb-68.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-68.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-69...\n",
      "  hfb-69.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-69.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-70...\n",
      "  hfb-70.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-70.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-71...\n",
      "  hfb-71.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-71.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-72...\n",
      "  hfb-72.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-72.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-73...\n",
      "  hfb-73.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-73.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-74...\n",
      "  hfb-74.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-74.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-75...\n",
      "  hfb-75.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-75.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-76...\n",
      "  hfb-76.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-76.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-77...\n",
      "  hfb-77.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-77.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-78...\n",
      "  hfb-78.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-78.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-79...\n",
      "  hfb-79.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-79.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-80...\n",
      "  hfb-80.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-80.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-81...\n",
      "  hfb-81.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-81.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-82...\n",
      "  hfb-82.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-82.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-83...\n",
      "  hfb-83.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-83.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-84...\n",
      "  hfb-84.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-84.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-85...\n",
      "  hfb-85.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-85.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-86...\n",
      "  hfb-86.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-86.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-87...\n",
      "  hfb-87.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-87.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-88...\n",
      "  hfb-88.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-88.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-89...\n",
      "  hfb-89.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-89.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-90...\n",
      "  hfb-90.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-90.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-91...\n",
      "  hfb-91.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-91.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-92...\n",
      "  hfb-92.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-92.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-93...\n",
      "  hfb-93.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-93.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-94...\n",
      "  hfb-94.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-94.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-95...\n",
      "  hfb-95.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-95.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-96...\n",
      "  hfb-96.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-96.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-97...\n",
      "  hfb-97.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-97.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-98...\n",
      "  hfb-98.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-98.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-99...\n",
      "  hfb-99.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-99.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-100...\n",
      "  hfb-100.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-100.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-101...\n",
      "  hfb-101.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-101.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-102...\n",
      "  hfb-102.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-102.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-103...\n",
      "  hfb-103.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-103.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-104...\n",
      "  hfb-104.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-104.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-105...\n",
      "  hfb-105.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-105.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-106...\n",
      "  hfb-106.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-106.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-107...\n",
      "  hfb-107.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-107.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-108...\n",
      "  hfb-108.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-108.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-109...\n",
      "  hfb-109.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-109.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-110...\n",
      "  hfb-110.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-110.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-111...\n",
      "  hfb-111.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-111.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-112...\n",
      "  hfb-112.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-112.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-113...\n",
      "  hfb-113.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-113.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-114...\n",
      "  hfb-114.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-114.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-115...\n",
      "  hfb-115.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-115.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-116...\n",
      "  hfb-116.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-116.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-117...\n",
      "  hfb-117.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-117.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-118...\n",
      "  hfb-118.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-118.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-119...\n",
      "  hfb-119.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-119.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-120...\n",
      "  hfb-120.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-120.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-121...\n",
      "  hfb-121.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-121.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-122...\n",
      "  hfb-122.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-122.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-123...\n",
      "  hfb-123.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-123.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-124...\n",
      "  hfb-124.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-124.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-125...\n",
      "  hfb-125.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-125.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-126...\n",
      "  hfb-126.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-126.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-127...\n",
      "  hfb-127.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-127.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-128...\n",
      "  hfb-128.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-128.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-129...\n",
      "  hfb-129.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-129.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-130...\n",
      "  hfb-130.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-130.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-131...\n",
      "  hfb-131.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-131.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-132...\n",
      "  hfb-132.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-132.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-133...\n",
      "  hfb-133.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-133.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-134...\n",
      "  hfb-134.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-134.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-135...\n",
      "  hfb-135.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-135.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-136...\n",
      "  hfb-136.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-136.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-137...\n",
      "  hfb-137.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-137.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-138...\n",
      "  hfb-138.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-138.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-139...\n",
      "  hfb-139.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-139.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-140...\n",
      "  hfb-140.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-140.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-141...\n",
      "  hfb-141.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-141.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-142...\n",
      "  hfb-142.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-142.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-143...\n",
      "  hfb-143.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-143.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-144...\n",
      "  hfb-144.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-144.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-145...\n",
      "  hfb-145.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-145.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-146...\n",
      "  hfb-146.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-146.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-147...\n",
      "  hfb-147.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-147.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-148...\n",
      "  hfb-148.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-148.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-149...\n",
      "  hfb-149.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-149.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing hfb-150...\n",
      "  hfb-150.geodataframe: ⚪️ - No spatial dims - keeping original\n",
      "  hfb-150.layer: ⚪️ - No spatial dims - keeping original\n",
      "Processing drn-1...\n",
      "  drn-1.conductance: 🟢 - Frozen({'time': 1, 'layer': 1, 'y': 344, 'x': 480}) -> Frozen({'time': 1, 'layer': 1, 'y': 344, 'x': 480})\n",
      "  drn-1.elevation: 🟢 - Frozen({'time': 1, 'layer': 1, 'y': 344, 'x': 480}) -> Frozen({'time': 1, 'layer': 1, 'y': 344, 'x': 480})\n",
      "Processing drn-2...\n",
      "  drn-2.conductance: 🟢 - Frozen({'time': 1, 'layer': 1, 'y': 344, 'x': 480}) -> Frozen({'time': 1, 'layer': 1, 'y': 344, 'x': 480})\n",
      "  drn-2.elevation: 🟢 - Frozen({'time': 1, 'layer': 1, 'y': 344, 'x': 480}) -> Frozen({'time': 1, 'layer': 1, 'y': 344, 'x': 480})\n",
      "Processing drn-3...\n",
      "  drn-3.conductance: 🟢 - Frozen({'time': 1, 'layer': 1, 'y': 35, 'x': 48}) -> Frozen({'time': 1, 'layer': 1, 'y': 344, 'x': 480})\n",
      "  drn-3.elevation: 🟢 - Frozen({'time': 1, 'layer': 1, 'y': 344, 'x': 480}) -> Frozen({'time': 1, 'layer': 1, 'y': 344, 'x': 480})\n",
      "Processing riv-1...\n",
      "  riv-1.conductance: 🟢 - Frozen({'time': 1, 'layer': 1, 'y': 344, 'x': 480}) -> Frozen({'time': 1, 'layer': 1, 'y': 344, 'x': 480})\n",
      "  riv-1.stage: 🟢 - Frozen({'time': 1, 'layer': 1, 'y': 344, 'x': 480}) -> Frozen({'time': 1, 'layer': 1, 'y': 344, 'x': 480})\n",
      "  riv-1.bottom_elevation: 🟢 - Frozen({'time': 1, 'layer': 1, 'y': 344, 'x': 480}) -> Frozen({'time': 1, 'layer': 1, 'y': 344, 'x': 480})\n",
      "  riv-1.infiltration_factor: ⚪️ - No spatial dims - keeping original\n",
      "Processing riv-2...\n",
      "  riv-2.conductance: 🟢 - Frozen({'time': 1, 'layer': 1, 'y': 344, 'x': 480}) -> Frozen({'time': 1, 'layer': 1, 'y': 344, 'x': 480})\n",
      "  riv-2.stage: 🟢 - Frozen({'time': 1, 'layer': 1, 'y': 35, 'x': 48}) -> Frozen({'time': 1, 'layer': 1, 'y': 344, 'x': 480})\n",
      "  riv-2.bottom_elevation: 🟢 - Frozen({'time': 1, 'layer': 1, 'y': 344, 'x': 480}) -> Frozen({'time': 1, 'layer': 1, 'y': 344, 'x': 480})\n",
      "  riv-2.infiltration_factor: ⚪️ - No spatial dims - keeping original\n",
      "Processing riv-3...\n",
      "  riv-3.conductance: 🟢 - Frozen({'time': 1, 'layer': 1, 'y': 344, 'x': 480}) -> Frozen({'time': 1, 'layer': 1, 'y': 344, 'x': 480})\n",
      "  riv-3.stage: 🟢 - Frozen({'time': 1, 'layer': 1, 'y': 35, 'x': 48}) -> Frozen({'time': 1, 'layer': 1, 'y': 344, 'x': 480})\n",
      "  riv-3.bottom_elevation: 🟢 - Frozen({'time': 1, 'layer': 1, 'y': 35, 'x': 48}) -> Frozen({'time': 1, 'layer': 1, 'y': 344, 'x': 480})\n",
      "  riv-3.infiltration_factor: ⚪️ - No spatial dims - keeping original\n",
      "Processing riv-4...\n",
      "  riv-4.conductance: 🟢 - Frozen({'time': 1, 'layer': 1, 'y': 86, 'x': 120}) -> Frozen({'time': 1, 'layer': 1, 'y': 344, 'x': 480})\n",
      "  riv-4.stage: 🟢 - Frozen({'time': 1, 'layer': 1, 'y': 86, 'x': 120}) -> Frozen({'time': 1, 'layer': 1, 'y': 344, 'x': 480})\n",
      "  riv-4.bottom_elevation: 🟢 - Frozen({'time': 1, 'layer': 1, 'y': 86, 'x': 120}) -> Frozen({'time': 1, 'layer': 1, 'y': 344, 'x': 480})\n",
      "  riv-4.infiltration_factor: ⚪️ - No spatial dims - keeping original\n",
      "Processing riv-5...\n",
      "  riv-5.conductance: 🟢 - Frozen({'time': 1, 'layer': 1, 'y': 35, 'x': 48}) -> Frozen({'time': 1, 'layer': 1, 'y': 344, 'x': 480})\n",
      "  riv-5.stage: 🟢 - Frozen({'time': 1, 'layer': 1, 'y': 35, 'x': 48}) -> Frozen({'time': 1, 'layer': 1, 'y': 344, 'x': 480})\n",
      "  riv-5.bottom_elevation: 🟢 - Frozen({'time': 1, 'layer': 1, 'y': 35, 'x': 48}) -> Frozen({'time': 1, 'layer': 1, 'y': 344, 'x': 480})\n",
      "  riv-5.infiltration_factor: ⚪️ - No spatial dims - keeping original\n",
      "Processing wel-WEL_Ind_Aa_and_Maas_T_NBr1...\n",
      "  wel-WEL_Ind_Aa_and_Maas_T_NBr1.has_associated: ⚪️ - No spatial dims - keeping original\n",
      "  wel-WEL_Ind_Aa_and_Maas_T_NBr1.dataframe: ⚪️ - No spatial dims - keeping original\n",
      "  wel-WEL_Ind_Aa_and_Maas_T_NBr1.layer: ⚪️ - No spatial dims - keeping original\n",
      "  wel-WEL_Ind_Aa_and_Maas_T_NBr1.time: ⚪️ - No spatial dims - keeping original\n",
      "  wel-WEL_Ind_Aa_and_Maas_T_NBr1.factor: ⚪️ - No spatial dims - keeping original\n",
      "  wel-WEL_Ind_Aa_and_Maas_T_NBr1.addition: ⚪️ - No spatial dims - keeping original\n",
      "Processing wel-WEL_Ind_Br_T_NBr1...\n",
      "  wel-WEL_Ind_Br_T_NBr1.has_associated: ⚪️ - No spatial dims - keeping original\n",
      "  wel-WEL_Ind_Br_T_NBr1.dataframe: ⚪️ - No spatial dims - keeping original\n",
      "  wel-WEL_Ind_Br_T_NBr1.layer: ⚪️ - No spatial dims - keeping original\n",
      "  wel-WEL_Ind_Br_T_NBr1.time: ⚪️ - No spatial dims - keeping original\n",
      "  wel-WEL_Ind_Br_T_NBr1.factor: ⚪️ - No spatial dims - keeping original\n",
      "  wel-WEL_Ind_Br_T_NBr1.addition: ⚪️ - No spatial dims - keeping original\n",
      "Processing wel-WEL_Br_Wa_T_NBr1...\n",
      "  wel-WEL_Br_Wa_T_NBr1.has_associated: ⚪️ - No spatial dims - keeping original\n",
      "  wel-WEL_Br_Wa_T_NBr1.dataframe: ⚪️ - No spatial dims - keeping original\n",
      "  wel-WEL_Br_Wa_T_NBr1.layer: ⚪️ - No spatial dims - keeping original\n",
      "  wel-WEL_Br_Wa_T_NBr1.time: ⚪️ - No spatial dims - keeping original\n",
      "  wel-WEL_Br_Wa_T_NBr1.factor: ⚪️ - No spatial dims - keeping original\n",
      "  wel-WEL_Br_Wa_T_NBr1.addition: ⚪️ - No spatial dims - keeping original\n",
      "Processing pcg...\n",
      "  pcg.mxiter: ⚪️ - No spatial dims - keeping original\n",
      "  pcg.iter1: ⚪️ - No spatial dims - keeping original\n",
      "  pcg.hclose: ⚪️ - No spatial dims - keeping original\n",
      "  pcg.rclose: ⚪️ - No spatial dims - keeping original\n",
      "  pcg.relax: ⚪️ - No spatial dims - keeping original\n",
      "  pcg.npcond: ⚪️ - No spatial dims - keeping original\n",
      "  pcg.iprpcg: ⚪️ - No spatial dims - keeping original\n",
      "  pcg.mutpcg: ⚪️ - No spatial dims - keeping original\n",
      "  pcg.damppcg: ⚪️ - No spatial dims - keeping original\n",
      "  pcg.damppcgt: ⚪️ - No spatial dims - keeping original\n",
      "  pcg.iqerror: ⚪️ - No spatial dims - keeping original\n",
      "  pcg.qerror: ⚪️ - No spatial dims - keeping original\n",
      "  pcg.active: ⚪️ - No spatial dims - keeping original\n",
      "Processing chd-1...\n",
      "  chd-1.head: 🟢 - Frozen({'time': 109, 'layer': 1, 'y': 86, 'x': 120}) -> Frozen({'time': 109, 'layer': 1, 'y': 344, 'x': 480})\n",
      "Processing chd-2...\n",
      "  chd-2.head: 🟢 - Frozen({'time': 109, 'layer': 1, 'y': 86, 'x': 120}) -> Frozen({'time': 109, 'layer': 1, 'y': 344, 'x': 480})\n",
      "Processing chd-3...\n",
      "  chd-3.head: 🟢 - Frozen({'time': 109, 'layer': 1, 'y': 86, 'x': 120}) -> Frozen({'time': 109, 'layer': 1, 'y': 344, 'x': 480})\n",
      "Processing chd-4...\n",
      "  chd-4.head: 🟢 - Frozen({'time': 109, 'layer': 1, 'y': 86, 'x': 120}) -> Frozen({'time': 109, 'layer': 1, 'y': 344, 'x': 480})\n",
      "Processing chd-5...\n",
      "  chd-5.head: 🟢 - Frozen({'time': 109, 'layer': 1, 'y': 86, 'x': 120}) -> Frozen({'time': 109, 'layer': 1, 'y': 344, 'x': 480})\n",
      "Processing chd-6...\n",
      "  chd-6.head: 🟢 - Frozen({'time': 109, 'layer': 1, 'y': 86, 'x': 120}) -> Frozen({'time': 109, 'layer': 1, 'y': 344, 'x': 480})\n",
      "Processing chd-7...\n",
      "  chd-7.head: 🟢 - Frozen({'time': 109, 'layer': 1, 'y': 86, 'x': 120}) -> Frozen({'time': 109, 'layer': 1, 'y': 344, 'x': 480})\n",
      "Processing chd-8...\n",
      "  chd-8.head: 🟢 - Frozen({'time': 109, 'layer': 1, 'y': 86, 'x': 120}) -> Frozen({'time': 109, 'layer': 1, 'y': 344, 'x': 480})\n",
      "Processing chd-9...\n",
      "  chd-9.head: 🟢 - Frozen({'time': 109, 'layer': 1, 'y': 86, 'x': 120}) -> Frozen({'time': 109, 'layer': 1, 'y': 344, 'x': 480})\n",
      "Processing chd-10...\n",
      "  chd-10.head: 🟢 - Frozen({'time': 109, 'layer': 1, 'y': 86, 'x': 120}) -> Frozen({'time': 109, 'layer': 1, 'y': 344, 'x': 480})\n",
      "Processing chd-11...\n",
      "  chd-11.head: 🟢 - Frozen({'time': 109, 'layer': 1, 'y': 86, 'x': 120}) -> Frozen({'time': 109, 'layer': 1, 'y': 344, 'x': 480})\n",
      "Processing chd-12...\n",
      "  chd-12.head: 🟢 - Frozen({'time': 109, 'layer': 1, 'y': 86, 'x': 120}) -> Frozen({'time': 109, 'layer': 1, 'y': 344, 'x': 480})\n",
      "Processing chd-13...\n",
      "  chd-13.head: 🟢 - Frozen({'time': 109, 'layer': 1, 'y': 86, 'x': 120}) -> Frozen({'time': 109, 'layer': 1, 'y': 344, 'x': 480})\n",
      "Processing chd-14...\n",
      "  chd-14.head: 🟢 - Frozen({'time': 109, 'layer': 1, 'y': 86, 'x': 120}) -> Frozen({'time': 109, 'layer': 1, 'y': 344, 'x': 480})\n",
      "Processing chd-15...\n",
      "  chd-15.head: 🟢 - Frozen({'time': 109, 'layer': 1, 'y': 86, 'x': 120}) -> Frozen({'time': 109, 'layer': 1, 'y': 344, 'x': 480})\n",
      "Processing chd-16...\n",
      "  chd-16.head: 🟢 - Frozen({'time': 109, 'layer': 1, 'y': 86, 'x': 120}) -> Frozen({'time': 109, 'layer': 1, 'y': 344, 'x': 480})\n",
      "Processing chd-17...\n",
      "  chd-17.head: 🟢 - Frozen({'time': 109, 'layer': 1, 'y': 86, 'x': 120}) -> Frozen({'time': 109, 'layer': 1, 'y': 344, 'x': 480})\n",
      "Processing chd-18...\n",
      "  chd-18.head: 🟢 - Frozen({'time': 109, 'layer': 1, 'y': 86, 'x': 120}) -> Frozen({'time': 109, 'layer': 1, 'y': 344, 'x': 480})\n",
      "Processing chd-19...\n",
      "  chd-19.head: 🟢 - Frozen({'time': 109, 'layer': 1, 'y': 86, 'x': 120}) -> Frozen({'time': 109, 'layer': 1, 'y': 344, 'x': 480})\n",
      "🟢🟢🟢 - Regridding complete.\n"
     ]
    }
   ],
   "source": [
    "U.set_verbose(True)\n",
    "IL.reload(UIM) #666\n",
    "PRJ_regrid = UIM.regrid_PRJ(PRJ, MdlN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d427856",
   "metadata": {},
   "source": [
    "# Load MF6 Mdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa7236f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = pd.date_range(SP_date_1st, SP_date_last, freq='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6004d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRJ_no_MSW = PRJ.copy()\n",
    "# PRJ_MSW = {}\n",
    "# if 'msw' in PRJ_no_MSW:\n",
    "#     PRJ_MSW['msw'] = PRJ_no_MSW['msw']\n",
    "#     PRJ_MSW['extra'] = PRJ_no_MSW['extra']\n",
    "#     del PRJ_no_MSW['msw'], PRJ_no_MSW['extra']\n",
    "#     print(\"Removed MSW/CAP package due to mixed grid compatibility issues\")\n",
    "\n",
    "# Sim_MF6 = mf6.Modflow6Simulation.from_imod5_data(PRJ_no_MSW, period_data, times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d0756a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert IMOD5 to MODFLOW6 (with proper error handling)\n",
    "# # First separate MSW package and fix temporal data issues\n",
    "\n",
    "# print(\"=== PREPARING PRJ DATA FOR MF6 CONVERSION ===\")\n",
    "\n",
    "# PRJ_no_MSW = PRJ_regrid.copy()\n",
    "# PRJ_MSW = {}\n",
    "# if 'msw' in PRJ_no_MSW:\n",
    "#     PRJ_MSW['msw'] = PRJ_no_MSW['msw']\n",
    "#     PRJ_MSW['extra'] = PRJ_no_MSW['extra']\n",
    "#     del PRJ_no_MSW['msw'], PRJ_no_MSW['extra']\n",
    "#     print(\"Removed MSW/CAP package due to mixed grid compatibility issues\")\n",
    "\n",
    "# # Check for problematic temporal data in river packages\n",
    "# riv_keys = [key for key in PRJ_no_MSW.keys() if key.startswith('riv')]\n",
    "# print(f\"Found river packages: {riv_keys}\")\n",
    "\n",
    "# for riv_key in riv_keys:\n",
    "#     if hasattr(PRJ_no_MSW[riv_key], 'time') and 'repeat_stress' in PRJ_no_MSW[riv_key].coords:\n",
    "#         repeat_stress = PRJ_no_MSW[riv_key].coords['repeat_stress']\n",
    "#         print(f\"{riv_key} repeat_stress dtype: {repeat_stress.dtype}\")\n",
    "        \n",
    "#         # Fix mixed data types in repeat_stress if needed\n",
    "#         if repeat_stress.dtype != 'datetime64[ns]':\n",
    "#             print(f\"⚠️  Fixing {riv_key} repeat_stress data type...\")\n",
    "#             try:\n",
    "#                 if np.issubdtype(repeat_stress.dtype, np.number):\n",
    "#                     # Convert numeric to datetime\n",
    "#                     PRJ_no_MSW[riv_key] = PRJ_no_MSW[riv_key].assign_coords(\n",
    "#                         repeat_stress=times[:len(repeat_stress)]\n",
    "#                     )\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Could not fix {riv_key}: {e}\")\n",
    "#                 PRJ_no_MSW[riv_key] = PRJ_no_MSW[riv_key].drop_vars('repeat_stress', errors='ignore')\n",
    "\n",
    "# print(\"\\n=== ATTEMPTING MF6 CONVERSION ===\")\n",
    "# try:\n",
    "#     Sim_MF6 = mf6.Modflow6Simulation.from_imod5_data(PRJ_no_MSW, period_data, times)\n",
    "#     print(\"✅ Simulation created successfully!\")\n",
    "# except Exception as e:\n",
    "#     print(f\"❌ Conversion failed: {e}\")\n",
    "#     print(\"\\nTrying alternative approach...\")\n",
    "    \n",
    "#     # Alternative: Remove problematic packages temporarily\n",
    "#     PRJ_minimal = {k: v for k, v in PRJ_no_MSW.items() if not k.startswith('riv')}\n",
    "#     print(f\"Trying conversion without river packages: {list(PRJ_minimal.keys())[:10]}...\")\n",
    "    \n",
    "#     try:\n",
    "#         Sim_MF6 = mf6.Modflow6Simulation.from_imod5_data(PRJ_minimal, period_data, times)\n",
    "#         print(\"✅ Minimal simulation created successfully!\")\n",
    "#         print(\"Note: River packages were excluded due to temporal data issues\")\n",
    "#     except Exception as e2:\n",
    "#         print(f\"❌ Even minimal conversion failed: {e2}\")\n",
    "#         Sim_MF6 = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0c9c1e",
   "metadata": {},
   "source": [
    "Using original PRJ to load MF6 Mdl gives warnings (and it's very slow). Thus, well use the regridded PRJ, which is much faster. It can be further sped up by multi-processing, but this is not implemented yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f749ccb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sim_MF6_test = mf6.Modflow6Simulation.from_imod5_data(PRJ_regrid, period_data, times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13e2dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed cap/extra package due to mixed grid compatibility issues\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\mamba_envs\\WS\\Lib\\site-packages\\dask\\_task_spec.py:741: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "c:\\mamba_envs\\WS\\Lib\\site-packages\\dask\\_task_spec.py:741: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "c:\\mamba_envs\\WS\\Lib\\site-packages\\dask\\_task_spec.py:741: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "c:\\mamba_envs\\WS\\Lib\\site-packages\\dask\\_task_spec.py:741: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "c:\\mamba_envs\\WS\\Lib\\site-packages\\dask\\_task_spec.py:741: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "c:\\mamba_envs\\WS\\Lib\\site-packages\\dask\\_task_spec.py:741: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "c:\\mamba_envs\\WS\\Lib\\site-packages\\dask\\_task_spec.py:741: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "c:\\mamba_envs\\WS\\Lib\\site-packages\\dask\\_task_spec.py:741: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "c:\\mamba_envs\\WS\\Lib\\site-packages\\dask\\_task_spec.py:741: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "c:\\mamba_envs\\WS\\Lib\\site-packages\\dask\\_task_spec.py:741: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\mamba_envs\\WS\\Lib\\site-packages\\dask\\array\\chunk.py:279: RuntimeWarning: invalid value encountered in cast\n",
      "  return x.astype(astype_dtype, **kwargs)\n",
      "c:\\mamba_envs\\WS\\Lib\\site-packages\\dask\\array\\chunk.py:279: RuntimeWarning: invalid value encountered in cast\n",
      "  return x.astype(astype_dtype, **kwargs)\n",
      "c:\\mamba_envs\\WS\\Lib\\site-packages\\dask\\array\\chunk.py:279: RuntimeWarning: invalid value encountered in cast\n",
      "  return x.astype(astype_dtype, **kwargs)\n",
      "c:\\mamba_envs\\WS\\Lib\\site-packages\\dask\\array\\chunk.py:279: RuntimeWarning: invalid value encountered in cast\n",
      "  return x.astype(astype_dtype, **kwargs)\n",
      "c:\\mamba_envs\\WS\\Lib\\site-packages\\dask\\array\\chunk.py:279: RuntimeWarning: invalid value encountered in cast\n",
      "  return x.astype(astype_dtype, **kwargs)\n",
      "c:\\mamba_envs\\WS\\Lib\\site-packages\\dask\\array\\chunk.py:279: RuntimeWarning: invalid value encountered in cast\n",
      "  return x.astype(astype_dtype, **kwargs)\n",
      "c:\\mamba_envs\\WS\\Lib\\site-packages\\dask\\array\\chunk.py:279: RuntimeWarning: invalid value encountered in cast\n",
      "  return x.astype(astype_dtype, **kwargs)\n",
      "c:\\mamba_envs\\WS\\Lib\\site-packages\\dask\\array\\chunk.py:279: RuntimeWarning: invalid value encountered in cast\n",
      "  return x.astype(astype_dtype, **kwargs)\n",
      "c:\\mamba_envs\\WS\\Lib\\site-packages\\dask\\array\\chunk.py:279: RuntimeWarning: invalid value encountered in cast\n",
      "  return x.astype(astype_dtype, **kwargs)\n",
      "c:\\mamba_envs\\WS\\Lib\\site-packages\\dask\\array\\chunk.py:279: RuntimeWarning: invalid value encountered in cast\n",
      "  return x.astype(astype_dtype, **kwargs)\n",
      "c:\\mamba_envs\\WS\\Lib\\site-packages\\dask\\array\\chunk.py:279: RuntimeWarning: invalid value encountered in cast\n",
      "  return x.astype(astype_dtype, **kwargs)\n",
      "c:\\mamba_envs\\WS\\Lib\\site-packages\\dask\\array\\chunk.py:279: RuntimeWarning: invalid value encountered in cast\n",
      "  return x.astype(astype_dtype, **kwargs)\n",
      "c:\\mamba_envs\\WS\\Lib\\site-packages\\dask\\array\\chunk.py:279: RuntimeWarning: invalid value encountered in cast\n",
      "  return x.astype(astype_dtype, **kwargs)\n",
      "c:\\mamba_envs\\WS\\Lib\\site-packages\\dask\\_task_spec.py:741: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "c:\\mamba_envs\\WS\\Lib\\site-packages\\dask\\_task_spec.py:741: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "c:\\mamba_envs\\WS\\Lib\\site-packages\\dask\\_task_spec.py:741: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "c:\\mamba_envs\\WS\\Lib\\site-packages\\dask\\_task_spec.py:741: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "c:\\mamba_envs\\WS\\Lib\\site-packages\\dask\\_task_spec.py:741: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "c:\\mamba_envs\\WS\\Lib\\site-packages\\dask\\_task_spec.py:741: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "c:\\mamba_envs\\WS\\Lib\\site-packages\\dask\\_task_spec.py:741: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "c:\\mamba_envs\\WS\\Lib\\site-packages\\dask\\_task_spec.py:741: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "c:\\mamba_envs\\WS\\Lib\\site-packages\\dask\\_task_spec.py:741: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n",
      "c:\\mamba_envs\\WS\\Lib\\site-packages\\dask\\_task_spec.py:741: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n"
     ]
    }
   ],
   "source": [
    "PRJ_no_MSW = PRJ_regrid.copy()\n",
    "PRJ_MSW = {}\n",
    "if 'cap' in PRJ_no_MSW:\n",
    "    PRJ_MSW['cap'] = PRJ_no_MSW['cap']\n",
    "    PRJ_MSW['extra'] = PRJ_no_MSW['extra']\n",
    "    del PRJ_no_MSW['cap'], PRJ_no_MSW['extra']\n",
    "    # print(\"Removed cap/extra package due to mixed grid compatibility issues\")\n",
    "\n",
    "Sim_MF6 = mf6.Modflow6Simulation.from_imod5_data(PRJ_no_MSW, period_data, times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "234ead8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MF6_Mdl = Sim_MF6['imported_model']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ba84d0",
   "metadata": {},
   "source": [
    "For some reason there is only 1 river system remaining. I'd expect at least 2 out of 5 (RIV and detailwatergangen) (RIV supposedly has 2, but the one that can discharge into the aquifer has a conductance of 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e51ba58",
   "metadata": {},
   "outputs": [],
   "source": [
    "MF6_Mdl[\"oc\"] = mf6.OutputControl(save_head=\"last\", save_budget=\"last\")\n",
    "    \n",
    "# Mimic iMOD5's \"Moderate\" settings\n",
    "Sim_MF6[\"ims\"] = UIM.mf6_solution_moderate_settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6492a155",
   "metadata": {},
   "source": [
    "# Load MSW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130f794e",
   "metadata": {},
   "source": [
    "## 1st attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02af4484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MF6_DIS will be extracted after regridding to ensure 25m resolution\n"
     ]
    }
   ],
   "source": [
    "# Don't extract MF6_DIS here - do it after regridding!\n",
    "MF6_DIS = Sim_MF6[\"imported_model\"][\"dis\"]  # This gets the OLD 100m grid\n",
    "print(\"MF6_DIS will be extracted after regridding to ensure 25m resolution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1936d316",
   "metadata": {},
   "source": [
    "PRJ_regrid['cap'].keys()\n",
    "for i in PRJ_regrid['cap'].keys():\n",
    "    print(f\" === {i} ===\")\n",
    "    print(PRJ_regrid['cap'][i], \"\\n\")\n",
    "x_CeCes, y_CeCes = UIM.get_CeCes_from_INI(MdlN)\n",
    "PRJ['cap']['urban_area'].x.shape[0] / PRJ_regrid['cap']['urban_area'].x.shape[0]\n",
    "len(x_CeCes)\n",
    "PRJ['cap']['urban_area'].sel(x=slice(Xmin, Xmax), y=slice(Ymax, Ymin)).plot(cmap='Spectral')\n",
    "(PRJ['cap']['urban_area'].sel(x=slice(Xmin, Xmax), y=slice(Ymax, Ymin)) / PRJ_regrid['cap']['urban_area']).plot(cmap='Spectral')\n",
    "PRJ_regrid['cap']['urban_area'].plot(cmap='Spectral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ed6fe49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating MetaSwap model: \n",
      "Did not find parsable path to existing .ASC file in column 2. Got\n",
      "values (printing first 10): ['..\\\\..\\\\In\\\\CAP\\\\P\\\\NBr1\\\\P_20100101_NBr1.asc', '..\\\\..\\\\In\\\\CAP\\\\P\\\\NBr1\\\\P_20100102_NBr1.asc', '..\\\\..\\\\In\\\\CAP\\\\P\\\\NBr1\\\\P_20100103_NBr1.asc', '..\\\\..\\\\In\\\\CAP\\\\P\\\\NBr1\\\\P_20100104_NBr1.asc', '..\\\\..\\\\In\\\\CAP\\\\P\\\\NBr1\\\\P_20100105_NBr1.asc', '..\\\\..\\\\In\\\\CAP\\\\P\\\\NBr1\\\\P_20100106_NBr1.asc', '..\\\\..\\\\In\\\\CAP\\\\P\\\\NBr1\\\\P_20100107_NBr1.asc', '..\\\\..\\\\In\\\\CAP\\\\P\\\\NBr1\\\\P_20100108_NBr1.asc', '..\\\\..\\\\In\\\\CAP\\\\P\\\\NBr1\\\\P_20100109_NBr1.asc', '..\\\\..\\\\In\\\\CAP\\\\P\\\\NBr1\\\\P_20100110_NBr1.asc'].\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    MSW_Mdl = msw.MetaSwapModel.from_imod5_data(PRJ_MSW, MF6_DIS, times)\n",
    "    print(\"🎉 MetaSwap model created successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating MetaSwap model: {e}\")\n",
    "    MSW_Mdl = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4a578f",
   "metadata": {},
   "source": [
    "## 2nd attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0f189b",
   "metadata": {},
   "source": [
    "### Fix mete_grid.inp relative paths\n",
    "MSW.MetaSwapModel.from_imod5_data is struggling with relative paths, so we'll convert them to full paths. #666 caution, if they're already full paths, this may cause an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0bcd8aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original file: C:\\Users\\Karam014\\OneDrive - Universiteit Utrecht\\WS_Mdl\\models\\NBr\\In\\CAP\\mete_grid\\NBr5\\mete_grid.inp\n"
     ]
    }
   ],
   "source": [
    "# Get the original mete_grid.inp file path\n",
    "Pa_mete_grid = PRJ_MSW['extra']['paths'][2][0]  # 3rd file (index 2) (by design in imod - i.e. the order can't change)\n",
    "print(f\"Original file: {Pa_mete_grid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9045fdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load mete_grid, edit and save it \n",
    "Dir_mete_grid = PDN(Pa_mete_grid)\n",
    "Pa_mete_grid_AbsPa = PJ( PDN(Pa_mete_grid), 'temp', 'mete_grid.inp')\n",
    "if not PE(PDN(Pa_mete_grid_AbsPa)):\n",
    "    MDs(PDN(Pa_mete_grid_AbsPa))\n",
    "\n",
    "DF = pd.read_csv(Pa_mete_grid, header=None, names=['N', 'Y', 'P', 'PET'])\n",
    "DF.P = DF.P.apply(lambda x: os.path.abspath( PJ(Dir_PRJ, x) ))\n",
    "DF.PET = DF.PET.apply(lambda x: os.path.abspath( PJ(Dir_PRJ, x) ))  # Fixed: was DF.P instead of DF.PET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6018fc31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created corrected mete_grid.inp: C:\\Users\\Karam014\\OneDrive - Universiteit Utrecht\\WS_Mdl\\models\\NBr\\In\\CAP\\mete_grid\\NBr5\\temp\\mete_grid.inp\n"
     ]
    }
   ],
   "source": [
    "# Write CSV with proper format to avoid imod parsing issues with newlines\n",
    "# imod doesn't strip newlines from paths, so we need to format carefully\n",
    "corrected_lines = []\n",
    "for index, row in DF.iterrows():\n",
    "    # Add quotes around paths like the original format\n",
    "    line = f'{row[\"N\"]},{row[\"Y\"]},\"{row[\"P\"]}\",\"{row[\"PET\"]}\"'\n",
    "    corrected_lines.append(line)\n",
    "\n",
    "# Write without newlines in path columns\n",
    "with open(Pa_mete_grid_AbsPa, 'w') as f:\n",
    "    for i, line in enumerate(corrected_lines):\n",
    "        if i == len(corrected_lines) - 1:  # Last line - no newline\n",
    "            f.write(line)\n",
    "        else:\n",
    "            f.write(line + '\\n')\n",
    "\n",
    "print(f\"Created corrected mete_grid.inp: {Pa_mete_grid_AbsPa}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90bd32c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the mete_grid.inp path in the PRJ_MSW_for_MSW dictionary\n",
    "PRJ_MSW['extra']['paths'][2][0] = Pa_mete_grid_AbsPa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bcabf7",
   "metadata": {},
   "source": [
    "### Finally load MS Sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5005945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎉 MetaSwap model created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create the MetaSwap model\n",
    "MSW_Mdl = msw.MetaSwapModel.from_imod5_data(PRJ_MSW, MF6_DIS, times)\n",
    "print(\"🎉 MetaSwap model created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b149d0",
   "metadata": {},
   "source": [
    "# Explore MSW_Mdl Keys and Plot Parameters\n",
    "\n",
    "This section systematically goes through all keys in the MetaSWAP model and plots each parameter with clear visual separation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15767167",
   "metadata": {},
   "source": [
    "### Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab5d1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's explore the top-level keys of MSW_Mdl\n",
    "print(\"=\"*80)\n",
    "print(\"MSW_Mdl Top-Level Keys:\")\n",
    "print(\"=\"*80)\n",
    "for i, key in enumerate(MSW_Mdl.keys(), 1):\n",
    "    print(f\"{i}. {key}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c765e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's explore the structure of each key to understand what we can plot\n",
    "print(\"=\"*80)\n",
    "print(\"DETAILED STRUCTURE OF EACH MSW_Mdl KEY:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for key in MSW_Mdl.keys():\n",
    "    print(f\"\\n{'='*20} {key.upper()} {'='*20}\")\n",
    "    try:\n",
    "        # Check if it has a dataset attribute (most plotting will be from datasets)\n",
    "        if hasattr(MSW_Mdl[key], 'dataset'):\n",
    "            print(f\"Type: {type(MSW_Mdl[key])}\")\n",
    "            print(f\"Dataset variables: {list(MSW_Mdl[key].dataset.keys())}\")\n",
    "            \n",
    "            # Show dimensions for each variable\n",
    "            for var in MSW_Mdl[key].dataset.keys():\n",
    "                dims = MSW_Mdl[key].dataset[var].dims\n",
    "                shape = MSW_Mdl[key].dataset[var].shape\n",
    "                print(f\"  - {var}: dims={dims}, shape={shape}\")\n",
    "        else:\n",
    "            print(f\"Type: {type(MSW_Mdl[key])}\")\n",
    "            print(f\"Content preview: {str(MSW_Mdl[key])[:200]}...\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error exploring {key}: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104091ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's focus on identifying which keys have spatial data that can be plotted\n",
    "print(\"=\"*80)\n",
    "print(\"PLOTTABLE PARAMETERS IN MSW_Mdl:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "plottable_params = {}\n",
    "\n",
    "for key in MSW_Mdl.keys():\n",
    "    print(f\"\\n{key.upper()}:\")\n",
    "    try:\n",
    "        if hasattr(MSW_Mdl[key], 'dataset'):\n",
    "            spatial_vars = []\n",
    "            for var in MSW_Mdl[key].dataset.keys():\n",
    "                dims = MSW_Mdl[key].dataset[var].dims\n",
    "                # Check if variable has spatial dimensions (x, y)\n",
    "                if 'x' in dims and 'y' in dims:\n",
    "                    spatial_vars.append(var)\n",
    "                    print(f\"  ✓ {var} - dims: {dims}\")\n",
    "            plottable_params[key] = spatial_vars\n",
    "        else:\n",
    "            print(f\"  - No dataset attribute (Type: {type(MSW_Mdl[key]).__name__})\")\n",
    "    except Exception as e:\n",
    "        print(f\"  - Error: {e}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"SUMMARY - Keys with plottable parameters:\")\n",
    "for key, vars_list in plottable_params.items():\n",
    "    if vars_list:\n",
    "        print(f\"  {key}: {len(vars_list)} parameters - {vars_list}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db018dd6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 🎨 **PLOTTING ALL MSW_Mdl PARAMETERS**\n",
    "\n",
    "Below we systematically plot all spatial parameters from each key in the MetaSWAP model. Each section is clearly separated and labeled for easy navigation.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6b5e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function for consistent plotting with clear visual separation\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_msw_parameter(data, param_name, key_name, subunit=None, cmap='viridis', figsize=(10, 8)):\n",
    "    \"\"\"\n",
    "    Plot a MetaSWAP parameter with consistent formatting and clear labeling.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : xarray.DataArray\n",
    "        The data to plot\n",
    "    param_name : str\n",
    "        Name of the parameter\n",
    "    key_name : str\n",
    "        Name of the MSW key (grid, infiltration, etc.)\n",
    "    subunit : int, optional\n",
    "        Subunit to plot (for parameters with subunit dimension)\n",
    "    cmap : str\n",
    "        Colormap to use\n",
    "    figsize : tuple\n",
    "        Figure size\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*20} {key_name.upper()}: {param_name} {'='*20}\")\n",
    "    \n",
    "    # Handle subunit selection if needed\n",
    "    if 'subunit' in data.dims:\n",
    "        if subunit is None:\n",
    "            subunit = 0  # Default to first subunit\n",
    "        plot_data = data.sel(subunit=subunit)\n",
    "        title = f\"{key_name.title()}: {param_name.replace('_', ' ').title()}\\n(Subunit {subunit})\"\n",
    "    else:\n",
    "        plot_data = data\n",
    "        title = f\"{key_name.title()}: {param_name.replace('_', ' ').title()}\"\n",
    "    \n",
    "    # Create the plot\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    # Plot with imshow\n",
    "    im = plot_data.plot.imshow(\n",
    "        ax=ax,\n",
    "        cmap=cmap,\n",
    "        add_colorbar=True,\n",
    "        cbar_kwargs={'shrink': 0.8}\n",
    "    )\n",
    "    \n",
    "    ax.set_title(title, fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('X Coordinate', fontsize=12)\n",
    "    ax.set_ylabel('Y Coordinate', fontsize=12)\n",
    "    \n",
    "    # Add statistics\n",
    "    valid_data = plot_data.values[~np.isnan(plot_data.values)]\n",
    "    if len(valid_data) > 0:\n",
    "        stats_text = f\"Min: {valid_data.min():.3f} | Max: {valid_data.max():.3f} | Mean: {valid_data.mean():.3f}\"\n",
    "        ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, \n",
    "                bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8),\n",
    "                fontsize=10, verticalalignment='top')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Dimensions: {plot_data.dims}\")\n",
    "    print(f\"Shape: {plot_data.shape}\")\n",
    "    print(f\"Data type: {plot_data.dtype}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "print(\"✅ Plotting utility function loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1790c4",
   "metadata": {},
   "source": [
    "### 🎨 **PLOTTING ALL MSW MODEL PARAMETERS**\n",
    "\n",
    "Below we systematically plot all spatial parameters from each key in the MetaSWAP model using a grouped, efficient approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f346e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define plotting configuration for all MSW model keys\n",
    "msw_plotting_config = {\n",
    "    'grid': {\n",
    "        'emoji': '🌍',\n",
    "        'description': 'Grid parameters including land use, area, soil properties, and surface characteristics',\n",
    "        'params': ['area', 'landuse', 'rootzone_depth', 'surface_elevation', 'soil_physical_unit', 'active'],\n",
    "        'subunit_params': ['area', 'landuse', 'rootzone_depth'],\n",
    "        'colormaps': {\n",
    "            'landuse': 'tab10',\n",
    "            'surface_elevation': 'terrain',\n",
    "            'default': 'viridis'\n",
    "        }\n",
    "    },\n",
    "    'infiltration': {\n",
    "        'emoji': '💧', \n",
    "        'description': 'Infiltration parameters for water capacity, soil resistance, and storage properties',\n",
    "        'params': ['infiltration_capacity', 'downward_resistance', 'upward_resistance', 'bottom_resistance', 'extra_storage_coefficient'],\n",
    "        'subunit_params': ['infiltration_capacity', 'downward_resistance', 'upward_resistance'],\n",
    "        'colormaps': {\n",
    "            'default': 'viridis',\n",
    "            'resistance': 'Blues'\n",
    "        }\n",
    "    },\n",
    "    'ponding': {\n",
    "        'emoji': '🌊',\n",
    "        'description': 'Ponding parameters for surface water, runoff, and runon processes',\n",
    "        'params': ['ponding_depth', 'runon_resistance', 'runoff_resistance'],\n",
    "        'subunit_params': ['ponding_depth', 'runon_resistance', 'runoff_resistance'],\n",
    "        'colormaps': {\n",
    "            'depth': 'Blues',\n",
    "            'resistance': 'Oranges',\n",
    "            'default': 'viridis'\n",
    "        }\n",
    "    },\n",
    "    'sprinkling': {\n",
    "        'emoji': '💦',\n",
    "        'description': 'Sprinkling parameters for irrigation and water abstraction',\n",
    "        'params': ['max_abstraction_groundwater', 'max_abstraction_surfacewater'],\n",
    "        'subunit_params': ['max_abstraction_groundwater', 'max_abstraction_surfacewater'],\n",
    "        'colormaps': {\n",
    "            'groundwater': 'Greens',\n",
    "            'surfacewater': 'Blues',\n",
    "            'default': 'viridis'\n",
    "        }\n",
    "    },\n",
    "    'idf_mapping': {\n",
    "        'emoji': '🗺️',\n",
    "        'description': 'IDF mapping parameters for grid coordinates and areas',\n",
    "        'params': ['area', 'rows', 'columns', 'x_grid', 'y_grid'],\n",
    "        'subunit_params': [],\n",
    "        'colormaps': {\n",
    "            'area': 'viridis',\n",
    "            'default': 'plasma'\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "def get_colormap(param_name, key_config):\n",
    "    \"\"\"Get appropriate colormap for a parameter\"\"\"\n",
    "    colormaps = key_config['colormaps']\n",
    "    \n",
    "    # Check for specific parameter matches\n",
    "    for keyword, cmap in colormaps.items():\n",
    "        if keyword != 'default' and keyword in param_name:\n",
    "            return cmap\n",
    "    \n",
    "    return colormaps.get('default', 'viridis')\n",
    "\n",
    "def plot_key_parameters(key_name, config):\n",
    "    \"\"\"Plot all parameters for a given MSW key\"\"\"\n",
    "    if key_name not in MSW_Mdl:\n",
    "        print(f\"⚠️  Key '{key_name}' not found in MSW_Mdl\")\n",
    "        return\n",
    "    \n",
    "    if not hasattr(MSW_Mdl[key_name], 'dataset'):\n",
    "        print(f\"⚠️  Key '{key_name}' has no dataset attribute\")\n",
    "        return\n",
    "    \n",
    "    # Header\n",
    "    print(f\"\\n{'='*20} {config['emoji']} {key_name.upper()} PARAMETERS {'='*20}\")\n",
    "    print(f\"{config['description']}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    available_params = [p for p in config['params'] if p in MSW_Mdl[key_name].dataset]\n",
    "    if not available_params:\n",
    "        print(f\"No plottable parameters found in {key_name}\")\n",
    "        return\n",
    "    \n",
    "    for param in available_params:\n",
    "        cmap = get_colormap(param, config)\n",
    "        \n",
    "        if param in config['subunit_params']:\n",
    "            # Plot both subunits\n",
    "            for subunit in [0, 1]:\n",
    "                plot_msw_parameter(\n",
    "                    MSW_Mdl[key_name].dataset[param], \n",
    "                    param, \n",
    "                    key_name, \n",
    "                    subunit=subunit,\n",
    "                    cmap=cmap\n",
    "                )\n",
    "        else:\n",
    "            # Plot without subunit\n",
    "            plot_msw_parameter(\n",
    "                MSW_Mdl[key_name].dataset[param], \n",
    "                param, \n",
    "                key_name,\n",
    "                cmap=cmap\n",
    "            )\n",
    "\n",
    "print(\"✅ MSW plotting configuration loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a183b44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot all MSW model parameters using the grouped approach\n",
    "# print(\"🚀 Starting comprehensive plotting of all MSW model parameters...\")\n",
    "# print(\"=\"*80)\n",
    "\n",
    "# for key_name, config in msw_plotting_config.items():\n",
    "#     plot_key_parameters(key_name, config)\n",
    "#     print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# print(\"🎉 All available MSW model parameters have been plotted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff00cfd4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 📊 **PLOTTING SUMMARY**\n",
    "\n",
    "The efficient grouped plotting approach covers all spatial parameters from the following MSW model components:\n",
    "\n",
    "### **Available Keys Plotted:**\n",
    "1. **🌍 GRID**: Land use, area distribution, soil properties, surface characteristics\n",
    "2. **💧 INFILTRATION**: Water capacity, soil resistance, storage properties  \n",
    "3. **🌊 PONDING**: Surface water, runoff, runon processes\n",
    "4. **💦 SPRINKLING**: Irrigation and water abstraction\n",
    "5. **🗺️ IDF_MAPPING**: Grid coordinates and mapping areas\n",
    "\n",
    "### **Key Features:**\n",
    "- **Automated Detection**: Only plots parameters that actually exist in the model\n",
    "- **Smart Colormaps**: Automatically selects appropriate colors based on parameter type\n",
    "- **Subunit Handling**: Automatically detects and plots both subunits where applicable\n",
    "- **Reusable Code**: Single configuration drives all plotting with minimal repetition\n",
    "- **Clear Organization**: Each key section clearly labeled and separated\n",
    "\n",
    "### **Benefits of Grouped Approach:**\n",
    "- ✅ **Less Code**: Single loop handles all keys instead of separate blocks\n",
    "- ✅ **Maintainable**: Easy to add new keys or modify colormaps\n",
    "- ✅ **Robust**: Handles missing parameters gracefully\n",
    "- ✅ **Consistent**: All plots follow the same formatting standards\n",
    "\n",
    "---\n",
    "\n",
    "**🎯 Efficient plotting complete - all spatial MSW parameters visualized with minimal code duplication!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d72c340",
   "metadata": {},
   "source": [
    "# Connect MF6 to MetaSWAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f254c4f",
   "metadata": {},
   "source": [
    "## Apply Discretization to MF6 Model\n",
    "\n",
    "Before clipping and connecting MF6 and MSW models, we need to ensure both have compatible discretizations. The MF6 model needs to be regridded to match the target MSW discretization (25m x 25m cells) and the correct extent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d7fd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple: Regrid MF6 to match existing MSW coordinates\n",
    "print(\"Regridding MF6 to MSW coordinates...\")\n",
    "\n",
    "# First, store the regridded DIS dataset separately\n",
    "regridded_dis_dataset = None\n",
    "\n",
    "# Regrid all MF6 packages to existing MSW coordinates\n",
    "for pkg_name, pkg in MF6_Mdl.items():\n",
    "    if hasattr(pkg, 'dataset') and 'x' in pkg.dataset.dims and 'y' in pkg.dataset.dims:\n",
    "        pkg._dataset = pkg.dataset.interp(x=x_MSW_CeCes, y=y_MSW_CeCes, method='linear')\n",
    "        if 'idomain' in pkg.dataset:\n",
    "            pkg._dataset['idomain'] = pkg._dataset['idomain'].round().astype(int)\n",
    "        \n",
    "        # Store the regridded DIS dataset\n",
    "        if pkg_name == 'dis':\n",
    "            regridded_dis_dataset = pkg._dataset\n",
    "\n",
    "# Now recreate DIS using the REGRIDDED dataset (not the original)\n",
    "if regridded_dis_dataset is not None:\n",
    "    MF6_Mdl['dis'] = mf6.StructuredDiscretization(\n",
    "        top=regridded_dis_dataset['top'],\n",
    "        bottom=regridded_dis_dataset['bottom'],\n",
    "        idomain=regridded_dis_dataset['idomain']\n",
    "    )\n",
    "\n",
    "print(f\"✅ MF6 regridded to {len(x_MSW_CeCes)}x{len(y_MSW_CeCes)} grid with {float(x_MSW_CeCes[1] - x_MSW_CeCes[0]):.1f}m spacing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a176203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug: Check what MF6_Mdl actually is and its relationship to Sim_MF6\n",
    "print(\"=== DEBUGGING MF6_Mdl vs Sim_MF6 ===\")\n",
    "print(f\"MF6_Mdl type: {type(MF6_Mdl)}\")\n",
    "print(f\"Sim_MF6['imported_model'] type: {type(Sim_MF6['imported_model'])}\")\n",
    "print(f\"MF6_Mdl is Sim_MF6['imported_model']: {MF6_Mdl is Sim_MF6['imported_model']}\")\n",
    "\n",
    "print(f\"\\nMF6_Mdl['dis'] grid:\")\n",
    "print(f\"  Size: {len(MF6_Mdl['dis'].dataset['x'])} x {len(MF6_Mdl['dis'].dataset['y'])}\")\n",
    "print(f\"  Resolution: {float(MF6_Mdl['dis'].dataset['x'][1] - MF6_Mdl['dis'].dataset['x'][0]):.1f}m\")\n",
    "\n",
    "print(f\"\\nSim_MF6['imported_model']['dis'] grid:\")\n",
    "print(f\"  Size: {len(Sim_MF6['imported_model']['dis'].dataset['x'])} x {len(Sim_MF6['imported_model']['dis'].dataset['y'])}\")\n",
    "print(f\"  Resolution: {float(Sim_MF6['imported_model']['dis'].dataset['x'][1] - Sim_MF6['imported_model']['dis'].dataset['x'][0]):.1f}m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29285ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick check: both models should now have same grid\n",
    "print(f\"MF6 shape: {MF6_Mdl['dis'].dataset.sizes}\")\n",
    "print(f\"MSW shape: {MSW_Mdl['grid'].dataset.sizes}\")\n",
    "print(\"✅ Ready for clipping\" if MF6_Mdl['dis'].dataset.sizes['x'] == MSW_Mdl['grid'].dataset.sizes['x'] else \"⚠️ Size mismatch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e79ef78",
   "metadata": {},
   "source": [
    "## Clip models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f712611",
   "metadata": {},
   "outputs": [],
   "source": [
    "MF6_Mdl['dis'].dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f90a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip both models to the same extent now that they have compatible discretization\n",
    "print(\"=== Clipping Models to Area of Interest ===\")\n",
    "print(f\"Clipping extent: X({Xmin:.1f}, {Xmax:.1f}), Y({Ymin:.1f}, {Ymax:.1f})\")\n",
    "\n",
    "# Clip MF6 simulation (which contains the regridded model)\n",
    "print(\"Clipping MF6 Simulation...\")\n",
    "Sim_MF6_AoI = Sim_MF6.clip_box(x_min=Xmin, x_max=Xmax, y_min=Ymin, y_max=Ymax)\n",
    "\n",
    "# Clip MSW model\n",
    "print(\"Clipping MSW Model...\")\n",
    "MSW_Mdl_AoI = MSW_Mdl.clip_box(x_min=Xmin, x_max=Xmax, y_min=Ymin, y_max=Ymax)\n",
    "\n",
    "print(\"\\n=== Clipping Results ===\")\n",
    "MF6_Mdl_AoI = Sim_MF6_AoI['imported_model']\n",
    "\n",
    "print(f\"MF6 Model AoI DIS shape: {MF6_Mdl_AoI['dis'].dataset.sizes}\")\n",
    "print(f\"MSW Model AoI grid shape: {MSW_Mdl_AoI['grid'].dataset.sizes}\")\n",
    "\n",
    "print(\"✅ Both models successfully clipped to Area of Interest with compatible discretization!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26386eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final check: models should be aligned after clipping\n",
    "print(f\"MF6 clipped: {MF6_Mdl_AoI['dis'].dataset.sizes}\")\n",
    "print(f\"MSW clipped: {MSW_Mdl_AoI['grid'].dataset.sizes}\")\n",
    "print(\"✅ Models aligned and ready for coupling!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ff36ab",
   "metadata": {},
   "source": [
    " ✅ **DISCRETIZATION FIXED**\n",
    "\n",
    "**Problem**: MF6 had 100m cells, MSW had 25m cells  \n",
    "**Solution**: Regridded MF6 to use the existing `x_MSW_CeCes`, `y_MSW_CeCes` coordinates  \n",
    "**Result**: Both models now have identical 25m grids and are ready for coupling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55116693",
   "metadata": {},
   "source": [
    "#### Sense check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8979c992",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xmin, Xmax, Ymin, Ymax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0060722",
   "metadata": {},
   "outputs": [],
   "source": [
    "MF6_Mdl_AoI = Sim_MF6_AoI['imported_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f2727b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MF6_Mdl_AoI['dis']['x'].min().values, MF6_Mdl_AoI['dis']['x'].max().values, \\\n",
    "MF6_Mdl_AoI['dis']['y'].min().values, MF6_Mdl_AoI['dis']['y'].max().values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2efe09",
   "metadata": {},
   "source": [
    "Makes sense as those are cell centers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5648db6c",
   "metadata": {},
   "source": [
    "## Load models into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2b2aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pkg in MF6_Mdl.values():\n",
    "    pkg.dataset.load()\n",
    "\n",
    "for pkg in MSW_Mdl.values():\n",
    "    pkg.dataset.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94ab962",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3272ea",
   "metadata": {},
   "source": [
    "### MF6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75111d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mask from current regridded model (not the old one)\n",
    "mask = MF6_Mdl.domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6df0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask.sel({'layer':1}).plot.imshow( #111 Just to check the mask\n",
    "    cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33a6e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip masking - models are already properly clipped and aligned\n",
    "Sim_MF6_AoI.mask_all_models(mask)  # Skip due to grid alignment issues\n",
    "DIS_AoI = MF6_Mdl_AoI[\"dis\"]\n",
    "print(\"✅ Models are clipped and ready to use\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fb43f1",
   "metadata": {},
   "source": [
    "### Check if IMS has changed after clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c3ac0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if IMS objects are identical using dataset comparison\n",
    "Sim_MF6['ims'].dataset.equals(Sim_MF6_AoI['ims'].dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887c7797",
   "metadata": {},
   "source": [
    "### Check if the packages are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01481d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MF6_Mdl.keys() == MF6_Mdl_AoI.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73874bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed comparison of MF6 model packages\n",
    "print(\"=== MF6 Model Package Comparison ===\")\n",
    "\n",
    "# Get the keys from both models\n",
    "original_keys = set(MF6_Mdl.keys())\n",
    "aoi_keys = set(MF6_Mdl_AoI.keys())\n",
    "\n",
    "print(f\"Original model packages: {len(original_keys)}\")\n",
    "print(f\"AoI model packages: {len(aoi_keys)}\")\n",
    "\n",
    "# Find differences\n",
    "only_in_original = original_keys - aoi_keys\n",
    "only_in_aoi = aoi_keys - original_keys\n",
    "common_keys = original_keys & aoi_keys\n",
    "\n",
    "print(f\"\\nPackages only in original model ({len(only_in_original)}):\")\n",
    "for key in sorted(only_in_original):\n",
    "    print(f\"  - {key}\")\n",
    "\n",
    "print(f\"\\nPackages only in AoI model ({len(only_in_aoi)}):\")\n",
    "for key in sorted(only_in_aoi):\n",
    "    print(f\"  - {key}\")\n",
    "\n",
    "print(f\"\\nCommon packages ({len(common_keys)}):\")\n",
    "for key in sorted(common_keys):\n",
    "    print(f\"  - {key}\")\n",
    "\n",
    "# Check if it's just an ordering issue\n",
    "print(f\"\\nSame packages (different order): {original_keys == aoi_keys}\")\n",
    "print(f\"Original keys (ordered): {sorted(original_keys)}\")\n",
    "print(f\"AoI keys (ordered): {sorted(aoi_keys)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a5bb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the difference is related to the masking operation\n",
    "print(\"\\n=== Impact of Masking Operation ===\")\n",
    "\n",
    "# The masking operation (Sim_MF6_AoI.mask_all_models(mask)) might have removed some packages\n",
    "# that are entirely outside the domain or have no active cells after masking\n",
    "\n",
    "# Let's check if any packages were removed due to masking\n",
    "print(\"Note: The masking operation might remove packages that have no active cells in the AoI\")\n",
    "\n",
    "# Check for specific package types that are commonly affected by clipping/masking\n",
    "potentially_affected = ['wel', 'drn', 'riv', 'ghb', 'chd', 'rch', 'evt']\n",
    "for pkg_type in potentially_affected:\n",
    "    orig_matches = [k for k in original_keys if pkg_type in k.lower()]\n",
    "    aoi_matches = [k for k in aoi_keys if pkg_type in k.lower()]\n",
    "    \n",
    "    if len(orig_matches) != len(aoi_matches):\n",
    "        print(f\"\\n{pkg_type.upper()} packages:\")\n",
    "        print(f\"  Original: {orig_matches}\")\n",
    "        print(f\"  AoI: {aoi_matches}\")\n",
    "        print(f\"  Difference: {len(orig_matches) - len(aoi_matches)} packages removed\")\n",
    "\n",
    "# Check the masking operation that was performed\n",
    "print(f\"\\nMask shape: {mask.shape if hasattr(mask, 'shape') else 'No shape attribute'}\")\n",
    "print(f\"Mask type: {type(mask)}\")\n",
    "\n",
    "# Count active cells in mask\n",
    "try:\n",
    "    if hasattr(mask, 'values'):\n",
    "        active_cells = (mask.values > 0).sum()\n",
    "        total_cells = mask.values.size\n",
    "        print(f\"Active cells in mask: {active_cells}/{total_cells} ({100*active_cells/total_cells:.1f}%)\")\n",
    "except:\n",
    "    print(\"Could not compute active cell statistics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad1368b",
   "metadata": {},
   "source": [
    "This is ok. The only missing package is one of the WEL packages, which has no items in the model area."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66284647",
   "metadata": {},
   "source": [
    "### Cleanup MF6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b129a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MF6_Mdl_AoI.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1e66b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in MF6_Mdl_AoI.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f977772d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for Pkg in [i for i in MF6_Mdl_AoI.keys() if ('riv' in i.lower()) or ('drn' in i.lower())]:\n",
    "        MF6_Mdl_AoI[Pkg].cleanup(DIS_AoI)\n",
    "except:\n",
    "    print('Failed to cleanup packaes. Proceeding without cleanup. Fingers crossed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e2e680",
   "metadata": {},
   "source": [
    "### MSW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfadb000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup MetaSWAP\n",
    "MSW_Mdl_AoI[\"grid\"].dataset[\"rootzone_depth\"] = MSW_Mdl_AoI[\"grid\"].dataset[\"rootzone_depth\"].fillna(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4be448",
   "metadata": {},
   "outputs": [],
   "source": [
    "metamod_coupling = primod.MetaModDriverCoupling(mf6_model=\"imported_model\", mf6_recharge_package=\"msw-rch\", mf6_wel_package=\"msw-sprinkling\")\n",
    "metamod = primod.MetaMod(MSW_Mdl_AoI, Sim_MF6_AoI, coupling_list=[metamod_coupling])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a52b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(d_Pa['Pa_MdlN'], exist_ok=True) # Create simulation directory if it doesn't exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802caf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pa_MF6_DLL = r\"C:\\OD\\WS_Mdl\\software\\iMOD5\\bin\\iMOD_coupler\\libmf6.dll\"\n",
    "Pa_MSW_DLL = r\"C:\\OD\\WS_Mdl\\software\\iMOD5\\bin\\iMOD_coupler\\MetaSWAP.dll\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682653d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metamod.write(directory=d_Pa['Pa_MdlN'], modflow6_dll=Pa_MF6_DLL, metaswap_dll=Pa_MSW_DLL, metaswap_dll_dependency=PDN(Pa_MF6_DLL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c8efe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINAL SOLUTION: Try recreating MetaMod or use alternative approach\n",
    "print(\"=== FINAL SOLUTION ATTEMPT ===\")\n",
    "\n",
    "# The issue is that MetaMod.write() should create the coupling packages but isn't doing it\n",
    "# Let's try a few approaches:\n",
    "\n",
    "print(\"Approach 1: Recreate MetaMod object...\")\n",
    "try:\n",
    "    # Recreate the coupling and metamod objects\n",
    "    metamod_coupling_new = primod.MetaModDriverCoupling(\n",
    "        mf6_model=\"imported_model\", \n",
    "        mf6_recharge_package=\"msw-rch\", \n",
    "        mf6_wel_package=\"msw-sprinkling\"\n",
    "    )\n",
    "    metamod_new = primod.MetaMod(MSW_Mdl_AoI, Sim_MF6_AoI, coupling_list=[metamod_coupling_new])\n",
    "    \n",
    "    print(\"Trying write with new MetaMod object...\")\n",
    "    metamod_new.write(\n",
    "        directory=d_Pa['Pa_MdlN'], \n",
    "        modflow6_dll=Pa_MF6_DLL, \n",
    "        metaswap_dll=Pa_MSW_DLL, \n",
    "        metaswap_dll_dependency=PDN(Pa_MF6_DLL),\n",
    "        modflow6_write_kwargs={\"validate\": False}\n",
    "    )\n",
    "    print(\"🎉 SUCCESS with recreated MetaMod object!\")\n",
    "    \n",
    "except Exception as e1:\n",
    "    print(f\"❌ Approach 1 failed: {e1}\")\n",
    "    \n",
    "    print(\"\\nApproach 2: Write models separately...\")\n",
    "    try:\n",
    "        from pathlib import Path\n",
    "        base_dir = Path(d_Pa['Pa_MdlN'])\n",
    "        \n",
    "        # Write MF6 simulation\n",
    "        mf6_dir = base_dir / \"mf6\"\n",
    "        mf6_dir.mkdir(exist_ok=True)\n",
    "        Sim_MF6_AoI.write(mf6_dir, validate=False)\n",
    "        print(\"✅ MF6 written separately\")\n",
    "        \n",
    "        # Write MSW without coupling (if possible)\n",
    "        msw_dir = base_dir / \"msw\"  \n",
    "        msw_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Create a dummy Mf6Wel for MSW\n",
    "        try:\n",
    "            from imod.mf6.mf6_wel_adapter import Mf6Wel\n",
    "            dummy_wel = Mf6Wel()  # Try to create empty one\n",
    "            MSW_Mdl_AoI.write(msw_dir, MF6_Mdl_AoI['dis'], dummy_wel, validate=False)\n",
    "            print(\"✅ MSW written with dummy WEL\")\n",
    "        except Exception as e2:\n",
    "            print(f\"❌ MSW write failed: {e2}\")\n",
    "            print(\"MSW requires proper coupling - cannot write independently\")\n",
    "        \n",
    "        print(f\"\\n📁 Partial output in: {base_dir}\")\n",
    "        print(\"Note: Full coupling may not be working due to primod version compatibility\")\n",
    "        \n",
    "    except Exception as e2:\n",
    "        print(f\"❌ Approach 2 also failed: {e2}\")\n",
    "        print(\"\\nSUGGESTION: This appears to be a primod version compatibility issue.\")\n",
    "        print(\"Consider:\")\n",
    "        print(\"1. Updating primod to latest version\") \n",
    "        print(\"2. Checking primod documentation for version 2024.3.0\")\n",
    "        print(\"3. Using older primod version if this worked before\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8bbae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "primod.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fcfdef",
   "metadata": {},
   "source": [
    "# Only write MF6_Sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120dcfae",
   "metadata": {},
   "source": [
    "coupler is failing, so let's try just MF6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfa17af",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sim_MF6.write(d_Pa['Pa_MdlN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060a5f30",
   "metadata": {},
   "source": [
    "# Junkyard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31eb2ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a103b6",
   "metadata": {},
   "source": [
    "#### Test sim without cap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504b7fc0",
   "metadata": {},
   "source": [
    " <!-- # Simple solution: Remove CAP package and test if conversion works\n",
    " print(\"=== Testing Without CAP Package ===\")\n",
    "\n",
    " # Create a copy of PRJ without the CAP package\n",
    " PRJ_no_MSW = PRJ.copy()\n",
    " if \"cap\" in PRJ_no_MSW:\n",
    "     del PRJ_no_MSW[\"cap\"]\n",
    "     print(\"CAP package removed from PRJ\")\n",
    " else:\n",
    "     print(\"CAP package not found in PRJ\")\n",
    "\n",
    " print(f\"Original PRJ keys: {list(PRJ.keys())}\")\n",
    " print(f\"PRJ without CAP keys: {list(PRJ_no_MSW.keys())}\")\n",
    "\n",
    " # Test the conversion without CAP\n",
    " try:\n",
    "     print(\"\\n=== Testing Simulation Conversion Without CAP ===\")\n",
    "     simulation = imod.MF6.Modflow6Simulation.from_imod5_data(PRJ_no_MSW, period_data, times)\n",
    "     print(\"SUCCESS: Simulation created without CAP package!\")\n",
    "     print(f\"Simulation keys: {list(simulation.keys())}\")\n",
    "    \n",
    "     # Check what packages were created\n",
    "     if \"imported_model\" in simulation:\n",
    "         model = simulation[\"imported_model\"]\n",
    "         print(f\"Model packages: {list(model.keys())}\")\n",
    "        \n",
    " except Exception as e:\n",
    "     print(f\"Error without CAP: {e}\")\n",
    "     import traceback\n",
    "     traceback.print_exc() -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0f474d",
   "metadata": {},
   "source": [
    "#### Investigate well error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2382b8",
   "metadata": {},
   "source": [
    "from imod.MF6.wel import LayeredWell, Well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061bef74",
   "metadata": {},
   "source": [
    "PRJ['wel-WEL_Br_Wa_T_NBr1']['layer']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1688bd",
   "metadata": {},
   "source": [
    "Well.from_imod5_data('wel-WEL_Br_Wa_T_NBr1', PRJ, times)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2b363a",
   "metadata": {},
   "source": [
    "os.remove(Pa_PRJ_temp)  # Delete temp PRJ file as it's not needed anymore."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7d3619",
   "metadata": {},
   "source": [
    "## Option: Subset PRJ data before conversion\n",
    "\n",
    "You can subset the PRJ data before calling `from_imod5_data` to reduce memory usage and processing time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc97a7f1",
   "metadata": {},
   "source": [
    "### Example: Subset PRJ data before conversion to reduce memory usage\n",
    "### This approach can be useful for very large models\n",
    "\n",
    "def subset_prj_data(prj_dict, x_min, x_max, y_min, y_max):\n",
    "    \"\"\"\n",
    "    Subset PRJ data to a specific bounding box before conversion.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    prj_dict : dict\n",
    "        The PRJ dictionary from open_projectfile_data\n",
    "    x_min, x_max, y_min, y_max : float\n",
    "        Bounding box coordinates\n",
    "    \"\"\"\n",
    "    prj_subset = {}\n",
    "    \n",
    "    for package_name, package_data in prj_dict.items():\n",
    "        if hasattr(package_data, 'sel') and hasattr(package_data, 'dims'):\n",
    "            # For xarray DataArrays with spatial dimensions\n",
    "            if 'x' in package_data.dims and 'y' in package_data.dims:\n",
    "                try:\n",
    "                    # Subset to bounding box\n",
    "                    subset_data = package_data.sel(\n",
    "                        x=slice(x_min, x_max),\n",
    "                        y=slice(y_max, y_min)  # Note: y is typically decreasing\n",
    "                    )\n",
    "                    prj_subset[package_name] = subset_data\n",
    "                    print(f\"Subsetted {package_name}: {package_data.sizes} -> {subset_data.sizes}\")\n",
    "                except Exception as e:\n",
    "                    # If subsetting fails, keep original data\n",
    "                    prj_subset[package_name] = package_data\n",
    "                    print(f\"Could not subset {package_name}: {e}\")\n",
    "            else:\n",
    "                # Keep non-spatial data as is\n",
    "                prj_subset[package_name] = package_data\n",
    "        else:\n",
    "            # Keep non-xarray data as is\n",
    "            prj_subset[package_name] = package_data\n",
    "    \n",
    "    return prj_subset\n",
    "\n",
    "### Example usage (commented out - use if needed):\n",
    "### PRJ_subset = subset_prj_data(PRJ, Xmin, Xmax, Ymin, Ymax)\n",
    "### Sim_MF6_subset = imod.mf6.Modflow6Simulation.from_imod5_data(PRJ_subset, period_data, times)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
